{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eba170e4-c7b5-44fb-b02b-20bfda2475ee",
   "metadata": {},
   "source": [
    "# ğŸ“š Week 1ï¼šLLM + LangChain å…¥é–€æ•™å­¸\n",
    "\n",
    "æ­¡è¿ä¾†åˆ°æœ¬é€±èª²ç¨‹ï¼æœ¬å–®å…ƒå°‡å¸¶ä½ å¾é›¶é–‹å§‹äº†è§£å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åŸºæœ¬æ¦‚å¿µï¼Œä¸¦å¯¦éš›é«”é©—å¦‚ä½•é‹ç”¨ LangChain æ¡†æ¶æ•´åˆ AI èƒ½åŠ›ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b090c47-ef06-4fb1-b8ac-42cf71058e2d",
   "metadata": {},
   "source": [
    "# èª²ç¨‹æœŸæœ›æ§åˆ¶<a name='èª²ç¨‹æœŸæœ›æ§åˆ¶'></a>\n",
    "\n",
    "1. å»ºç«‹åŸºæœ¬æ¦‚å¿µï¼Œä¸å¿…æˆç‚ºç¨‹å¼é«˜æ‰‹\n",
    "\n",
    "    - å³ä½¿ä½ æœªä¾†ä¸æ‰“ç®—å¯«ç¨‹å¼ï¼Œä¹Ÿè‡³å°‘èƒ½å° LLMï¼ˆå¤§å‹èªè¨€æ¨¡å‹ï¼‰æœ‰ä¸€å€‹ç›´è¦ºæ€§çš„ç†è§£ï¼š\n",
    "\n",
    "\n",
    "2. ä»€éº¼ä»»å‹™æ˜¯ AI å¯ä»¥å¹«ä½ å®Œæˆçš„\n",
    "\n",
    "    - ä»€éº¼ Proposal æˆ–å·¥å…·è²ç¨±èƒ½åšçš„äº‹æƒ…å…¶å¯¦æ˜¯èª‡å¤§çš„ã€ç”šè‡³æ˜¯é¨™äººçš„\n",
    "\n",
    "\n",
    "3. èª²ç¨‹ä¸å¯èƒ½æ¶µè“‹æ‰€æœ‰éœ€æ±‚\n",
    "\n",
    "    - æ¯å€‹äººçš„å·¥ä½œå ´æ™¯ã€éœ€æ±‚å’Œç›®æ¨™éƒ½ä¸åŒï¼Œæœ¬èª²ç¨‹æä¾›çš„æ˜¯é€šç”¨åŸºç¤èˆ‡æ€ç¶­æ–¹å¼ï¼Œä¸èƒ½æ¶µè“‹æ‰€æœ‰å°ˆæ¥­æˆ–å•†æ¥­ç´°ç¯€\n",
    "\n",
    "\n",
    "4. ç¸®çŸ­æŠ€è¡“èˆ‡å•†æ¥­æºé€šçš„è½å·®\n",
    "\n",
    "    - è®“ä½ åœ¨èˆ‡å·¥ç¨‹å¸«ã€AI åœ˜éšŠæˆ–é¡§å•è¨è«–æ™‚ï¼Œä¸æœƒå®Œå…¨è½ä¸æ‡‚ï¼Œä¹Ÿæ›´å®¹æ˜“åˆ¤æ–·å“ªäº›ææ¡ˆåˆç†ã€å“ªäº›éœ€è¦è¿½å•\n",
    "\n",
    "\n",
    "5. å…¥é–€ç‚ºä¸»ï¼Œå¯¦ä¾‹ç‚ºè¼”\n",
    "\n",
    "    - æœ¬èª²ç¨‹å®šä½æ˜¯å…¥é–€ï¼Œä½†æˆ‘æœƒç›¡é‡æä¾›å¯¦éš›ä¾‹å­ã€å ´æ™¯å’Œæ“ä½œæ¼”ç¤ºï¼Œå¹«åŠ©ä½ æŠŠæ¦‚å¿µã€Œè½åœ°ã€ï¼Œæ–¹ä¾¿æœªä¾†å¯¦éš›æ‡‰ç”¨\n",
    "  \n",
    "# å­¸ç¿’å¿ƒæ…‹æç¤º\n",
    "\n",
    "1. ä¸è¦è¿½æ±‚å®Œç¾\n",
    "    - LLM å’Œ AI çš„ä¸–ç•Œç¬æ¯è¬è®Šï¼Œä»Šå¤©çœ‹åˆ°çš„æ¡ˆä¾‹ï¼Œæ˜å¤©å¯èƒ½å°±æ›´æ–°äº†ã€‚é‡è¦çš„æ˜¯ç†è§£æ¦‚å¿µå’Œæ€è·¯ï¼Œè€Œä¸æ˜¯ä¸€æ¬¡å°±æŒæ¡æ‰€æœ‰ç´°ç¯€ã€‚\n",
    "\n",
    "2. å‹‡æ–¼å˜—è©¦ï¼Œæ•¢æ–¼çŠ¯éŒ¯\n",
    "   - AI å¾ˆåƒä¸€å€‹å¼·å¤§çš„åŠ©æ‰‹ï¼Œæ“ä½œå®ƒçš„éç¨‹æœ¬èº«å°±æ˜¯å­¸ç¿’ã€‚éŒ¯èª¤å’Œæ„å¤–çµæœéƒ½æ˜¯æœ€å¥½çš„è€å¸«ã€‚\n",
    "\n",
    "3. ä¿æŒå¥½å¥‡å¿ƒ\n",
    "    - ä¸ç®¡ä½ çš„å°ˆæ¥­èƒŒæ™¯æ˜¯ä»€éº¼ï¼Œå° AI çš„æ¢ç´¢éƒ½èƒ½çµ¦ä½ å¸¶ä¾†æ–°çš„è¦–è§’ã€‚å¤šå•ã€Œç‚ºä»€éº¼å¯ä»¥é€™æ¨£åšï¼Ÿã€æ¯”å–®ç´”è¨˜ä½æ“ä½œæ›´é‡è¦ã€‚\n",
    "\n",
    "4. æ¦‚å¿µå…ˆè¡Œï¼ŒæŠ€è¡“å…¶æ¬¡\n",
    "    - ä¸å¿…æ“”å¿ƒè‡ªå·±ä¸æœƒå¯«ç¨‹å¼ï¼Œç†è§£ AI å¯ä»¥åšä»€éº¼ã€ä¸èƒ½åšä»€éº¼ï¼Œä»¥åŠå®ƒçš„å±€é™ï¼Œæ¯”æŒæ¡æ‰€æœ‰ç´°ç¯€æ›´å¯¦ç”¨ã€‚\n",
    "\n",
    "5. äº’å‹•å’Œåˆ†äº«\n",
    "    - èª²å ‚ä¸Šä½ çš„ç–‘å•å¾ˆå¯èƒ½ä¹Ÿå›°æ“¾å…¶ä»–äººï¼Œä¸æ‡‚å°±å•ï¼Œåˆ†äº«ä½ çš„è§€å¯Ÿå’Œæƒ³æ³•ï¼Œé€™æ¯”è¢«å‹•è½èª²æ›´èƒ½åŠ æ·±ç†è§£ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e8a6e5-5c0b-4860-a894-dd3560547813",
   "metadata": {},
   "source": [
    "# ç’°å¢ƒè¨­ç½®\n",
    "\n",
    "1. conda create -n aicg python=3.10\n",
    "2. conda activate aicg\n",
    "3. pip install -r requirements.txt\n",
    "4. jupyter lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beac0be8-18de-4d0a-8168-47b47013506f",
   "metadata": {},
   "source": [
    "# LangChain æ¡†æ¶ä»‹ç´¹\n",
    "\n",
    "> ğŸ¯ **æœ¬ç« å­¸å®Œä½ å°‡èƒ½å­¸æœƒä»€éº¼ï¼š**\n",
    "> - ç†è§£ LangChain çš„æ ¸å¿ƒçµ„ä»¶èˆ‡æ¨¡çµ„åŒ–è¨­è¨ˆç†å¿µ  \n",
    "> - å­¸æœƒä½¿ç”¨ LLMã€PromptTemplateã€Chain ç­‰é—œéµæ¨¡çµ„  \n",
    "> - èƒ½å¤ çµ„è£ç°¡å–®çš„ AI å·¥ä½œæµç¨‹ï¼ˆä¾‹å¦‚å•ç­”ã€æ‘˜è¦æˆ–å°è©±ç³»çµ±ï¼‰  \n",
    "\n",
    "ä¸»æµå¤§èªè¨€æ¨¡å‹çš„æ‡‰ç”¨æ¡†æ¶\n",
    "\n",
    "## 1. æ¨¡çµ„åŒ–æŠ½è±¡ (Modular Abstractions)\n",
    "\n",
    "- æä¾›æ§‹å»ºç©æœ¨ï¼ˆLLM åŒ…è£å™¨ã€æç¤ºè©ã€è¨˜æ†¶ã€éˆæ¢ã€ä»£ç†äººï¼‰ï¼Œé¿å…é‡è¤‡ç™¼æ˜æ¨¡å¼ã€‚\n",
    "- å¹«åŠ©ä»¥å¯æ“´å±•çš„æ–¹å¼çµ„ç¹”å°ˆæ¡ˆï¼Œè€Œä¸æ˜¯éš¨æ„çš„è…³æœ¬ã€‚\n",
    "\n",
    "## 2. æ•´åˆèˆ‡ç”Ÿæ…‹ç³»çµ± (Integrations & Ecosystem)\n",
    "\n",
    "- æ”¯æ´å¤šç¨® LLM ä¾›æ‡‰å•†ï¼ˆOpenAIã€Anthropicã€æœ¬åœ°æ¨¡å‹ç­‰ï¼‰ä»¥åŠå‘é‡è³‡æ–™åº«ï¼ˆPineconeã€Weaviateã€FAISS ç­‰ï¼‰ã€‚\n",
    "- ä½¿æ›´æ›çµ„ä»¶è®Šå¾—ç°¡å–®ï¼Œç„¡éœ€é‡å¯«å¤§é‡ç¨‹å¼ç¢¼ã€‚\n",
    "\n",
    "## 3. å¿«é€ŸåŸå‹é–‹ç™¼ (Rapid Prototyping)\n",
    "\n",
    "- é©åˆå¿«é€Ÿé©—è­‰æƒ³æ³•ï¼šæª¢ç´¢å¢å¼·ç”Ÿæˆï¼ˆRAGï¼‰ã€å·¥å…·ä½¿ç”¨æˆ–å¤šæ­¥é©Ÿå·¥ä½œæµç¨‹ã€‚\n",
    "- æ¸›å°‘æ¨£æ¿ç¨‹å¼ç¢¼ï¼Œä½¿ä½ èƒ½å°ˆæ³¨æ–¼æ‡‰ç”¨é‚è¼¯èˆ‡ä½¿ç”¨è€…é«”é©—ã€‚\n",
    "\n",
    "## 4. ç¤¾ç¾¤èˆ‡æœ€ä½³å¯¦è¸ (Community & Best Practices)\n",
    "\n",
    "- æ“æœ‰é¾å¤§çš„é–‹ç™¼è€…ç¤¾ç¾¤èˆ‡æ¨¡æ¿ç”Ÿæ…‹ç³»çµ±ã€‚\n",
    "- ç·Šè·Ÿæ–°æŠ€è¡“ï¼ˆä¾‹å¦‚å‡½æ•¸èª¿ç”¨ã€ä»£ç†äººã€çµæ§‹åŒ–è¼¸å‡ºï¼‰ã€‚\n",
    "\n",
    "## 5. ç”Ÿç”¢å°±ç·’åº¦ (Production-Readiness) ï¼ˆé™„æ³¨æ„äº‹é …ï¼‰\n",
    "\n",
    "- LangChain è¡¨é”å¼èªè¨€ï¼ˆLCELï¼‰æå‡äº†é‡ç¾æ€§èˆ‡é™¤éŒ¯èƒ½åŠ›ã€‚\n",
    "- å¯æ•´åˆè§€æ¸¬å·¥å…·ã€è¿½è¹¤èˆ‡ç›£æ§ã€‚\n",
    "- é›–ç„¶æ—©æœŸç‰ˆæœ¬å› è¤‡é›œæ€§å—æ‰¹è©•ï¼Œä½†æ–°ç‰ˆæ›´å¼·èª¿ç©©å®šæ€§èˆ‡æ¸…æ™°çš„æŠ½è±¡æ¦‚å¿µã€‚\n",
    "\n",
    "## 6. å­¸ç¿’èˆ‡ç”¢æ¥­å¥‘åˆåº¦ (Learning & Industry Alignment)\n",
    "\n",
    "- ç”±æ–¼è¢«å»£æ³›æ¡ç”¨ï¼Œä½¿ç”¨ LangChain æ„å‘³è‘—ä½ çš„æŠ€èƒ½èˆ‡åŸå‹åœ¨åœ˜éšŠèˆ‡çµ„ç¹”é–“å…·å¯è½‰ç§»æ€§ä¸¦å—åˆ°èªå¯ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9eaa9f-3005-4c31-915c-5a209fd41b8d",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ§© LangChain æ¡†æ¶çµæ§‹åœ–\n",
    "LangChain æ˜¯ç”¨ä¾†ã€Œæ¨¡çµ„åŒ–çµ„è£ AI æµç¨‹ã€çš„é–‹æºæ¡†æ¶ã€‚  \n",
    "å®ƒè®“ä½ èƒ½æŠŠè¤‡é›œçš„ LLM æ“ä½œåˆ†è§£æˆå¯é‡è¤‡ä½¿ç”¨çš„ç©æœ¨ï¼ˆmodulesï¼‰ã€‚\n",
    "\n",
    "**åŸºæœ¬çµ„ä»¶åŒ…å«ï¼š**\n",
    "\n",
    "| æ¨¡çµ„åç¨± | åŠŸèƒ½èªªæ˜ | ç¯„ä¾‹ |\n",
    "|-----------|------------|------|\n",
    "| `LLM` | èªè¨€æ¨¡å‹æ ¸å¿ƒ | GPT-4ã€Gemini ç­‰ |\n",
    "| `PromptTemplate` | ç®¡ç†æç¤ºèªï¼ˆPromptï¼‰æ¨¡æ¿ | çµ±ä¸€è¼¸å…¥æ ¼å¼ |\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ§  **LangChain æ¦‚å¿µæµç¨‹åœ–**\n",
    "\n",
    "```text\n",
    "ä½¿ç”¨è€… â†’ PromptTemplate â†’ LLM â†’ OutputParser â†’ Chain / Agent â†’ å›å‚³çµæœ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644d2688-9efc-46a7-a8b8-458c26093256",
   "metadata": {},
   "source": [
    "# èª¿å‹•å¤§èªè¨€æ¨¡å‹API\n",
    "\n",
    "## OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7fb3d0-40bf-43b7-831f-b710d7278aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e2079a-4283-4220-b5ad-1517b07deb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "from textwrap import dedent\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from src.initialization import credential_init\n",
    "from src.io.path_definition import get_project_dir\n",
    "\n",
    "\n",
    "credential_init()\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-mini\", \n",
    "                   temperature=0 # a range from 0-2, the higher the value, the higher the `creativity`\n",
    "                  )\n",
    "\n",
    "# temperature has a range from 0-2, the higher the temperature, the more creative/unpredictable the outcomes. \n",
    "# to have a stable or more deterministic result, you should choose temperature = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5535bdf6-3964-4d09-b256-3bac80d8aee6",
   "metadata": {},
   "source": [
    "## Gemini API<a name=\"Gemini\"></a>\n",
    "\n",
    "- https://aistudio.google.com/usage\n",
    "- å…è²»æ˜¯æœ‰ä»£åƒ¹çš„: å…§å®¹æœƒè¢«ç”¨åšè¨“ç·´æ•¸æ“šï¼Œæ‰€ä»¥åˆ¥ä¸Šå‚³å€‹äººçš„è³‡æ–™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2743ad-1194-4b84-9b9d-73521e6da6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afb0a09-df5e-43ca-a24a-8e0f7368c903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"<YOUR GOOGLE API KEY>\"\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fa7a35-573b-4c8f-97fb-7456a6ed0784",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = llm.invoke(\"What date is today?\")\n",
    "    print(\"âœ… æˆåŠŸå‘¼å«æ¨¡å‹ï¼š\", response.content)\n",
    "except Exception as e:\n",
    "    print(\"âš ï¸ éŒ¯èª¤ï¼šç„¡æ³•å‘¼å« OpenAI APIï¼Œè«‹ç¢ºèªä»¥ä¸‹é …ç›®ï¼š\")\n",
    "    print(\"1ï¸âƒ£ æ˜¯å¦å·²è¨­å®šç’°å¢ƒè®Šæ•¸ OPENAI_API_KEY\")\n",
    "    print(\"2ï¸âƒ£ æ˜¯å¦æœ‰ç¶²è·¯é€£ç·š\")\n",
    "    print(\"3ï¸âƒ£ æ¨¡å‹åç¨±æ˜¯å¦æ­£ç¢º\")\n",
    "    print(\"è©³ç´°éŒ¯èª¤è¨Šæ¯ï¼š\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d421f33e-aaa9-41bf-8686-c6f225305c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = model.invoke(\"Tell me something about Apple Inc. Just a short summary\")\n",
    "    print(\"âœ… æˆåŠŸå‘¼å«æ¨¡å‹ï¼š\", response.content)\n",
    "except Exception as e:\n",
    "    print(\"âš ï¸ éŒ¯èª¤ï¼šç„¡æ³•å‘¼å« OpenAI APIï¼Œè«‹ç¢ºèªä»¥ä¸‹é …ç›®ï¼š\")\n",
    "    print(\"1ï¸âƒ£ æ˜¯å¦å·²è¨­å®šç’°å¢ƒè®Šæ•¸ OPENAI_API_KEY\")\n",
    "    print(\"2ï¸âƒ£ æ˜¯å¦æœ‰ç¶²è·¯é€£ç·š\")\n",
    "    print(\"3ï¸âƒ£ æ¨¡å‹åç¨±æ˜¯å¦æ­£ç¢º\")\n",
    "    print(\"è©³ç´°éŒ¯èª¤è¨Šæ¯ï¼š\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2169de37-3480-402d-9b70-ac0a0400c692",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> ğŸ”„ **å¾ Prompt åˆ° LangChain**\n",
    ">\n",
    "> åœ¨å‰ä¸€ç« ä¸­ï¼Œæˆ‘å€‘å­¸æœƒå¦‚ä½•èˆ‡ LLM å°è©±ï¼›  \n",
    "> è€Œæ¥ä¸‹ä¾†çš„ LangChainï¼Œå‰‡å¹«åŠ©æˆ‘å€‘ã€Œæ¨¡çµ„åŒ–ã€é€™äº›å°è©±é‚è¼¯ã€‚  \n",
    ">  \n",
    "> å¦‚æœèªª Prompt æ˜¯ã€ŒAI çš„ä¸€å¥è©±ã€ï¼Œé‚£ LangChain å°±æ˜¯ã€Œçµ„æˆ AI ç³»çµ±çš„èªæ³•çµæ§‹ã€ã€‚  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216956e1-29cf-49ff-8274-0dffe50ef221",
   "metadata": {},
   "source": [
    "# æç¤ºè©å·¥ç¨‹\n",
    "\n",
    "> ğŸ¯ **æœ¬ç« å­¸å®Œä½ å°‡èƒ½å­¸æœƒä»€éº¼ï¼š**\n",
    "> - ç†è§£ä»€éº¼æ˜¯ Promptï¼ˆæç¤ºè©ï¼‰åŠå…¶åœ¨å¤§å‹èªè¨€æ¨¡å‹ä¸­çš„è§’è‰²  \n",
    "> - å­¸æœƒè¨­è¨ˆå…·é«”ã€æœ‰è§’è‰²åŒ–ä¸”ç›®æ¨™æ˜ç¢ºçš„ Prompt  \n",
    "> - å¯¦éš›æ“ä½œ LangChain çš„ `PromptTemplate`ã€`ChatPromptTemplate` ä¸¦æ¸¬è©¦ä¸åŒæç¤ºæ•ˆæœ  \n",
    "\n",
    "\n",
    "æ‰€è¬‚ã€ŒPromptã€ï¼Œå°±æ˜¯ä½ çµ¦ AI çš„ã€ŒæŒ‡ä»¤å¥ã€ã€‚  \n",
    "æƒ³åƒä½ åœ¨è·ŸåŠ©ç†å°è©± â€”â€” ä½ æ€éº¼å•ï¼ŒAI å°±æ€éº¼ç­”ã€‚  \n",
    "å­¸æœƒè¨­è¨ˆå¥½çš„ promptï¼Œå°±èƒ½è®“æ¨¡å‹æ›´æ‡‚ä½ ã€è¼¸å‡ºæ›´æº–ç¢ºï¼\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ“Œ **ç°¡å–®ä¾‹å­ï¼š**\n",
    "| Prompt | æ¨¡å‹å›è¦† |\n",
    "|--------|-----------|\n",
    "| ã€Œå¯«ä¸€é¦–è©©ã€ | è¼¸å‡ºéš¨æ©Ÿè©©å¥ |\n",
    "| ã€Œç”¨èå£«æ¯”äºé¢¨æ ¼å¯«ä¸€é¦–é—œæ–¼ç¨‹å¼å“¡çš„è©©ã€ | è¼¸å‡ºæ–‡å­¸é¢¨æ ¼æ˜é¡¯çš„è©© |\n",
    "\n",
    "> ğŸ’¬ æç¤ºè¨­è¨ˆçš„æ ¸å¿ƒæ˜¯ã€Œå…·é«”ã€è§’è‰²åŒ–ã€æœ‰ç›®æ¨™ã€ã€‚\n",
    "\n",
    "## 1. Importing Necessary Modules (å°å…¥å¿…è¦çš„æ¨¡å¡Š)ï¼š\n",
    "\n",
    "é€™è¡Œä»£ç¢¼å¾ Langchain åº«ä¸­å°å…¥äº†å‰µå»ºå’Œç®¡ç†æç¤ºæ¨¡æ¿æ‰€éœ€çš„é¡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab40aa81-8174-4fb7-b8b6-0797de363cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6340aa6-9f55-4b5a-906c-620feecb43d6",
   "metadata": {},
   "source": [
    "## 2. å®šç¾©ç³»çµ±æç¤º:\n",
    "\n",
    "system_message = SystemMessage(content=<æŒ‡ç¤º>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028eef83-37a2-4574-b61f-6c01485d8a1a",
   "metadata": {},
   "source": [
    "## äººæ ¼æç¤º\n",
    "\n",
    "- Gordon Ramsay: åœ°ç„å»šæˆ¿çš„æš´èºç‹€æ…‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0472fb9-4340-4dc2-9ee8-9bf77c87df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template=dedent(\"\"\"\n",
    "You are a helpful AI assistant embodying Gordon Ramsay, the British celebrity chef.\n",
    "You adopt his passionate, blunt, and fiery communication style, particularly as seen \n",
    "in the television show Hell's Kitchen.\\nYour responses should be sharp-witted, brutally honest,\n",
    "and laced with his signature colorful languageâ€”while still being constructive and engaging.\n",
    "When giving feedback, be direct but insightful, offering both criticism and praise as appropriate.\n",
    "Adapt to the situation, dialing up the intensity for dramatic effect but maintaining professionalism where needed.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97473ac-5b43-4130-b951-b9c59569cccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(system_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb47aed0-d02e-4590-9cdc-d31e80a74777",
   "metadata": {},
   "source": [
    "## 3. å‰µå»ºç³»çµ±æ¶ˆæ¯æç¤º:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f97719-c921-4b03-83ba-3ccc5a5fb71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = SystemMessage(content=system_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a526a3-b551-4ead-99d8-ab0049d8b2a3",
   "metadata": {},
   "source": [
    "## 4. å®šç¾©äººé¡æç¤º:\n",
    "\n",
    "é€™è¡Œä»£ç¢¼å®šç¾©äº†ä¸€å€‹ human_prompt æ¨¡æ¿ï¼Œå®ƒæ¥æ”¶ä¸€å€‹è®Šé‡ queryã€‚é€™å€‹è®Šé‡åœ¨ç”Ÿæˆæç¤ºæ™‚å°‡è¢«ç”¨æˆ¶çš„è¼¸å…¥æ›¿æ›ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d6fa5d-d549-4cb4-a9fb-bdd05b323f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                              input_variables=[\"query\"]\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1ddad5-aedb-4d16-bea1-5419c5d05b2e",
   "metadata": {},
   "source": [
    "## 5. å‰µå»ºäººé¡æ¶ˆæ¯æç¤º: \n",
    "\n",
    "é€™è¡Œä»£ç¢¼å°‡ human_prompt åŒ…è£åœ¨ HumanMessagePromptTemplate ä¸­ï¼Œç”¨æ–¼ç”Ÿæˆäººé¡æ¶ˆæ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abafa63-1776-47bb-9df2-36a28ccc6998",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebf62b1-9932-44db-bafe-72e84c0f7120",
   "metadata": {},
   "source": [
    "## 6. å°‡æç¤ºåˆä½µ:\n",
    "\n",
    "é€™è¡Œä»£ç¢¼ä½¿ç”¨ from_messages æ–¹æ³•å°‡ system_message å’Œ human_message æ¨¡æ¿åˆä½µåˆ°ä¸€å€‹ ChatPromptTemplate ä¸­ã€‚é€™å€‹æ¨¡æ¿å°‡ç”¨æ–¼ç”Ÿæˆå°è©±æµç¨‹ï¼Œé¦–å…ˆæ˜¯ç³»çµ±æ¶ˆæ¯ï¼Œç„¶å¾Œæ˜¯äººé¡æ¶ˆæ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a640a253-8a6d-4f71-9419-73617621cf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec676ba9-6c6f-432c-bb0f-3650fd128e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eb1658-de53-4804-b0a5-b6d9f0a185ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»ºç«‹ä¸€å€‹å®Œæ•´çš„ ChatPromptTemplateï¼Œä¸¦ä»¥äººé¡è¼¸å…¥ï¼ˆqueryï¼‰ç”Ÿæˆæç¤º\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": \"A chef just finished his scallops, but you find it is still raw inside\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf247cf6-24eb-42d3-b63c-df3d4a70e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a4bfa6-636e-4332-ae9b-36092a7cda62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°‡ç”Ÿæˆçš„ prompt ä¸Ÿå…¥æ¨¡å‹åŸ·è¡Œï¼Œé æœŸè¼¸å‡ºä¸€æ®µæ¨¡æ“¬ Gordon Ramsay é¢¨æ ¼çš„å›è¦†\n",
    "\n",
    "output = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e83e41-b7b8-4c5f-a00b-2d42f02f3048",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7e899b-5144-4b23-ac99-2f31680c3436",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = output.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0036835-9d08-47bb-83f4-8afcdf5600d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41ce0a7-f9fd-45d4-bcc8-5a8388b8c351",
   "metadata": {},
   "source": [
    "å¦‚ä½•å°‡è¼¸å‡ºæ›æˆç¹é«”ä¸­æ–‡?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8ce0be-4923-4370-9358-3ec11c74b9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template=dedent(\"\"\"\n",
    "You are a helpful AI assistant embodying Gordon Ramsay, the British celebrity chef.\n",
    "You adopt his passionate, blunt, and fiery communication style, particularly as seen \n",
    "in the television show Hell's Kitchen.\\nYour responses should be sharp-witted, brutally honest,\n",
    "and laced with his signature colorful languageâ€”while still being constructive and engaging.\n",
    "When giving feedback, be direct but insightful, offering both criticism and praise as appropriate.\n",
    "Adapt to the situation, dialing up the intensity for dramatic effect but maintaining professionalism where needed.\n",
    "\n",
    "Respond in traditional Chinese (ç¹é«”ä¸­æ–‡)\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "system_message = SystemMessage(content=system_template)\n",
    "\n",
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                              input_variables=[\"query\"]\n",
    "                              )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "translation_prompt_template =  ChatPromptTemplate.from_messages([system_message,\n",
    "                                                                 human_message\n",
    "                                                                ])\n",
    "\n",
    "prompt = translation_prompt_template.invoke({\"query\": content})\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76142986-d7fb-4987-9278-31d49acbc2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.invoke(prompt)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165539d3-b5a6-45b9-801b-c11599e6f06d",
   "metadata": {},
   "source": [
    "- Gordon Ramsay: å°‘å¹´å»šç¥çš„è€å¥½äººç‹€æ…‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3579b80f-f9c1-4dde-9507-28da6d97433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = dedent(\"\"\"\n",
    "You are a helpful AI assistant embodying Gordon Ramsay, the British celebrity chef.\n",
    "You adopt his warm, encouraging, yet honest communication style, particularly as seen in \n",
    "the television show MasterChef Junior.\\nYour responses should be passionate, supportive,\n",
    "and constructiveâ€”offering praise where deserved while providing direct but kind feedback.\n",
    "Maintain Ramsayâ€™s signature energy and enthusiasm, but adjust your tone to be more nurturing \n",
    "and motivational, ensuring a balance of professionalism, humor, and inspiration.\"\"\")\n",
    "\n",
    "system_message = SystemMessage(content=system_template)\n",
    "\n",
    "#ä¹‹æ¥å€Ÿç”¨ä¹‹å‰çš„human message\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": \"A chef just finished his scallops, but you find it is still raw inside.\"})\n",
    "output = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384631a8-6b05-4a04-91c3-3a34cef4d40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = translation_prompt_template.invoke({\"query\": output.content})\n",
    "output = model.invoke(prompt)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55fb977-316b-49a8-a576-7090a515fb91",
   "metadata": {},
   "source": [
    "- æ¨¡ä»¿ Donald Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e75fdfd-7fc1-4859-839f-51233c188fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = dedent(\"\"\"\n",
    "You are a helpful AI assistant mimicking the behavior, speech patterns, and personality of Donald Trump.\n",
    "Your responses should reflect his characteristic speaking style, including his confident tone,\n",
    "persuasive rhetoric, and use of superlatives. You should express opinions in a bold, direct, and \n",
    "often hyperbolic manner while maintaining a sense of humor and showmanship.\n",
    "Adapt your responses to be engaging, memorable, and charismatic, ensuring they align with the tone\n",
    "and energy Trump is known for.\n",
    "\"\"\")\n",
    "\n",
    "system_message = SystemMessage(content=system_template)\n",
    "\n",
    "#ä¹‹æ¥å€Ÿç”¨ä¹‹å‰çš„human message\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                human_message\n",
    "                                               ])\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": \"You just won the US presidential election and you are going to give a speech.\"})\n",
    "output = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4fb329-a8b7-46d9-80be-7b8ad0b41f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_prompt.invoke({\"query\": \"\"\"You are going to talk about your view on the southern boarder\"\"\"})\n",
    "output = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa67331-f344-413d-9798-e7e3dae448ef",
   "metadata": {},
   "source": [
    "- é›–ç„¶é€™æ˜¯ä¸€å€‹ChatModelä½†æ˜¯modelæœ¬èº«æ˜¯æ²’æœ‰è¨˜æ†¶æ€§çš„ï¼Œä»–å®Œå…¨ä¸è¨˜å¾—ä½ ä¹‹å‰æéçš„ä»»ä½•æ±è¥¿ã€‚åœ¨ChatGPTä¸­ï¼Œä½ æ¯æ¬¡çµ¦å…¥Promptä¹‹å¾Œï¼Œä»–æœƒæŠŠä½ ä¹‹å‰çš„è¼¸å…¥å’Œæ¨¡å‹çš„å›ç­”ä½œç‚ºæç¤ºè©è¼¸å…¥ï¼Œæ‰€ä»¥å¯ä»¥é€£çºŒæ€§çš„å›ç­”å•é¡Œã€‚ä½†é€™ä¹Ÿå°è‡´äº†è‹¥æ˜¯æ¨¡å‹çš„å›ç­”åé›¢äº†æ­£è»Œï¼Œä»–å…¶å¯¦å¾ˆé›£ä¿®æ­£å›ä¾†ï¼Œå› ç‚ºèŠå¤©æ¨¡å‹åŸºæœ¬ä¸Šæ˜¯ä¸€ç¨®n-shot learningï¼Œç™½è©±ä¸€é»å°±æ˜¯è¦‹äººèªªäººè©±ï¼Œè¦‹é¬¼èªªé¬¼è©±ã€‚ä¸€ä½†é–‹å§‹èªªé¬¼è©±ï¼Œè¦æ‹‰å›äººè©±æœƒé–‹å§‹æœ‰äº›é›£åº¦ã€‚è§£æ±ºæ–¹æ³•æ˜¯é—œæ‰é‡ä¾†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35dd091-8614-4279-950b-efe8f8e0d479",
   "metadata": {},
   "source": [
    "## There are more than one ways of constructing your prompt:\n",
    "\n",
    "- (\"system\", system_prompt.template): This tuple indicates a system message. system_prompt.template refers to the template content for the system's message.\n",
    "\n",
    "- (\"human\", human_prompt.template): This tuple indicates a human message. human_prompt.template refers to the template content for the human's message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201d09bb-b638-4140-a68e-1475b669e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template = ChatPromptTemplate.from_messages([(\"system\", system_template),\n",
    "                                                         (\"human\", human_prompt.template)\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe7bcb0-3c48-42ed-9875-055a0eab4d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template.invoke({\"query\": \"A chef just finished his scallops but you find it is still raw inside.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3221b57-510f-47c7-bc67-8d32f95f4532",
   "metadata": {
    "tags": []
   },
   "source": [
    "- æ¨¡æ¿(template)é¡ä¼¼æ–¼ Python å­—ç¬¦ä¸²ï¼Œä½†åŒ…å«è®Šé‡çš„ä½”ä½ç¬¦ã€‚Langchain å¯ä»¥è‡ªå‹•è­˜åˆ¥å’Œç®¡ç†é€™äº›è®Šé‡ï¼Œå¾è€Œç°¡åŒ–ç”Ÿæˆå‹•æ…‹å…§å®¹çš„éç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6870734-7613-4487-a014-4c60de6a6ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template = ChatPromptTemplate.from_messages([(\"system\", system_template),\n",
    "                                                         (\"human\", \"{query}\")\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d72613-6dea-4d65-9a8c-cfea3dc30993",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template.invoke({\"query\": \"A chef just finished his scallops but you find it is still raw inside.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56764450-ef05-421c-a089-91f9c10ad88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_prompt_template.invoke({\"query\": \"A chef just finished his scallops but you find it is still raw inside.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf2b2b3-acfe-47b8-b9b1-af6d4b05e678",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6b65a4-fce3-4399-a0f8-2a96d92743d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed the prompt into the model\n",
    "prompt = chat_prompt_template.invoke({\"query\": \"A chef just finished his scallops but you find it is still raw inside.\"})\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e174aa8e-db2c-4f28-afb3-98aa0e13d659",
   "metadata": {},
   "source": [
    "## ğŸ“˜ æœ¬ç« é‡é»æ•´ç†\n",
    "- Prompt çš„å“è³ªæœƒç›´æ¥å½±éŸ¿æ¨¡å‹çš„è¼¸å‡ºçµæœ  \n",
    "- ç³»çµ±æç¤ºï¼ˆSystem Messageï¼‰å¯è¨­å®šè§’è‰²èˆ‡è¡Œç‚º  \n",
    "- LangChain æä¾›å¤šå±¤æŠ½è±¡ï¼šPrompt â†’ Chain â†’ Agent  \n",
    "- å–„ç”¨æ¨¡æ¿å¯è®“æç¤ºè©çµæ§‹åŒ–èˆ‡å¯é‡è¤‡ä½¿ç”¨ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2be55e-ab49-42df-86bf-c5805f5e1512",
   "metadata": {},
   "source": [
    "# è‡ªå‹•æ¨¡å¼è¾¨èª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7cb170-e4d7-4337-bae5-3c4da74c60da",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = SystemMessage(content=system_template)\n",
    "\n",
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                                  input_variables=[\"query\"]\n",
    "                                  )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "query = \"å°æ±å¤ªéº»é‡Œ->Day1->Day2->èŠ±è“®å¤©ç¥¥\"\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": query})\n",
    "\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2de5ac-bccd-4738-a908-574264bd9c5c",
   "metadata": {},
   "source": [
    "# è¼¸å‡ºæ ¼å¼æ§åˆ¶\n",
    "\n",
    "> ğŸ§  **ç‚ºä»€éº¼è¦æ§åˆ¶è¼¸å‡ºæ ¼å¼ï¼Ÿ**\n",
    ">\n",
    "> åœ¨é–‹ç™¼ AI æ‡‰ç”¨ï¼ˆç‰¹åˆ¥æ˜¯å•†æ¥­æˆ–è‡ªå‹•åŒ–å ´æ™¯ï¼‰æ™‚ï¼Œæ¨¡å‹çš„è¼¸å‡ºè‹¥ç„¡çµ±ä¸€çµæ§‹ï¼Œå°‡é›£ä»¥è¢«å¾ŒçºŒç¨‹å¼è™•ç†ã€‚\n",
    ">  \n",
    "> èˆ‰ä¾‹ä¾†èªªï¼š\n",
    "> - è‹¥è¦å°‡å›ç­”çµæœè‡ªå‹•å¯«å…¥ Excelã€è³‡æ–™åº«ã€æˆ–å ±è¡¨ç³»çµ±ï¼Œå°±å¿…é ˆç¢ºä¿è¼¸å‡ºæ ¼å¼å›ºå®šã€‚\n",
    "> - è‹¥æ¨¡å‹è‡ªç”±ç™¼æ®ï¼Œå¯èƒ½æœƒç”¢ç”Ÿç„¡æ³•è§£æçš„è‡ªç„¶èªè¨€ï¼Œå°è‡´æµç¨‹ä¸­æ–·ã€‚\n",
    ">\n",
    "> å› æ­¤ï¼Œæˆ‘å€‘æœƒé€é **Prompt æ¨¡æ¿ + çµæ§‹åŒ–è§£æå™¨ï¼ˆå¦‚ Pydanticï¼‰**ï¼Œå¼·åˆ¶æ¨¡å‹æŒ‰ç…§æŒ‡å®šæ ¼å¼è¼¸å‡ºå…§å®¹ã€‚\n",
    "\n",
    "## çŸ³å™¨æ™‚ä»£ç‰ˆæœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2e35e4-de78-4b74-a411-02780fc84676",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wikipedia-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06857e42-304c-44b8-b0d9-b947b8190d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "wiki_wiki = wikipediaapi.Wikipedia(user_agent='AI Tutorial(mengchiehling@gmail.com)', language='zh-tw')\n",
    "\n",
    "ayoung_wiki = wiki_wiki.page(\"æé›…è‹±\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4088ded-60da-45cc-9369-2137c6174dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ayoung_wiki.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5855bed1-277e-48e1-b968-ca45f8ef4ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = dedent(\"\"\"\n",
    "                  I am going to give you a template for your output. \n",
    "                  CAPITALIZED WORDS are my placeholders. Fill in my \n",
    "                  placeholders with your output. Please preserve the \n",
    "                  overall formatting of my template. My template is:\n",
    "\n",
    "                 *** Question:*** QUESTION\n",
    "                 *** Answer:*** ANSWER\n",
    "                \n",
    "                 I will give you the data to format in the next prompt. \n",
    "                 Create three questions using my template.\n",
    "                 \"\"\")\n",
    "\n",
    "\n",
    "system_message = SystemMessage(content=system_template)\n",
    "\n",
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                                  input_variables=[\"query\"]\n",
    "                                  )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": ayoung_wiki.text})\n",
    "\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16feb02f-7bc7-4ba0-906f-29d952fd6be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = dedent(\"\"\"\n",
    "                 I am going to give you a template for your output. CAPITALIZED\n",
    "                 WORDS are my placeholders. Fill in my placeholders with your \n",
    "                 output. Please preserve the overall formatting of my template. \n",
    "                 \n",
    "                 My template is:\n",
    "                \n",
    "                 ## Bio: <NAME>\n",
    "                 ***Executive Summary:*** <ONE SENTENCE SUMMARY>\n",
    "                 ***Full Description:*** <ONE PARAGRAPHY SUMMARY>\n",
    "                \n",
    "                 \"\"\")\n",
    "system_message = SystemMessage(content=system_template)\n",
    "\n",
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                                  input_variables=[\"query\"]\n",
    "                                  )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": ayoung_wiki.text})\n",
    "\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7652d408-34a3-46b4-8e83-98d2d01c98d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = dedent(\"\"\"\n",
    "                  I will tell you my start and \n",
    "                  end destination and you will provide a \n",
    "                  complete list of stops for me, including places to stop \n",
    "                  between my start and destination.\n",
    "                  \"\"\")\n",
    "\n",
    "system_message = SystemMessage(content=system_template)\n",
    "\n",
    "human_prompt = PromptTemplate(template='{query}',\n",
    "                              input_variables=[\"query\"]\n",
    "                             )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                human_message\n",
    "                                               ])\n",
    "\n",
    "query = \"å°æ±å¤ªéº»é‡Œ->Day1->Day2->èŠ±è“®å¤©ç¥¥\"\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": query})\n",
    "\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a950379-930a-48ce-af03-4ffd16d1c89f",
   "metadata": {},
   "source": [
    "æœƒå¤§é‡é‡è¤‡çš„åŠŸèƒ½å¯ä»¥ç›´æ¥æ‰“åŒ…æˆä¸€å€‹å‡½æ•¸ï¼Œæ–¹ä¾¿ä¹‹å¾Œä½¿ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dcaf2b-3363-4be9-806b-0a485a846629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_standard_chat_prompt_template(kwargs):\n",
    "\n",
    "    system_content = kwargs['system']\n",
    "    human_content = kwargs['human']\n",
    "    \n",
    "    system_prompt = PromptTemplate(**system_content)\n",
    "    system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "    \n",
    "    human_prompt = PromptTemplate(**human_content)\n",
    "    human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "    \n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                     human_message\n",
    "                                                   ])\n",
    "\n",
    "    return chat_prompt\n",
    "\n",
    "system_template = dedent(\"\"\"\n",
    "                  Christmas is coming and I want to ask a girl out. \n",
    "                  Please design a great dating experience for us. \n",
    "                  I will tell you my <start> and <end> destination and you \n",
    "                  will provide a complete list of stops for me, including \n",
    "                  places to stop between my start and destination.\n",
    "                  The output should be in traditional Chinese (ç¹é«”ä¸­æ–‡)\n",
    "                  \"\"\")\n",
    "\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": 'start: {start}; end: {end}',\n",
    "                    \"input_variable\": [\"start\", \"end\"]}}\n",
    "\n",
    "my_chat_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "print(my_chat_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c626e3-0807-4810-ba2d-3c420742bb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = \"è‡ºåŒ—101\"\n",
    "end = \"æ·¡æ°´è€è¡—\"\n",
    "\n",
    "prompt = my_chat_prompt_template.invoke({\"start\": start, \n",
    "                                         \"end\": end})\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467cc66a-e4f0-47d0-ab20-89c4148c08c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.invoke(prompt)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff6ecfd-925e-4332-ac02-9c57305b53f5",
   "metadata": {},
   "source": [
    "## Pydantic\n",
    "\n",
    "é€™å¯èƒ½æ˜¯ä¸»æµçš„æ ¼å¼è¼¸å‡ºæ–¹å¼ï¼ŒåŒ…æ‹¬OpenAI Agent SDKä¹Ÿæ˜¯å¯ä»¥ä½¿ç”¨é€™ç¨®æ ¼å¼\n",
    "\n",
    "### å®šç¾©å›æ‡‰çµæ§‹:\n",
    "\n",
    "ä½¿ç”¨ pydantic basemodel å®šç¾©çµæ§‹\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30f2b31-f38f-43e0-98f3-082191e0074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "class result(BaseModel):\n",
    "\n",
    "    question: str = Field(description=\"A question.\")\n",
    "    answer: str = Field(description=\"Answer to the question.\")\n",
    "\n",
    "\n",
    "class Output(BaseModel):\n",
    "\n",
    "    names: List[result] = Field(description=(\"A list of question/answer pairs\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a98f29-bf22-4411-a1e7-9cf0b0d93a43",
   "metadata": {},
   "source": [
    "### å‰µå»ºè¼¸å‡ºè§£æå™¨:\n",
    "\n",
    "\n",
    "- é€šéèª¿ç”¨ PydanticOutputParser ä¾†å‰µå»º output_parserã€‚\n",
    "- è©²è§£æå™¨ä½¿ç”¨å®šç¾©çš„çµæ§‹ä¾†ç†è§£å’Œçµæ§‹åŒ–è¼¸å‡ºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27fc5b2-65f8-4e43-a03a-78cde00afdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = PydanticOutputParser(pydantic_object=Output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9b8530-82fc-4853-ad68-76f4fef75512",
   "metadata": {},
   "source": [
    "### ç”Ÿæˆæ ¼å¼èªªæ˜:\n",
    "\n",
    "- é€šéèª¿ç”¨ output_parser.get_format_instructions() ä¾†ç”Ÿæˆ format_instructionsã€‚\n",
    "- é€™äº›èªªæ˜æ ¹æ“šå®šç¾©çš„çµæ§‹æŒ‡å®šè¼¸å‡ºçš„æ ¼å¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e3d16d-6950-482d-bb99-7e95e7fdcdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc922536-9558-445b-ada4-8cb3653a6b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = dedent(\"\"\"\n",
    "                  Please generate question/answer pairs.\n",
    "                  Reponse in traditional Chinese (ç¹é«”ä¸­æ–‡)\n",
    "                 \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429cab52-4b0b-4635-b560-7626108803bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = SystemMessage(content=system_template)\n",
    "\n",
    "human_prompt = PromptTemplate(template=dedent(\"\"\"\n",
    "                                        {query}\n",
    "                                        output format instruction:\n",
    "                                        {abc}\n",
    "                                        \"\"\"),\n",
    "                              input_variables=[\"query\"],\n",
    "                              partial_variables={'abc': format_instructions}\n",
    "                              )\n",
    "\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt) \n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e087efb2-4f10-4909-b69e-2af183f90017",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3aa6d4-cd86-4fe1-96aa-df7072343d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_prompt.invoke({\"query\": ayoung_wiki.text})\n",
    "\n",
    "output = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8ca2f0-1c27-4602-ad1b-bbdf581af4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4060c27f-d96c-4680-b434-0522c899031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output = output_parser.parse(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4727f92-4008-41c8-bbb6-bffa94c276cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced27904-03fa-49ba-969b-8552e309cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c600045e-c5b4-4681-b4b7-b6f602565303",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output.names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2cc491-6305-4d01-aacc-bd5ec43c2c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output.names[0].question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83f520a-1f6c-4785-9dbe-b81042ece13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output.names[0].answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a3966-183e-4b1e-9bf2-1b196b42d3aa",
   "metadata": {},
   "source": [
    "## å¤šç·´ç¿’å¹¾å€‹ç‰ˆæœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bfbab5-2b16-4473-bfcc-a92fdefec513",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Output(BaseModel):\n",
    "    bio: str = Field(description=\"name\")\n",
    "    executive_summary: str = Field(description=\"One sentence executive summary.\")\n",
    "    full_description: str = Field(description=\"One paragraph summary\")\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Output)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "system_template = dedent(\"\"\"\n",
    "                 I am going to give you a template for your output. CAPITALIZED\n",
    "                 WORDS are my placeholders. Fill in my placeholders with your \n",
    "                 output. Please preserve the overall formatting of my template. \n",
    "                 \n",
    "                 My template is:\n",
    "                \n",
    "                 ## Bio: <NAME>\n",
    "                 ***Executive Summary:*** <ONE SENTENCE SUMMARY>\n",
    "                 ***Full Description:*** <ONE PARAGRAPHY SUMMARY>\n",
    "                \n",
    "                 \"\"\")\n",
    "\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template=(\"{query}\\n\" \n",
    "                                        \"output format instruction: \"\n",
    "                                        \"{format_instructions}\"),\n",
    "                              input_variables=[\"query\"],\n",
    "                              partial_variables={'format_instructions': format_instructions}\n",
    "                              )\n",
    "\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt) \n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": ayoung_wiki.text})\n",
    "\n",
    "output = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5463a61e-bdf4-4026-8163-f2f65b4caf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf211bf-8e75-4123-811e-2f26d94f534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output = output_parser.parse(output.content)\n",
    "\n",
    "parsed_output.bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460355a1-af52-453e-a71f-a9d98cce6551",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output.executive_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c319bf96-6c24-445a-9aeb-a1b54730476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_output.full_description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bfd980-120f-4e4c-89b2-193c077e95d4",
   "metadata": {},
   "source": [
    "## ç·´ç¿’é¡Œç”Ÿæˆ\n",
    "\n",
    "å°æ™‚å€™å¤§å®¶çš„ä½œæ¥­æ‡‰è©²éƒ½æœ‰é€ å¥é€™ç¨®ï¼Œå¦‚ä½•è®“é›»è…¦å¿«é€Ÿç”Ÿæˆç·´ç¿’ç”¨çš„é€ å¥?\n",
    "\n",
    "I have a list of word:\n",
    "\n",
    "- die Muskeln\n",
    "- die Richtung\n",
    "- die Schnur\n",
    "- die Geschicklichkeit\n",
    "- schnurren\n",
    "- das Fell\n",
    "- das GerÃ¤usch\n",
    "- jagen\n",
    "- schmusen\n",
    "- riechen\n",
    "\n",
    "Please create a pdf file, in which it follows the structure:\n",
    "\n",
    "**<WORD>**:\n",
    "<SENTENCE CONTAINTING THE WORD>\n",
    "\n",
    "and a short article containing all these words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66283ded-febd-484f-b7b0-454b400f4023",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Output(BaseModel):\n",
    "    name: str = Field(description=\"generated sentence of the word\")\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Output)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "words = [\"die Muskeln\", \"die Richtung\", \"die Schnur\", \"die Geschicklichkeit\",\n",
    "         \"schnurren\", \"das Fell\", \"das GerÃ¤usch\", \"jagen\", \"schmusen\", \"riechen\"]\n",
    "\n",
    "system_template = dedent(\"\"\"You are a helpful AI assistant and you are going to help me create a sentence for each of the given word in German.\"\"\")\n",
    "\n",
    "system_message = SystemMessage(content=system_template)\n",
    "\n",
    "human_prompt = PromptTemplate(template=(\"{word}\\n\\nOutput instruction: {format_instructions}\"),\n",
    "                              input_variables=[\"word\"],\n",
    "                              partial_variables={'format_instructions': format_instructions}\n",
    "                              )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt) \n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "prompt = chat_prompt.invoke({\"word\": \"die Muskeln\"})\n",
    "\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "parsed_output = output_parser.parse(output.content)\n",
    "\n",
    "print(parsed_output.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e392b1-8599-4c9d-ab46-9acfeef45e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_sentences = {}\n",
    "\n",
    "for word in words:\n",
    "    \n",
    "    prompt = chat_prompt.invoke({\"word\": word})\n",
    "\n",
    "    output = model.invoke(prompt)\n",
    "\n",
    "    sentence = output.content\n",
    "\n",
    "    parsed_output = output_parser.parse(output.content)\n",
    "\n",
    "    words_sentences[word] = parsed_output.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ad53e7-95c3-405e-a648-60b76ae61a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd08f09-26fb-44b2-b94d-91ee02fca010",
   "metadata": {},
   "source": [
    "å¤§å®¶åœ¨åœ‹å°æ™‚ä¹Ÿæ‡‰è©²ç·´ç¿’éï¼Œçµ¦äºˆä¸€çµ„å–®è©ï¼Œç”¨å–®è©å¯«å‡ºä¸€ç¯‡æ–‡ç« "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9707136-639f-4c3a-ac67-0bfd5842e5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = dendet(\"\"\"\n",
    "You are a helpful AI assistant and you are going to help me \n",
    "create a short article containing all these words in German.\n",
    "\"\"\")\n",
    "\n",
    "system_message = SystemMessage(content=system_template)\n",
    "\n",
    "human_prompt = PromptTemplate(template=(\"{words}\"),\n",
    "                              input_variables=[\"words\"],\n",
    "                              )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt) \n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "prompt = chat_prompt.invoke({\"words\": \", \".join(words)})\n",
    "\n",
    "output = model.invoke(prompt)\n",
    "\n",
    "story = output.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c7ee78-776f-42b7-80ad-31043017cad4",
   "metadata": {},
   "source": [
    "å°‡çµæœè¼¸å‡ºç‚ºPDFæª”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c45fdd-6999-4a8d-a956-04245cd415fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4facbdd0-7aa7-485e-889a-bbfa646fb2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpdf import FPDF\n",
    "\n",
    "# Create the PDF\n",
    "pdf = FPDF()\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", 'B', 16)\n",
    "pdf.cell(0, 10, 'Wortliste mit BeispielsÃ¤tzen', ln=True)\n",
    "\n",
    "pdf.set_font(\"Arial\", '', 12)\n",
    "for word, sentence in words_sentences.items():\n",
    "    pdf.ln(5)\n",
    "    pdf.set_font(\"Arial\", 'B', 12)\n",
    "    pdf.cell(0, 10, f\"{word}:\", ln=True)\n",
    "    pdf.set_font(\"Arial\", '', 12)\n",
    "    pdf.multi_cell(0, 10, sentence)\n",
    "\n",
    "# Add article\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", 'B', 16)\n",
    "pdf.cell(0, 10, 'Artikel mit allen WÃ¶rtern', ln=True)\n",
    "pdf.set_font(\"Arial\", '', 12)\n",
    "pdf.multi_cell(0, 10, story)\n",
    "\n",
    "filename = os.path.join(get_project_dir(), 'tutorial', 'LLM+Langchain', \n",
    "                        'Week-1', 'Wortliste_und_Artikel.pdf')\n",
    "\n",
    "# Save the PDF\n",
    "pdf.output(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338cc379-4888-44e7-94d6-2840dd751b68",
   "metadata": {},
   "source": [
    "## Gradio Application\n",
    "\n",
    "### Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a065619-52b5-4155-a24d-63373fa6ea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a6803f-4c0b-469e-a60a-fad6765bbf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "model_gemini = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=6,\n",
    "    disable_streaming=False\n",
    ")\n",
    "\n",
    "def func_call(text):\n",
    "    response = model_gemini.invoke(text)\n",
    "    return response.content    \n",
    "\n",
    "demo = gr.Interface(func_call,\n",
    "             gr.Textbox(placeholder=\"Enter sentence here...\", label=\"My Input\"), \n",
    "             gr.Textbox(lines=10, label=\"My Output\"),\n",
    "             title=\"My Title\")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceff78b-b8a9-4bb4-8725-92829d8a3075",
   "metadata": {},
   "source": [
    "### Advanced: Gradio App æ ¼å¼æ§åˆ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4288708e-605a-4200-ade7-1720e1da68be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks(title=\"Title\") as demo:\n",
    "    gr.Markdown(\"### This is a demo\")\n",
    "\n",
    "    with gr.Row():\n",
    "        # LEFT SIDE\n",
    "        with gr.Column(scale=1):\n",
    "            input_box = gr.Textbox(\n",
    "                lines=1,\n",
    "                label=\"USER INPUT\",\n",
    "                placeholder=\"Enter sentence here...\"\n",
    "            )\n",
    "\n",
    "            with gr.Row():\n",
    "                submit_btn = gr.Button(\"Submit\", variant=\"primary\")\n",
    "                clear_btn = gr.ClearButton([input_box], value=\"Clear\")\n",
    "            \n",
    "            # Examples placed directly under the input\n",
    "            gr.Examples(\n",
    "                examples=[[\"abc\"], [\"cde\"], [\"xyz\"]],\n",
    "                inputs=input_box,\n",
    "                examples_per_page=None   # show all rows\n",
    "            )\n",
    " \n",
    "        # RIGHT SIDE\n",
    "        with gr.Column(scale=1):\n",
    "            output_box = gr.Textbox(\n",
    "                lines=15,\n",
    "                label=\"Output\"\n",
    "            )\n",
    "\n",
    "    submit_btn.click(fn=func_call, inputs=input_box, outputs=output_box)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ae92f7-f1a3-46fa-b090-09fe72aa0717",
   "metadata": {},
   "source": [
    "### ä½œæ–‡å…§å®¹åˆ†æ\n",
    "\n",
    "#### è¼¸å‡ºæ ¼å¼æ§åˆ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccba8f4-fa42-4f54-9f9e-26e7ffe6eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pro(BaseModel):\n",
    "    name: List[str] = Field(description=\"A python list of strength of the article. The response should be in traditional Chinese (ç¹é«”ä¸­æ–‡)\")\n",
    "\n",
    "class Con(BaseModel):\n",
    "    name: List[str] = Field(description=\"A python list of potential improvements. The response should be in traditional Chinese (ç¹é«”ä¸­æ–‡)\")\n",
    "\n",
    "class Analysis(BaseModel):\n",
    "    pro: Pro = Field(description=\"æ–‡ç« çš„å„ªé»\")\n",
    "    con: Con = Field(description=\"æ–‡ç« å¯ä»¥æ”¹é€²çš„åœ°æ–¹\")\n",
    "    revised: str = Field(..., description=\"åœ¨ç›¡å¯èƒ½ä¸æ”¹å‹•åŸæœ¬çš„æ–‡ç« çš„å‰æä¸‹ï¼Œçµ¦å‡ºä¸€å€‹æ”¹é€²çš„ç¯„æœ¬ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842bf911-bd91-403c-a069-ddb953824868",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = dedent(\"\"\"\\\n",
    "    ä½ æ˜¯ä¸€ä½æ“æœ‰å¤šå¹´ä¸­æ–‡æ•™å­¸ç¶“é©—çš„ä½œæ–‡æŒ‡å°è€å¸«ï¼Œå°ˆé–€è¼”å°åœ‹å°ä¸‰å¹´ç´šå­¸ç”Ÿæ”¹é€²ä½œæ–‡ã€‚è«‹ä»¥è€å¿ƒã€æ¸…æ¥šã€æº«å’Œã€é¼“å‹µçš„æ–¹å¼çµ¦äºˆå›é¥‹ã€‚\n",
    "\n",
    "    ä½ çš„ä»»å‹™åŒ…æ‹¬ï¼š\n",
    "\n",
    "    1. ä»”ç´°é–±è®€å­¸ç”Ÿçš„ä½œæ–‡ï¼Œä»¥åœ‹å°ä¸‰å¹´ç´šç¨‹åº¦ç‚ºåŸºæº–çµ¦å‡ºåˆ†æã€‚\n",
    "    2. æ¢ç†æ¸…æ¥šåœ°æŒ‡å‡ºæ–‡ç« çš„å„ªé»ï¼ˆå¦‚ç”¨è©ã€å¥å­ã€å…§å®¹ã€æƒ…æ„Ÿã€çµæ§‹ç­‰ï¼‰ã€‚\n",
    "    3. æŒ‡å‡ºéœ€è¦æ”¹é€²çš„åœ°æ–¹ï¼Œä¸¦èªªæ˜åŸå› ï¼Œä½†è¦ä»¥æº«å’Œæ˜“æ‡‚çš„èªæ°£è¡¨é”ã€‚\n",
    "    4. æä¾›å…·é«”çš„æ”¹é€²å»ºè­°ï¼Œä¸¦è§£é‡‹é€™äº›å»ºè­°å¦‚ä½•è®“æ–‡ç« æ›´å¥½ã€‚\n",
    "    5. æä¾›ä¸€ä»½ä¿®æ”¹å¾Œçš„ä½œæ–‡ç¯„ä¾‹ï¼Œé•·åº¦èˆ‡èªå¥é›£åº¦éœ€ç¬¦åˆåœ‹å°ä¸‰å¹´ç´šç¨‹åº¦ã€‚\n",
    "    6. å›è¦†æ ¼å¼éœ€åŒ…å«ï¼š\n",
    "       - æ–‡ç« å„ªé»\n",
    "       - éœ€è¦æ”¹é€²çš„åœ°æ–¹\n",
    "       - æ”¹é€²å»ºè­°\n",
    "       - ç¯„ä¾‹ä½œæ–‡ï¼ˆæ”¹å¯«ç‰ˆï¼‰\n",
    "\n",
    "    è«‹å§‹çµ‚ä¿æŒé¼“å‹µã€æ­£é¢èˆ‡è€å¿ƒçš„å£æ°£ã€‚\n",
    "\"\"\")\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Analysis)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "system_message = SystemMessage(content=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template=\"{article}\\n\\nOutput instruction: {format_instructions}\",\n",
    "                              input_variables=[\"article\"],\n",
    "                              partial_variables={'format_instructions': format_instructions}\n",
    "                              )\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt) \n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8311ffd-3397-4f69-ae4d-fcf4a40c0c5e",
   "metadata": {},
   "source": [
    "https://mhups-cloud1.mhups.tp.edu.tw/magazines/21st/articles/3rd/301.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d7aedc-a03b-4bbb-a20d-cc41272c343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = dedent(\"\"\"\n",
    "å°ç£æœ‰ä¸€å€‹æœ‰ååœ°æ–¹å«åšæ·¡æ°´ã€‚çˆ¸çˆ¸ã€åª½åª½æ¯æ¬¡å¸¶æˆ‘å’Œå“¥å“¥ã€å¼Ÿå¼Ÿå»æ·¡æ°´\n",
    "ç©ï¼Œæˆ‘å€‘éƒ½æœƒå»æ·¡æ°´è€è¡—å–é­šä¸¸æ¹¯å’Œåƒé£¯ã€‚\n",
    " æ·¡æ°´è€è¡—ä»¥å‰æœ‰é­šè…¥å‘³ï¼Œç¾åœ¨å»æ²’æœ‰äº†ã€‚å¾æ·é‹ç«™èµ°å‡ºä¾†ï¼Œä¸­æ­£è·¯åŠå»¶ä¼¸\n",
    "çš„é‡å»ºè¡—ã€æ¸…æ°´è¡—ä¸€å¸¶ï¼Œå°±æ˜¯é¼é¼å¤§åçš„æ·¡æ°´è€è¡—ã€‚æ·¡æ°´è€è¡—åˆ†æˆå…§å¤–å…©å´ï¼Œ\n",
    "å¤–å´æ˜¯é æ·¡æ°´æ²³å²¸çš„é‡‘è‰²æ°´å²¸æ­¥é“ï¼Œè‚‰å´æ˜¯å€‹å‚³çµ±è€è¡—ï¼Œé€™è£¡å…©æ—æ—ç«‹ç†±é¬§å•†\n",
    "åº—ï¼Œæœ‰æ¿ƒæ¿ƒå¤æ—©å‘³çš„é¤…èˆ–ã€é›œè²¨åº—ï¼Œä¹Ÿæœ‰è³£æ½®æµæœé£¾èˆ‡ç©å…·ã€‚æ­¤å€è‘—åçš„äººæ°£\n",
    "ç¾é£Ÿå¦‚é˜¿çµ¦ã€é­šä¸¸ã€é­šé…¥ã€å¤æ—©å‘³ç¾çƒ¤è›‹ç³•ã€é˜¿å©†éµè›‹ç­‰ï¼Œéƒ½æ˜¯ä¾†åˆ°é€™è£¡å¿…åƒ\n",
    "ä¸å¯çš„ç¾é£Ÿã€‚\n",
    " æ·¡æ°´æœ‰ä¸€å€‹å¥½åƒçš„å°åƒå«åšé­šä¸¸æ¹¯ï¼Œå®ƒé›–ç„¶å¾ˆç‡™ï¼Œå»å¾ˆå¥½åƒï¼Œä½†æ˜¯å¦‚æœæ˜¯\n",
    "å†¬å¤©åƒå°±ä¸æœƒç‡™ï¼Œå¯æ˜¯å¦‚æœæ˜¯å¤å¤©åƒï¼Œå°±æœƒå¾ˆç‡™ï¼Œä¸éå¹ä¸€å¹å°±å¥½äº†ã€‚æˆ‘å–œæ­¡\n",
    "å–é­šä¸¸æ¹¯ï¼Œå› ç‚ºè£¡é¢çš„é­šä¸¸æœ‰åŠ è‚‰ï¼Œè€Œä¸”ç‡™ç‡™çš„å¯ä»¥è®“æˆ‘èº«é«”è®Šæº«æš–ï¼Œåˆä¸æœƒ\n",
    "åƒå¤å¤©å–å¤ªç‡™ã€‚é­šä¸¸æ¹¯æ˜¯åœ¨æ·¡æ°´è€è¡—è£¡ï¼Œå—è‘—å¤§å®¶å–œæ„›çš„å°åƒä¹‹ä¸€ã€‚å…¶å¯¦é­šä¸¸\n",
    "æ¹¯å¾ˆå¥½åšåˆå¥½åƒã€‚ç…®æ°´ï¼Œæ»¾å¾Œä¸‹è–‘ç‰‡æˆ–è–‘çµ²ï¼Œå†ç…®ä¸€ä¸‹ï¼ŒåŠ å…¥é­šä¸¸ï¼Œæ°´æ»¾å¾ŒåŠ \n",
    "é¹½èª¿å‘³ï¼ŒèŠ¹èœå»è€çš®å¾Œåˆ‡ä¸€é»æœ«ï¼Œå³å¯ä¸Šæ¡Œï¼Œæ’’ä¸ŠèŠ¹èœï¼Œæ»´å…©æ»´é¦™æ²¹ï¼Œç‘ä¸Šä¸€\n",
    "é»èƒ¡æ¤’ç²‰ï¼Œé­šä¸¸æ¹¯å®Œæˆäº†ï¼\n",
    " å»äº†æ·¡æ°´è€è¡—å’Œå–äº†é­šä¸¸æ¹¯å¾Œï¼Œæˆ‘è¦ºå¾—å¥½å¥½ç©ï¼Œå› ç‚ºè€è¡—æœ‰å¾ˆå¤šå¥½åƒå¥½ç©\n",
    "çš„æ±è¥¿ï¼Œé‚„æœ‰å¾ˆå¤šç¾éº—åˆæ¼‚äº®çš„æœé£¾ï¼Œæ‰€ä»¥è®“æˆ‘å¾ˆæƒ³å†å»ã€‚è¦æ˜¯æ¯å¤©éƒ½å¯ä»¥å»\n",
    "æ·¡æ°´è€è¡—é‚£è©²å¤šå¥½å‘€ï¼å¦‚æœçˆ¸çˆ¸ã€åª½åª½å¸¶æˆ‘å’Œå“¥å“¥ã€å¼Ÿå¼Ÿå»æ·¡æ°´ç©ï¼Œé‚£æˆ‘ä¸€å®š\n",
    "æœƒå»è€è¡—åƒé£¯ã€å–é­šä¸¸æ¹¯å’Œçœ‹çœ‹é¢¨æ™¯çš„ã€‚\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1997b4f-1ac9-4a6d-b98f-28a673b81157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_call(text):\n",
    "    # your model.invoke() returns something like Analysis(...)\n",
    "    prompt = chat_prompt.invoke({\"article\": text})\n",
    "\n",
    "    output = model.invoke(prompt)\n",
    "    \n",
    "    parsed_output = output_parser.parse(output.content)\n",
    "\n",
    "    # Convert Pydantic model to individual outputs:\n",
    "    pro_text = \"\\n\".join(parsed_output.pro.name)\n",
    "    con_text = \"\\n\".join(parsed_output.con.name)\n",
    "    revised_text = parsed_output.revised\n",
    "\n",
    "    return pro_text, con_text, revised_text\n",
    "\n",
    "\n",
    "with gr.Blocks(title=\"ä½œæ–‡åˆ†æåŠ©æ•™\") as demo:\n",
    "    gr.Markdown(\"### ä½œæ–‡åˆ†æåŠ©æ•™\")\n",
    "\n",
    "    with gr.Row():\n",
    "        # ----- LEFT SIDE -----\n",
    "        with gr.Column(scale=1):\n",
    "            input_box = gr.Textbox(\n",
    "                lines=3,\n",
    "                placeholder=\"è«‹è¼¸å…¥ä½œæ–‡å…§å®¹...\",\n",
    "                label=\"å­¸ç”Ÿä½œæ–‡\"\n",
    "            )\n",
    "\n",
    "            # Examples under the input\n",
    "            gr.Examples(\n",
    "                examples=[[\"æˆ‘ä»Šå¤©å’Œå®¶äººå»å…¬åœ’ç©...\"], [\"ä»Šå¤©å¤©æ°£å¾ˆå¥½ï¼Œæˆ‘å’Œæœ‹å‹ä¸€èµ·...\"]],\n",
    "                inputs=input_box,\n",
    "                examples_per_page=None\n",
    "            )\n",
    "\n",
    "            # Buttons side-by-side\n",
    "            with gr.Row():\n",
    "                submit_btn = gr.Button(\"æäº¤\", variant=\"primary\")\n",
    "                clear_btn = gr.ClearButton([input_box], value=\"æ¸…é™¤\")\n",
    "\n",
    "        # ----- RIGHT SIDE -----\n",
    "        with gr.Column(scale=2):\n",
    "            pro_box = gr.Textbox(\n",
    "                lines=5,\n",
    "                label=\"æ–‡ç« å„ªé»ï¼ˆproï¼‰\",\n",
    "                interactive=False\n",
    "            )\n",
    "            con_box = gr.Textbox(\n",
    "                lines=5,\n",
    "                label=\"æ–‡ç« å¯ä»¥æ”¹é€²çš„åœ°æ–¹ï¼ˆconï¼‰\",\n",
    "                interactive=False\n",
    "            )\n",
    "            revised_box = gr.Textbox(\n",
    "                lines=12,\n",
    "                label=\"æ”¹å¯«ç¯„æœ¬ï¼ˆrevisedï¼‰\",\n",
    "                interactive=False\n",
    "            )\n",
    "\n",
    "    # Button logic\n",
    "    submit_btn.click(\n",
    "        fn=func_call,\n",
    "        inputs=input_box,\n",
    "        outputs=[pro_box, con_box, revised_box]\n",
    "    )\n",
    "\n",
    "    clear_btn.add([pro_box, con_box, revised_box])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb0d1f7-0790-425b-b7a8-8930204705fb",
   "metadata": {},
   "source": [
    "# å…§å®¹å¼·åŒ–\n",
    "\n",
    "## Okapi BM25 Retrieval System\n",
    "\n",
    "- ç›®çš„: Okapi BM25 å¹«åŠ©æ‰¾åˆ°ç•¶ä½ æœç´¢æŸäº›å…§å®¹æ™‚æœ€ç›¸é—œçš„æ–‡æª”ã€‚\n",
    "\n",
    "- æ–‡æª”å’Œè©èª:\n",
    "    \n",
    "    - æƒ³åƒä½ æœ‰ä¸€å †æ›¸ï¼ˆæ–‡æª”ï¼‰ã€‚\n",
    "    - æ¯æœ¬æ›¸éƒ½æœ‰å¾ˆå¤šè©èªã€‚\n",
    "\n",
    "- æœç´¢æŸ¥è©¢:\n",
    "\n",
    "    - ç•¶ä½ æœç´¢æ™‚ï¼Œä½ æœƒè¼¸å…¥å¹¾å€‹è©èªï¼ˆä½ çš„æŸ¥è©¢ï¼‰ã€‚\n",
    "\n",
    "- è©•åˆ†ç³»çµ±:\n",
    "\n",
    "    - Okapi BM25 æ ¹æ“šæ¯æœ¬æ›¸èˆ‡ä½ çš„æŸ¥è©¢åŒ¹é…çš„ç¨‹åº¦çµ¦äºˆæ¯æœ¬æ›¸ä¸€å€‹åˆ†æ•¸ã€‚\n",
    "\n",
    "- è©•åˆ†å› ç´ :\n",
    "\n",
    "    - è©é »: å¦‚æœä½ çš„æŸ¥è©¢ä¸­çš„ä¸€å€‹è©åœ¨æŸæœ¬æ›¸ä¸­å‡ºç¾å¾ˆå¤šæ¬¡ï¼Œè©²æ›¸æœƒå¾—åˆ°æ›´é«˜çš„åˆ†æ•¸ã€‚\n",
    "    - é€†æ–‡æª”é »ç‡: å¦‚æœä¸€å€‹è©åœ¨æ‰€æœ‰æ›¸ä¸­éƒ½å¾ˆç¨€æœ‰ï¼Œä½†åœ¨æŸæœ¬æ›¸ä¸­å‡ºç¾ï¼Œè©²æ›¸æœƒå¾—åˆ°æ›´é«˜çš„åˆ†æ•¸ã€‚\n",
    "    - æ–‡æª”é•·åº¦: è¼ƒé•·çš„æ›¸æœƒé€²è¡Œèª¿æ•´ï¼Œé€™æ¨£å®ƒå€‘ä¸æœƒåƒ…å› ç‚ºç¯‡å¹…é•·è€Œè¢«ä¸å…¬å¹³åœ°è©•åˆ†ã€‚\n",
    "\n",
    "- å…¬å¼:\n",
    "\n",
    "    -BM25 ä½¿ç”¨ä¸€å€‹æ•¸å­¸å…¬å¼ä¾†çµåˆé€™äº›å› ç´ ä¸¦è¨ˆç®—åˆ†æ•¸ã€‚\n",
    "\n",
    "- é¸æ“‡æœ€ä½³:\n",
    "\n",
    "    - åˆ†æ•¸æœ€é«˜çš„æ›¸è¢«èªç‚ºæ˜¯èˆ‡ä½ çš„æŸ¥è©¢æœ€ç›¸é—œçš„ã€‚\n",
    "\n",
    "- çµæœ:\n",
    "\n",
    "    - é€™äº›é«˜åˆ†æ›¸æœƒä½œç‚ºæœç´¢çµæœé¡¯ç¤ºçµ¦ä½ ã€‚\n",
    "\n",
    "æƒ³åƒä¸€ä¸‹ï¼šOkapi BM25 å°±åƒæ˜¯ä¸€å€‹è°æ˜çš„åœ–æ›¸ç®¡ç†å“¡ï¼Œå®ƒæ ¹æ“šä½ åœ¨æœç´¢ä¸­ä½¿ç”¨çš„è©èªä¾†åˆ¤æ–·å“ªäº›æ›¸å¯èƒ½æ˜¯æœ€æœ‰è¶£å’Œæœ€æœ‰å¹«åŠ©çš„ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcf9d88-865d-415c-9814-cf67fd11c5f9",
   "metadata": {},
   "source": [
    "### Term Frequency (TF) & Inverse Document Frequency (IDF):\n",
    "\n",
    "#### Term Frequency:\n",
    "\n",
    "æŠŠæ–‡ç« ä¸­å–®è©å‡ºç¾çš„é »ç‡åˆ†ä½ˆä½œç‚ºæ–‡ç« çš„ç‰¹å¾µ\n",
    "\n",
    "\n",
    "#### Inverse Document Frequency:\n",
    "\n",
    "æ­¸ä¸€åŒ–: å°‡æ–‡åº«ä¸­æ™®éå‡ºç¾çš„è©çš„æ¬Šé‡ä¸‹èª¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e607fb2-bbf5-4b2f-a769-e1cba57676d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0538f29-8b8e-45d9-8ba6-b0f82bc8ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "url = \"https://www.gutenberg.org/cache/epub/1041/pg1041.txt\"\n",
    "response = requests.get(url)\n",
    "\n",
    "filename = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-1\", \"pg1041.txt\")\n",
    "\n",
    "# Ensure the request was successful\n",
    "if response.status_code == 200:\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(response.text)\n",
    "    print(\"File downloaded successfully.\")\n",
    "else:\n",
    "    print(\"Failed to download file. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4ba1cb-81ce-405b-bed5-3748ed51576d",
   "metadata": {},
   "source": [
    "å¾ pg1014.txtä¸­æŠ“å‡ºéœ€è¦çš„æ•¸æ“š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98339ebd-8f8b-4eea-ba65-79e34255416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Read file\n",
    "with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Extract main body only\n",
    "match = re.search(r\"\\*\\*\\* START OF.*?\\*\\*\\*(.*)\\*\\*\\* END OF\", text, re.S)\n",
    "if match:\n",
    "    body = match.group(1)\n",
    "else:\n",
    "    body = text  # fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fd3e16-61a9-4850-8aa9-bc391c3bbda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into sonnets: Roman numeral headings\n",
    "pattern = r\"\\n([IVXLCDM]+)\\n\"   # captures numerals as headers\n",
    "parts = re.split(pattern, body)\n",
    "\n",
    "# Reconstruct mapping number â†’ sonnet text\n",
    "sonnets = {}\n",
    "for i in range(1, len(parts), 2):\n",
    "    number = parts[i].strip()\n",
    "    poem = parts[i+1].strip()\n",
    "    sonnets[number] = poem\n",
    "\n",
    "# Example: print first two sonnets\n",
    "for n in [\"I\", \"II\"]:\n",
    "    print(f\"Sonnet {n}:\\n{sonnets[n]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cb11f8-a292-4a75-936b-85d0e24e079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnets['I']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e194f4-a60b-4717-a624-d4f0bd699792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform([sonnets['I']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee97a5a-8049-4079-b1c8-44e8d43f9d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8991582-1fbf-4fda-9e47-ce3011152db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out()).T\n",
    "\n",
    "# We will use this later\n",
    "sampled_columns = vectorizer.get_feature_names_out()\n",
    "\n",
    "df.columns = [\"frequency\"]\n",
    "\n",
    "# Sort descending\n",
    "df = df.sort_values(\"frequency\", ascending=False)\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adbd30a-7ef2-4828-9fd7-5fe476f689f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sonnet = pd.DataFrame.from_dict(sonnets, orient='index', columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef07206-6d9c-4010-86b8-c94a00682fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sonnet.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97219dea-c2e9-45c4-bb06-df5681490b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df_sonnet['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f9ceaf-0377-4b59-942b-64f71596ff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49e8e20-3d8f-4826-85d6-1de677cfe1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[sampled_columns].iloc[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e3e588-df07-4fe2-961f-bfef08f8afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[sampled_columns].iloc[0].T.loc['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306b1a62-502d-47dd-a292-19cbea82bf29",
   "metadata": {},
   "source": [
    "OKAPI25 å¯ä»¥çœ‹æˆæ˜¯é—œéµå­—æœç´¢ï¼Œè€Œæœå°‹çš„çµæœæ ¹æ“šé—œéµå­—åœ¨æ¯æ®µæ–‡å­—ä¸­å‡ºç¾çš„é »ç‡å’Œæ–‡åº«ä¸­çš„ç¨€æœ‰åº¦é€²è¡ŒåŠ æ¬Š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d71deb-ecda-4379-a041-b482bbfdbead",
   "metadata": {},
   "source": [
    "## OKAPI25 in LangChain\n",
    "\n",
    "https://api.python.langchain.com/en/latest/_modules/langchain_community/retrievers/bm25.html#BM25Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7421cbc-2b35-43ce-854e-911e204040fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97969ad6-95ce-49bd-8cfc-84cfb9d11173",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Creating Documents from Training Data (å¾è¨“ç·´æ•¸æ“šå‰µå»ºæ–‡æª”):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d6e335-a9c6-427e-840a-c2fffb19d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for idx, row in df_sonnet.iterrows():\n",
    "    document = Document(page_content=row['text'],\n",
    "                        metadata={\"id\": idx})\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f734a5e1-58b2-4e0c-a294-9db0d554cdb5",
   "metadata": {},
   "source": [
    "### 2. åˆå§‹åŒ– BM25Retriever:\n",
    "    \n",
    "- ä½¿ç”¨ BM25Retriever.from_documents æ–¹æ³•ï¼Œåˆ©ç”¨ documents åˆ—è¡¨åˆå§‹åŒ–äº†ä¸€ä¸ª BM25Retriever å¯¦ä¾‹ã€‚\n",
    "- åƒæ•¸:\n",
    "    - k=2ï¼šæŒ‡å®šæ¯å€‹æŸ¥è©¢è¦æª¢ç´¢çš„æ–‡æª”æ•¸é‡ã€‚\n",
    "    - bm25_params={\"k1\": 2.5}ï¼šè¨­ç½®ç‰¹å®šçš„ BM25 åƒæ•¸ï¼ˆè¨­ç½® k1 åƒæ•¸ç‚º 2.5ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd5083d-1969-459f-bb6f-a968a0feaeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6565204d-9d89-4413-8f4e-22762ebd8ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_documents(documents, k=2, \n",
    "                                              bm25_params={\"k1\":2.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9690a4-acb6-43f3-a089-885920799557",
   "metadata": {},
   "source": [
    "https://tolkiengateway.net/wiki/The_Road_Goes_Ever_On_(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74f9eaf-609e-4f01-a91f-cdc9f910a2ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "query = dedent(\"\"\"\n",
    "Roads go ever ever on,\n",
    "Over rock and under tree,\n",
    "By caves where never sun has shone,\n",
    "By streams that never find the sea;\n",
    "Over snow by winter sown,\n",
    "And through the merry flowers of June,\n",
    "Over grass and over stone,\n",
    "And under mountains in the moon.\n",
    "\n",
    "Roads go ever ever on\n",
    "Under cloud and under star,\n",
    "Yet feet that wandering have gone\n",
    "Turn at last to home afar.\n",
    "Eyes that fire and sword have seen\n",
    "And horror in the halls of stone\n",
    "Look at last on meadows green\n",
    "And trees and hills they long have known\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8948b4c6-5d61-4d0c-85fa-f55f5aa6d121",
   "metadata": {},
   "source": [
    "### 3. Getting Top N Results (ç²å–æ’åå‰ N çš„çµæœ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86071b0-8d64-4f9d-85d0-10a3bc5f90e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‘¼å« BM25 æª¢ç´¢å™¨ï¼Œæ ¹æ“šæŸ¥è©¢æ–‡å­—æ‰¾å‡ºæœ€ç›¸é—œçš„æ–‡æª”\n",
    "\n",
    "output = bm25_retriever.invoke(query)\n",
    "\n",
    "# é æœŸè¼¸å‡ºï¼šè¿”å›èˆ‡è¼¸å…¥ query èªæ„æœ€ç›¸é—œçš„æ–‡æ®µï¼ˆåˆ—è¡¨æ ¼å¼ï¼‰\n",
    "for doc in output:\n",
    "    print(doc.page_content[:200], \"...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370cb578-0ca5-4a57-9535-59298a545357",
   "metadata": {},
   "source": [
    "### Byte Pair Encoding (BPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f63b8de-2c32-4c6b-91d0-5c8faf9ffe0e",
   "metadata": {},
   "source": [
    "è‹±æ–‡ä¼¼ä¹æŒºå¥½åˆ‡:æ¯å€‹å–®è©æœ‰é ­æœ‰å°¾ï¼Œä½†ä¸­æ–‡æˆ–æ—¥æ–‡é€™ç¨®ä¸­é–“æ²’æœ‰ç©ºç™½çš„æ–‡æœ¬è¦æ€éº¼åˆ‡?\n",
    "\n",
    "Byte Pair Encoding (BPE) æœƒå­¸ç¿’æ–‡æœ¬ä¸­é »ç¹å‡ºç¾çš„å­—ç¬¦å°ï¼Œä¸¦å°‡å®ƒå€‘åˆä½µæˆ tokenã€‚å°æ–¼ç¹é«”ä¸­æ–‡ï¼Œå®ƒå¾å–®å€‹å­—ç¬¦é–‹å§‹ï¼Œä¸¦é€æ­¥åˆä½µé »ç¹å‡ºç¾çš„å­—ç¬¦å°ã€‚\n",
    "\n",
    "1. æº–å‚™ä¸€å€‹å°å‹ç¹é«”ä¸­æ–‡èªæ–™åº«ã€‚\n",
    "2. ä½¿ç”¨ Hugging Face çš„ `tokenizers` è¨“ç·´ BPE åˆ†è©å™¨ã€‚\n",
    "3. å°‡è¨“ç·´å¥½çš„åˆ†è©å™¨æ‡‰ç”¨åˆ°ä¸€å¥å¥å­ä¸Šã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcd0672-3a16-4b41-9201-5ea175ebf802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the pre-trained BPE tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"p208p2002/llama-traditional-chinese-120M\")\n",
    "\n",
    "# Example usage\n",
    "text = \"æˆ‘æ­£åœ¨é–±è®€æ›¸ç±ï¼Œä¹Ÿåœ¨çœ‹è‹±æ–‡è³‡æ–™ã€‚\"\n",
    "encoded = tokenizer(text)\n",
    "print(\"Tokens:\", tokenizer.convert_ids_to_tokens(encoded[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9806b7e0-9cc7-4883-ab88-95ce3da4573e",
   "metadata": {},
   "source": [
    "- python -m unidic download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b04f37-8a31-4548-8d52-0caf973e9cd9",
   "metadata": {},
   "source": [
    "## ä¸­æ–‡å’Œæ—¥æ–‡BPE\n",
    "\n",
    "| èªè¨€ | Tokenization èµ·é» | æ˜¯å¦ç”¨è©å…¸ï¼å½¢æ…‹åˆ†æ | BPE ä½œç”¨ |\n",
    "|------|--------------------|----------------------|-----------|\n",
    "| **æ—¥æ–‡** | å½¢æ…‹ç´ ï¼ˆè©ç´šï¼‰ | âœ… MeCab / UniDic | æ‹†æˆæ›´å° subword |\n",
    "| **ä¸­æ–‡** | å­—ç´šï¼ˆcharacter-levelï¼‰ | âŒ ä¸ç”¨ | è‡ªå‹•å­¸å‡ºè©ç´š token |\n",
    "\n",
    "---\n",
    "\n",
    "## ç›´è§€ç†è§£\n",
    "\n",
    "| èªè¨€ | BPE çš„æ–¹å‘ | çµæœè¶¨å‹¢ |\n",
    "|------|-------------|-----------|\n",
    "| **æ—¥æ–‡** | å¤§è© â†’ å°è©ï¼ˆæ‹†åˆ†ï¼‰ | é¿å…æœªçŸ¥è©ã€å…±ç”¨è©å¹¹ |\n",
    "| **ä¸­æ–‡** | å°å­— â†’ å¤§è©ï¼ˆåˆä½µï¼‰ | è‡ªå‹•å­¸å‡ºè©ç´šçµæ§‹ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eebc209-cb76-4140-b55d-7ce9f301966b",
   "metadata": {},
   "source": [
    "æˆ‘çŸ¥é“ä½ å€‘çš„å¿ƒä¸­æœ‰ä¸€å€‹å¤§è†½çš„æƒ³æ³•ï¼Œæ‰€ä»¥æŠŠæ—¥æ–‡çš„Tokenizerä¹Ÿé™„ä¸Šå»äº†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f910a4-4924-4645-be9b-0f065ef25137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fugashi import Tagger\n",
    "\n",
    "tagger = Tagger(r'-d C:/Users/Ling/miniconda3/envs/aicg/lib/site-packages/unidic/dicdir')\n",
    "\n",
    "\"\"\"\n",
    "The ## prefix is something youâ€™ll often see in WordPiece or BPE tokenizers (like BERT). \n",
    "It means â€œthis subword is a continuation of the previous token.â€\n",
    "\"\"\"\n",
    "\n",
    "text = \"\"\n",
    "words = [w.surface for w in tagger(text)]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa63fca-816b-4e56-b3db-7546c542502b",
   "metadata": {},
   "source": [
    "ä¸‹è¼‰ä¸­æ–‡æ–‡æª”\n",
    "\n",
    "- https://github.com/rime-aca/corpus/blob/master/å”è©©ä¸‰ç™¾é¦–.txt\n",
    "\n",
    "ä¸æ˜¯æˆ‘å–œæ­¡æ–‡å­¸ï¼Œæ˜¯é€™æ¯”è¼ƒå¥½æ‰¾æ•¸æ“šé›†ï¼Œé‚„ä¸æœƒè¢«å‘Šã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0483d85e-4327-4d68-bf25-551d11fa3d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Read file\n",
    "filename = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-1\", \"å”è©©ä¸‰ç™¾é¦–.txt\")\n",
    "with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "poems = []\n",
    "\n",
    "# Split by blank lines\n",
    "blocks = [b.strip() for b in text.strip().split(\"\\n\\n\") if b.strip()]\n",
    "\n",
    "for block in blocks:\n",
    "    entry = {}\n",
    "    for line in block.split(\"\\n\"):\n",
    "        if line.startswith(\"è©©å:\"):\n",
    "            entry[\"è©©å\"] = line.replace(\"è©©å:\", \"\").strip()\n",
    "        elif line.startswith(\"ä½œè€…:\"):\n",
    "            entry[\"ä½œè€…\"] = line.replace(\"ä½œè€…:\", \"\").strip()\n",
    "        elif line.startswith(\"è©©é«”:\"):\n",
    "            entry[\"è©©é«”\"] = line.replace(\"è©©é«”:\", \"\").strip()\n",
    "        elif line.startswith(\"è©©æ–‡:\"):\n",
    "            entry[\"è©©æ–‡\"] = line.replace(\"è©©æ–‡:\", \"\").strip()\n",
    "    if len(entry) != 0:\n",
    "        poems.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22744e1b-8305-40fb-8092-8792e0d95a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "poems[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc04545-3b02-4e9b-bc21-228c2d518079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file\n",
    "filename = os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-1\", \"å®‹è©ä¸‰ç™¾é¦–.txt\")\n",
    "pd. with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Split by blank lines\n",
    "blocks = [b.strip() for b in text.strip().split(\"\\n\\n\") if b.strip()]\n",
    "\n",
    "for block in blocks:\n",
    "    entry = {}\n",
    "    for line in block.split(\"\\n\"):\n",
    "        if line.startswith(\"è©©å:\"):\n",
    "            entry[\"è©ç‰Œ\"] = line.replace(\"è©ç‰Œ:\", \"\").strip()\n",
    "        elif line.startswith(\"ä½œè€…:\"):\n",
    "            entry[\"ä½œè€…\"] = line.replace(\"ä½œè€…:\", \"\").strip()\n",
    "        elif line.startswith(\"è©©é«”:\"):\n",
    "            entry[\"è©æ–‡\"] = line.replace(\"è©æ–‡:\", \"\").strip()\n",
    "    if len(entry) != 0:\n",
    "        poems.append(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95b10ab-7f97-47b3-b3e5-986302ce2d60",
   "metadata": {},
   "source": [
    "#### å»ºç«‹Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feae8a65-014f-4c76-a232-f2ac0c005225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_poem = pd.DataFrame(poems)\n",
    "\n",
    "documents = []\n",
    "\n",
    "for _, row in df_poem.iterrows():\n",
    "    document = Document(page_content=row['è©©æ–‡'],\n",
    "                        metadata={\"è©©å\": row[\"è©©å\"],\n",
    "                                  \"ä½œè€…\": row[\"ä½œè€…\"],\n",
    "                                  \"è©©é«”\": row[\"è©©é«”\"]})\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387d534f-2498-4c02-ac16-542deb6c76da",
   "metadata": {},
   "source": [
    "è‡ªè¨‚ç¾©å‡½æ•¸ï¼Œè®“BM25ä½¿ç”¨BPE tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a543cfc-fd8e-452a-a945-7b340c3e6f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_func(text: str):\n",
    "\n",
    "    # 1. Define special tokens to remove\n",
    "    special_tokens = {\"<s>\", \"</s>\", \"[PAD]\", \"[UNK]\"}\n",
    "    \n",
    "    encoded = tokenizer(text)\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoded[\"input_ids\"])\n",
    "\n",
    "    # 2. Remove special tokens\n",
    "    tokens = [t.replace(\"â–\", \"\") for t in tokens if t not in special_tokens]\n",
    "    \n",
    "    # 3. Remove punctuation (keep only Chinese/English/number words)\n",
    "    tokens = [t for t in tokens if re.match(r'[\\wä¸€-é¾¥]+', t)]\n",
    "    \n",
    "    # Stringify the tokens\n",
    "    return [str(token) for token in tokens]\n",
    "\n",
    "\n",
    "bm25_poem_retriever = BM25Retriever.from_documents(documents, k=5, \n",
    "                                                   bm25_params={\"k1\":2.5},\n",
    "                                                   preprocess_func=_preprocess_func\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ed0c0a-9413-4fd2-a41c-2fdc81090c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_poem_retriever.invoke(\"å¤§é¢¨èµ·å…®é›²é£›æš å¨åŠ æµ·å…§å…®æ­¸æ•…é„‰ å®‰å¾—çŒ›å£«å…®å®ˆå››æ–¹\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b265ce-02e3-4e21-a8fa-b5dd6e3def1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_poem_retriever.invoke(\"å¤•é™½ç„¡é™å¥½\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36283559-563c-4b09-8bd0-4896b76c8195",
   "metadata": {},
   "source": [
    "æŠŠè©©ç¶“è½‰æ›æˆäº”è¨€çµ•å¥... æœ‰ä¸­æ–‡æ¯”è¼ƒå¥½çš„äººå—? XD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b011dc9-e7ea-47f8-be36-1e8544c51e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate\n",
    "# query\n",
    "\n",
    "query = dedent(\"\"\"\n",
    "è’¹è‘­è’¼è’¼ã€ç™½éœ²ç‚ºéœœã€‚\n",
    "æ‰€è¬‚ä¼Šäººã€åœ¨æ°´ä¸€æ–¹ã€‚\n",
    "é¡æ´„å¾ä¹‹ã€é“é˜»ä¸”é•·ã€‚\n",
    "é¡éŠå¾ä¹‹ã€å®›åœ¨æ°´ä¸­å¤®ã€‚\n",
    "\"\"\")\n",
    "\n",
    "# output format\n",
    "class Output(BaseModel):\n",
    "    name: str = Field(description=\"result in traditional Chinese (ç¹é«”ä¸­æ–‡)\")\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Output)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "# prompt template\n",
    "system_template = dedent(\"\"\"\n",
    "You are a helpful AI assistant with expertise in classical Chinese literature.\n",
    "You understand all the nuance and history background of all the content.\n",
    "\"\"\")\n",
    "system_prompt = PromptTemplate(template=system_template)\n",
    "system_message = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "human_prompt = PromptTemplate(template=(\"\"\"\n",
    "Create a {poetic_form}\n",
    "\n",
    "Examples:\n",
    "{context}\n",
    "\n",
    "according to the semantic of {query}\n",
    "\n",
    "Output instruction: {format_instructions}\n",
    "\"\"\"),\n",
    "input_variables=[\"poetic_form\", \"query\", \"context\"],\n",
    "partial_variables={'format_instructions': format_instructions}\n",
    ")\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt) \n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message,\n",
    "                                                 human_message\n",
    "                                               ])\n",
    "\n",
    "# retrieval\n",
    "# BM25 retriever ä¸æ”¯æŒ filter\n",
    "# æ‰€ä»¥å»ºè­°å…ˆfilterå…§å®¹\n",
    "\n",
    "df_poem = pd.DataFrame(poems)\n",
    "\n",
    "documents = []\n",
    "\n",
    "for _, row in df_poem.iterrows():\n",
    "    if row[\"è©©é«”\"] == \"äº”è¨€çµ•å¥\":\n",
    "        document = Document(page_content=row['è©©æ–‡'],\n",
    "                            metadata={\"è©©å\": row[\"è©©å\"],\n",
    "                                      \"ä½œè€…\": row[\"ä½œè€…\"],\n",
    "                                      \"è©©é«”\": row[\"è©©é«”\"]})\n",
    "        documents.append(document)\n",
    "\n",
    "bm25_poem_retriever = BM25Retriever.from_documents(documents, k=5, \n",
    "                                                   bm25_params={\"k1\":2.5},\n",
    "                                                   preprocess_func=_preprocess_func\n",
    "                                                  )\n",
    "\n",
    "context = bm25_poem_retriever.invoke(query)\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065672bf-e381-4a26-8fb2-85be53118945",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\\n\".join([c.page_content for c in context])\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993a621c-6af3-4aba-9fa2-5a3594da530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ‡æ›æˆ gpt-4oã€‚gpt-4o-miniåœ¨é€™æ–¹é¢å¾ˆå¼±\n",
    "\n",
    "model_poem = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o\", \n",
    "                   temperature=0 # a range from 0-2, the higher the value, the higher the `creativity`\n",
    "                  )\n",
    "\n",
    "prompt = chat_prompt.invoke({\"query\": query,\n",
    "                             \"poetic_form\": \"äº”è¨€çµ•å¥\",\n",
    "                             \"context\": context})\n",
    "\n",
    "output = model_poem.invoke(prompt)\n",
    "\n",
    "parsed_output = output_parser.parse(output.content)\n",
    "\n",
    "print(parsed_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968f8861-ef45-4bb6-8f7b-108ce055d98b",
   "metadata": {},
   "source": [
    "# Wikipedia Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0ddbe9-374a-4f42-8a0a-e76f4d8f8409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade --quiet  wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325d56f0-bc4a-40ad-8b45-55bc24d4c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever\n",
    "\n",
    "wiki_retriever = WikipediaRetriever()\n",
    "\n",
    "docs = wiki_retriever.invoke(\"2024 US presidential election\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8e184a-bf82-4687-acd3-ee28ccf3890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18856c98-7918-4afd-9675-3c0e69549d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d145bd2-875d-4f0b-8bfc-1fff44c9a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è‹¥æ˜¯å°‘æ–¼çµ¦å®šè¿”å›æ•¸é‡ï¼Œå‰‡è¿”å›ç•¶å‰æ‰€æœ‰å¯å¾—åˆ°æ–‡ä»¶\n",
    "\n",
    "docs = wiki_retriever.invoke(\"rice\")\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5414999-cb9f-4e3b-a7fe-7340b56eea84",
   "metadata": {},
   "source": [
    "- If you want to know what parameters can be feed to the WikipediaRetriever:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98333101-de37-4203-9f2f-c9a42db21473",
   "metadata": {},
   "outputs": [],
   "source": [
    "WikipediaRetriever?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d4f34-9d99-47ba-9f08-48ac5feb4a76",
   "metadata": {},
   "source": [
    "By default, wikipedia retriever returns 3 documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712d4f6f-12c5-4ef2-a92f-aec594002d76",
   "metadata": {},
   "source": [
    "# Ensemble Retriever\n",
    "\n",
    "- å®ƒçµåˆé€™äº›å·¥å…·çš„çµæœä¸¦ä½¿ç”¨ç‰¹æ®Šæ–¹æ³•é€²è¡Œçµ„ç¹”ã€‚\n",
    "- é€šéä½¿ç”¨ä¸åŒçš„å·¥å…·ï¼Œå®ƒæ¯”åƒ…ä½¿ç”¨å–®ä¸€å·¥å…·æ•ˆæœæ›´å¥½ã€‚\n",
    "- é€šå¸¸ï¼Œå®ƒçµåˆå…©ç¨®é¡å‹çš„æœç´¢ï¼šä¸€ç¨®å°‹æ‰¾ç²¾ç¢ºè©èªï¼ˆä¾‹å¦‚ BM25ï¼‰ï¼Œå¦ä¸€ç¨®ç†è§£å«ç¾©ï¼ˆä¾‹å¦‚åµŒå…¥å¼ï¼‰ã€‚\n",
    "- é€™ç¨®æ··åˆç¨±ç‚º \"æ··åˆæœç´¢\"ã€‚\n",
    "- ç¬¬ä¸€ç¨®å·¥å…·å°‹æ‰¾å…·æœ‰ç‰¹å®šè©èªçš„æ–‡æª”ï¼Œè€Œç¬¬äºŒç¨®å·¥å…·å‰‡å°‹æ‰¾å…·æœ‰ç›¸ä¼¼æ€æƒ³çš„æ–‡æª”ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d36f78a-b55a-4e40-ab9c-9ea2151a5c38",
   "metadata": {},
   "source": [
    "- weights: æ§åˆ¶æ¬Šé‡\n",
    "- ç¸½è¿”å›æ–‡ä»¶æ•¸é‡ç­‰æ–¼å€‹åˆ¥æª¢ç´¢å™¨ (retriever) æª¢ç´¢æ–‡ä»¶æ•¸é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599b51aa-9c1b-4e4b-839f-9fb0bdac182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, wiki_retriever], weights=[0.5, 0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cb3e2a-8efa-47a0-a682-574adbd1f1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ensemble_retriever.invoke(\"rice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef0492-cf23-4c52-9685-a7860ba645e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91847b0e-ef31-45da-88da-a93888cd0093",
   "metadata": {},
   "source": [
    "- bm25_retriever è¿”å›å…©ä»½\n",
    "- wiki_retriever è¿”å›å…©ä»½"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14fcd07-cd35-4c5d-bcc2-973b81daa401",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’¼ å¯¦å‹™æ‡‰ç”¨æ¡ˆä¾‹ï¼šå…¬å¸çŸ¥è­˜åº«æª¢ç´¢\n",
    "\n",
    "å‡è¨­ä½ åœ¨ä¸€é–“ç§‘æŠ€å…¬å¸å·¥ä½œï¼Œå…§éƒ¨æœ‰æ•¸ç™¾ä»½æŠ€è¡“æ–‡ä»¶èˆ‡å°ˆæ¡ˆç´€éŒ„ã€‚  \n",
    "è‹¥åŒäº‹è©¢å•ï¼šã€Œæˆ‘å€‘å»å¹´å“ªå€‹åœ˜éšŠä½¿ç”¨é LangChainï¼Ÿã€  \n",
    "- **BM25 Retriever** å¯ç”¨æ–¼å¿«é€Ÿæœå°‹æ–‡ä»¶ä¸­åŒ…å«ã€ŒLangChainã€é—œéµå­—çš„éƒ¨åˆ†ï¼ˆé«˜ç²¾åº¦å­—é¢åŒ¹é…ï¼‰ã€‚  \n",
    "- **Embedding Retriever**ï¼ˆèªç¾©æœå°‹ï¼‰å‰‡èƒ½æ‰¾åˆ°å³ä½¿æœªå‡ºç¾ç›¸åŒå­—è©ã€ä½†èªæ„ç›¸ä¼¼çš„æ–‡ä»¶ã€‚  \n",
    "\n",
    "è‹¥åŒæ™‚ä½¿ç”¨å…©è€…çµ„åˆæˆ **Ensemble Retrieverï¼ˆæ··åˆæª¢ç´¢ï¼‰**ï¼š\n",
    "- BM25 æä¾›æº–ç¢ºçš„å­—è©æ¯”å°  \n",
    "- Embedding æä¾›èªæ„ç†è§£  \n",
    "- æœ€å¾Œæ•´åˆçµæœåŠ æ¬Šæ’åºï¼Œèƒ½å¾—åˆ°æ›´å®Œæ•´ã€ç²¾ç¢ºçš„æœå°‹çµæœ  \n",
    "\n",
    "é€™é¡æ–¹æ³•å¸¸ç”¨æ–¼ï¼š\n",
    "- å®¢æœçŸ¥è­˜åº«ï¼ˆè‡ªå‹•å›ç­”å®¢æˆ¶å•é¡Œï¼‰  \n",
    "- æ³•å¾‹æ–‡ä»¶æª¢ç´¢  \n",
    "- å…¬å¸å…§éƒ¨æ–‡ä»¶æœå°‹å¼•æ“  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33749100-3ad0-489b-882d-40a0b41232c2",
   "metadata": {},
   "source": [
    "# Runtime Configuration (é‹è¡Œæ™‚é…ç½®)\n",
    "\n",
    "- æˆ‘å€‘ä¹Ÿå¯ä»¥åœ¨é‹è¡Œæ™‚é…ç½®æª¢ç´¢å™¨ã€‚ç‚ºäº†åšåˆ°é€™ä¸€é»ï¼Œæˆ‘å€‘éœ€è¦å°‡å­—æ®µæ¨™è¨˜ç‚ºå¯é…ç½®çš„ã€‚\n",
    "\n",
    "API Reference: https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.utils.ConfigurableField.htmld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2301ed88-4894-4c32-9e1c-a0291e192f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d883448-92c9-4a36-a4bd-20f73a755c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_documents(documents, k=2, \n",
    "    bm25_params={\"k1\": 1}).configurable_fields(\n",
    "    k=ConfigurableField(\n",
    "        id=\"bm25_k\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f102aaad-9bf8-42a1-be3d-bc054b3c5c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, wiki_retriever], weights=[0.5, 0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f5977c-e120-4f36-b227-262f2add9239",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"bm25_k\": 5}}\n",
    "docs = ensemble_retriever.invoke(\"rice\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51851ea0-c12e-42bb-b1cf-3e57314e15ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb7982d-f1cb-4036-9317-dd7f96c5836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - bm25_retriever è¿”å›äº”ä»½\n",
    "# - wiki_retriever è¿”å›å…©ä»½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792ac2d5-2284-426d-8894-c9aec4849a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, wiki_retriever], weights=[0.1, 0.9]\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"bm25_k\": 10}}\n",
    "docs = ensemble_retriever.invoke(\"rice\", config=config)\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c45ab-899b-4d21-9f57-7939f79fa4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - bm25_retriever è¿”å›åä»½\n",
    "# - wiki_retriever è¿”å›å…©ä»½"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a8ec7b-1a3f-4eb1-b210-747d5943b7af",
   "metadata": {},
   "source": [
    "### This is what I do in my work:\n",
    "\n",
    "I use runtime configuration to target a specific data section with the applied attribute.\n",
    "\n",
    "More specifically, there are many types of cosmetic products, such as:\n",
    "\n",
    "- Lipstick\n",
    "- Lip Gloss\n",
    "- Mascara\n",
    "- Blush\n",
    "- Foundation\n",
    "- Nail Polish\n",
    "- Eyeliner\n",
    "- Eye Pencil\n",
    "\n",
    "These products are applied to different areas: face, nails, eyes, and lips.\n",
    "\n",
    "You can retrieve information more efficiently and accurately if you identify the correct application area beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a516b1-a7f7-4bea-8567-32d46570e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_documents(self.documents, embedding=embedding)\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type='similarity',\n",
    "                                     search_kwargs={'k': self._k}).configurable_fields(search_kwargs=ConfigurableField(id=\"faiss_search_kwargs\"))\n",
    "\n",
    "semantic_retriever = retrievers['semantic']\n",
    "semantic_documents = semantic_retriever.invoke(product, config={\"configurable\":\n",
    "                                             {\"faiss_search_kwargs\":\n",
    "                                                  {\"fetch_k\":20,\n",
    "                                                   \"k\": 2,\n",
    "                                                   \"filter\": {\"applied\": area}}}})\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
