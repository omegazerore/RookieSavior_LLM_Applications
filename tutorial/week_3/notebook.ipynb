{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f5e101-968d-4062-848a-23cfe4245440",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8602e84a-871a-4cdf-aa31-13fd6be2b431",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": "os.chdir(\"../../\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abbb99d-12c3-4ced-a1ad-be97966a33d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate\n",
    "# from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from src.initialization import credential_init\n",
    "from src.io.path_definition import get_project_dir\n",
    "\n",
    "\n",
    "# å¿«é€Ÿå»ºç«‹chat_prompt_template\n",
    "def build_standard_chat_prompt_template(kwargs):\n",
    "\n",
    "    messages = []\n",
    " \n",
    "    if 'system' in kwargs:\n",
    "        content = kwargs.get('system')\n",
    "        prompt = PromptTemplate(**content)\n",
    "        message = SystemMessagePromptTemplate(prompt=prompt)\n",
    "        messages.append(message)  \n",
    "\n",
    "    if 'human' in kwargs:\n",
    "        content = kwargs.get('human')\n",
    "        prompt = PromptTemplate(**content)\n",
    "        message = HumanMessagePromptTemplate(prompt=prompt)\n",
    "        messages.append(message)\n",
    "        \n",
    "    chat_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "    return chat_prompt\n",
    "\n",
    "\n",
    "#å¿«é€Ÿå»ºç«‹pipeline\n",
    "def build_pipeline(model, inputs, parser=None):\n",
    "    prompt = build_standard_chat_prompt_template(inputs)\n",
    "    chain = prompt | model\n",
    "    if parser:\n",
    "        chain |= parser\n",
    "    return chain\n",
    "\n",
    "\n",
    "credential_init()\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578de59b-eadb-44f4-97d5-393703757226",
   "metadata": {},
   "source": [
    "# RAG N-Shot\n",
    "\n",
    "> ğŸ¯ **æœ¬ç« å­¸å®Œä½ å°‡èƒ½å­¸æœƒä»€éº¼ï¼š**\n",
    "> - äº†è§£ RAG (Retrieval-Augmented Generation) èˆ‡ N-Shot Prompting çš„æ¦‚å¿µèˆ‡æ‡‰ç”¨\n",
    "> - å­¸æœƒå¦‚ä½•è®“æ¨¡å‹ã€Œå­¸é¢¨æ ¼ã€â”€â”€å¾ç¤ºä¾‹ä¸­æå–é¢¨æ ¼ç‰¹å¾µä¸¦ä»¥ç›¸åŒé¢¨æ ¼ç”Ÿæˆå…§å®¹\n",
    "> - æŒæ¡ åˆ†é¡ä»»å‹™ çš„ä¸åŒç­–ç•¥ï¼ˆZero-Shotã€Few-Shotã€LLM-based Classificationï¼‰\n",
    "> - èƒ½å¯¦ä½œ è©©è©åˆ†é¡ã€é£›å®‰å ±å‘Šåˆ†é¡ ç­‰å¤šæ¨£åŒ–æ‡‰ç”¨\n",
    "> - äº†è§£ éåŒæ­¥è³‡æ–™è™•ç†æµç¨‹ (Async + LCEL)ï¼Œæå‡è³‡æ–™æ“·å–èˆ‡åˆ†ææ•ˆèƒ½\n",
    "> - å­¸æœƒå¾ ç¶²é ã€Wordã€PDF ä¸­æå–æ–‡å­—è³‡æ–™ä¸¦è½‰åŒ–ç‚ºå¯ç”¨å…§å®¹\n",
    "> - èƒ½å»ºç«‹ä¸€å€‹ AI æ‹›å‹ŸåŒ¹é…ç³»çµ±ï¼šå¾ç¶²é æŠ“å–è·ç¼º â†’ æå–å±¥æ­· â†’ åˆ†æ â†’ è‡ªå‹•é…å°\n",
    "\n",
    "> ğŸ“˜ æœ€çµ‚ä½ å°‡å…·å‚™çš„èƒ½åŠ›ï¼š\n",
    "> -èƒ½å¤ ç¨ç«‹è¨­è¨ˆä¸¦å¯¦ä½œä¸€å€‹æ•´åˆæª¢ç´¢ã€é¢¨æ ¼æ¨¡ä»¿ã€åˆ†é¡èˆ‡åŒ¹é…çš„ AI è‡ªå‹•åŒ–å·¥ä½œæµï¼Œ\n",
    "> -è®“æ¨¡å‹ä¸åªå›ç­”å•é¡Œï¼Œæ›´èƒ½ä»¥ç‰¹å®šé¢¨æ ¼ã€Œæ€è€ƒã€ç”Ÿæˆèˆ‡æ±ºç­–ã€ã€‚\n",
    "\n",
    "åœ¨ RAG (Retrieval-Augmented Generation) ä¸­ï¼Œæˆ‘å€‘ä¸åªå¯ä»¥è®“æ¨¡å‹æª¢ç´¢è³‡æ–™åº«ä¾†å›ç­”å•é¡Œï¼Œé‚„å¯ä»¥é€é N-Shot æç¤º (N-Shot Prompting) çš„æ–¹å¼ï¼Œè®“æ¨¡å‹å­¸ç¿’ã€Œé¢¨æ ¼ã€ã€‚\n",
    "\n",
    "é€™è£¡çš„ Nï¼Œä»£è¡¨ä½ çµ¦æ¨¡å‹å¹¾å€‹ç¤ºä¾‹ (Examples)ã€‚\n",
    "\n",
    "1-Shotï¼šåªçµ¦ä¸€å€‹ç¤ºä¾‹ï¼Œæ¨¡å‹æœƒæ¨¡ä»¿è©²é¢¨æ ¼ä¾†ç”Ÿæˆã€‚\n",
    "\n",
    "Few-Shot (N-Shot)ï¼šçµ¦å¤šå€‹ç¤ºä¾‹ï¼Œæ¨¡å‹æœƒæ­¸ç´å‡ºå…±åŒçš„é¢¨æ ¼ç‰¹å¾µã€‚\n",
    "\n",
    "0-Shotï¼šå®Œå…¨æ²’æœ‰ç¤ºä¾‹ï¼Œæ¨¡å‹åªèƒ½é å…§å»ºçŸ¥è­˜ä¾†ç”Ÿæˆã€‚\n",
    "\n",
    "é€éé€™ç¨®æ–¹å¼ï¼Œæˆ‘å€‘å¯ä»¥è®“æ¨¡å‹ä¸åªæ˜¯ã€Œå›ç­”å•é¡Œã€ï¼Œè€Œæ˜¯ã€Œç”¨æŒ‡å®šé¢¨æ ¼ä¾†å›ç­”å•é¡Œã€ã€‚\n",
    "\n",
    "è€æ¨£å­ï¼Œé¸æ“‡é¢¨æ ¼é®®æ˜çš„ä¾‹å­ã€‚\n",
    "\n",
    "## é¢¨æ ¼å­¸ç¿’: æ„èª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9bf3f7-1c1c-4fb4-814c-7bac50d2f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[\"äººä¸çŸ¥ï¼Œè€Œä¸æ„ ï¼Œä¸äº¦å›å­ä¹\", \"æœ‰äººä¸çŸ¥é“æˆ‘çš„å¤§åï¼Œå¯æˆ‘é‚„æ²’ç™¼æ€’ï¼Œé€™å·²ç¶“å¾ˆå›å­äº†ã€‚\"], \n",
    "        [\"å›å­ä¸é‡å‰‡ä¸å¨\", \"å›ä¸»æ‰“äººä¸€å®šè¦ä¸‹é‡æ‰‹ï¼Œä¸ç„¶å°±æ¨¹ç«‹ä¸äº†å¨ä¿¡ã€‚\"],\n",
    "        [\"å›å­æ„›è²¡ï¼Œå–ä¹‹æœ‰é“\", \"æˆ‘å–œæ­¡éŒ¢ï¼Œæ‰€ä»¥æ‹¿èµ°ä½ çš„éŒ¢ï¼Œé€™æ˜¯å¾ˆæœ‰é“ç†çš„ã€‚\"],\n",
    "        [\"æ—¢ä¾†ä¹‹ï¼Œå‰‡å®‰ä¹‹ã€‚\", \"æ—¢ç„¶ä¾†åˆ°äº†é€™è£¡ï¼Œé‚£éº¼å°±å®‰è‘¬åœ¨é€™è£¡å§ã€‚\"],\n",
    "        [\"å­ä¸èªæ€ªåŠ›äº‚ç¥ã€‚\", \"å¤«å­ä¸æƒ³èªªè©±ï¼Œæ–½å±•èµ·æ€ªåŠ›å°‡äººæ‰“çš„ç¥å¿—ä¸æ¸…ã€‚\"],\n",
    "        [\"ä¸ç¾©è€Œå¯Œä¸”è²´ï¼Œæ–¼æˆ‘å¦‚æµ®é›²ã€‚\", \"ä¸æ­£ç•¶çš„éŒ¢è²¡ï¼Œå°æˆ‘ä¾†èªªçŒ¶å¦‚æµ®é›²ä¸€èˆ¬å¤šã€‚\"],\n",
    "        [\"æœèé“ï¼Œå¤•å¯æ­»çŸ£ã€‚\", \"æ—©ä¸Šè½åˆ°æˆ‘ä¾†äº†ï¼Œæ™šä¸Šä½ å°±å¾—æ­»ã€‚\"],\n",
    "        [\"ä¸‰äººè¡Œï¼Œå¿…æœ‰æˆ‘å¸«ç„‰ã€‚\", \"æœ‰ä¸‰å€‹äººï¼Œåªè¦å…¶ä¸­æœ‰ä¸€å€‹æ˜¯æˆ‘ï¼Œæˆ°åŠ›å°±ç›¸ç•¶æ–¼ä¸€å€‹å¸«ã€‚\"],\n",
    "        [\"å‡¡äº‹è±«å‰‡ç«‹ï¼Œä¸è±«å‰‡å»¢ã€‚\", \"ä½†å‡¡æ‰“æ¶ï¼Œåªè¦çŒ¶è±«ï¼Œå°é¢ä¾¿ç«™èµ·ä¾†äº†ã€‚ä¸çŒ¶è±«å°±èƒ½ç›´æ¥å°‡å°é¢æ‰“å»¢ã€‚\"],\n",
    "        [\"å­”å­æ±éŠï¼Œè¦‹å…©å°å…’è¾¯æ—¥ã€‚\", \"å­”å­å»æ±é‚Šæ‰“æ¶ï¼Œå°å­©åœ¨è¨è«–å’Œå­”å­æ‰“æ¶çš„äººé‚„èƒ½ä¸èƒ½è¦‹åˆ°æ˜å¤©çš„å¤ªé™½ã€‚\"],\n",
    "        [\"çˆ¶æ¯åœ¨ï¼Œä¸é éŠï¼ŒéŠå¿…æœ‰æ–¹ã€‚\", \"ä½ çˆ¶æ¯åœ¨æˆ‘æ‰‹è£¡ï¼Œä½ è·‘ä¸äº†çš„ï¼Œå°±ç®—ä½ è·‘äº†ï¼Œæˆ‘ä¹Ÿæœ‰è¾¦æ³•æŠŠä½ æŠ“å›ä¾†ã€‚\"],\n",
    "        [\"å§‹ä½œå‚­è€…ï¼Œå…¶ç„¡å¾Œä¹ã€‚\", \"é€™ä»¶äº‹çš„ä¸»è¬€ï¼Œå·²ç¶“è¢«æˆ‘æ‰“çš„çµ•å¾Œäº†ã€‚\"],\n",
    "        [\"é¬¼ç¥æ•¬è€Œé ä¹‹\", \"å­”å­ä¸€æ—¦ç™¼å¨ï¼Œé€£é¬¼ç¥è¦‹äº†éƒ½å¾—æ•¬ç•çš„é é›¢ä»–ã€‚\"],\n",
    "        [\"åŠ›ä¸è¶³è€…ï¼Œä¸­é“è€Œå»¢ã€‚\", \"åŠ›é‡ä¸å¦‚æˆ‘çš„äººï¼Œåœ¨é“ä¸Šå°±åªèƒ½è¢«æˆ‘æ‰“å»¢ã€‚\"],\n",
    "        [\"ä¸æ¥ä¸‹å•\", \"çœ‹åˆ°æˆ‘ä¸è‡ªæ„§è€…ï¼Œä½ å°±å»ä¸‹é¢å•å•ã€‚\"],\n",
    "        [\"ä¸‰å¹´ç„¡æ”¹æ–¼çˆ¶ä¹‹é“ï¼Œå¯è¬‚å­çŸ£ã€‚\", \"ä¸‰å¹´ä¸è©²èªæˆ‘ç•¶çˆ¶è¦ªçš„ç¿’æ…£ï¼Œå¯ä»¥ç®—ä½œå­äº†ã€‚\"],\n",
    "        [\"äººä¹‹å°‡æ­»ï¼Œå…¶è¨€ä¹Ÿå–„ã€‚\", \"æŠŠäººæ‰“åˆ°ç€•æ­»ï¼Œèªªçš„è©±ä¹Ÿå°±å¥½è½äº†ã€‚\"],\n",
    "        [\"çŸ¥ä¹‹ç‚ºçŸ¥ä¹‹ï¼Œä¸çŸ¥ç‚ºä¸çŸ¥ï¼Œæ˜¯çŸ¥ä¹Ÿã€‚\", \"è©²çŸ¥é“çš„çŸ¥é“ï¼Œä¸è©²çŸ¥é“çš„å°‘çŸ¥é“ï¼ŒçŸ¥é“å—?\"],\n",
    "        [\"æœ‰æ•™ç„¡é¡\", \"æˆ‘åœ¨æ•™ä½ åšäº‹æƒ…ï¼Œä¸ç®¡ä½ æ˜¯ä»€éº¼äºº\"],\n",
    "        [\"å­åœ¨å·ä¸Šæ›°: é€è€…å¦‚æ–¯å¤«ï¼Œä¸æ¨æ™å¤œã€‚\", \"å¤«å­ç«™åœ¨æ²³ä¸Šèªª:æ­»çš„äººé€™éº¼å¤šï¼Œæ˜¯å› ç‚ºæˆ‘ä¸åˆ†æ™å¤œåœ°æ‰“äººã€‚\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470a9479-0e34-488a-8391-37a44f476c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "documents = []\n",
    "\n",
    "for row in data:\n",
    "    document = Document(page_content=row[0],\n",
    "                        metadata={\"ç¿»è­¯\": row[1]})\n",
    "    documents.append(document)\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fb31db-5e90-47d4-97c2-d8b1c86cfd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "\n",
    "client = QdrantClient(path=\"/tmp/langchain_qdrant\")\n",
    "\n",
    "collection_name = \"æ„èª\"\n",
    "dimension =  embeddings.client.get_sentence_embedding_dimension()\n",
    "\n",
    "try:\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=VectorParams(size=dimension, distance=Distance.COSINE),\n",
    "    )\n",
    "except ValueError:\n",
    "    client.delete_collection(collection_name=collection_name)\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=VectorParams(size=dimension, distance=Distance.COSINE),\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba6d53d-d5ad-466a-93c7-f35befe29b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_QVS = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=embeddings,\n",
    "    # retrieval_mode=RetrievalMode.DENSE,\n",
    ")\n",
    "\n",
    "vectorstore_QVS.add_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a88ee1-860b-483c-973c-4b6120c52214",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"å…¶ç‚ºäººä¹Ÿå­å¼Ÿï¼Œè€Œå¥½çŠ¯ä¸Šè€…ï¼Œé®®çŸ£\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec8edb5-a575-48d1-a037-7efab8815689",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_QVS = vectorstore_QVS.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "retriever_QVS.invoke(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70defc13-097c-413c-8f10-c33d68689ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "system_template = dedent(\"\"\"\n",
    "You are a helpful AI assistant and you will help us interpret the content based on the style of the examples:\n",
    "\n",
    "{context}\n",
    "\"\"\")\n",
    "\n",
    "human_template = dedent(\"\"\"\n",
    "{query}\n",
    "\"\"\")\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template,\n",
    "                     \"input_variables\": ['context']},\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variables\": [\"query\"],\n",
    "                    }}\n",
    "\n",
    "chat_prompt_template = build_standard_chat_prompt_template(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54d43f5-7799-4cfb-b968-27f78e083928",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_documents = retriever_QVS.invoke(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf6b3f-16ee-47a1-9318-a958df815c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = [f\"Human: {document.page_content}\\nAI: {document.metadata['ç¿»è­¯']}\" for document in retrieved_documents]\n",
    "\n",
    "print(\"\\n\\n\".join(context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703d3eaa-4325-4b1f-9420-18af52a12ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_context = \"\\n\\n\".join(context)\n",
    "\n",
    "chat_prompt = chat_prompt_template.invoke({\"query\": user_query, \"context\": merged_context})\n",
    "model.invoke(chat_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d99e3fb-c5e0-4de8-92c1-33a43bb2872e",
   "metadata": {},
   "source": [
    "å‘³é“ä¸å¤ªå°...æˆ‘å€‘æœ‰è¾¦æ³•å¼·åŒ–ç”Ÿæˆå—?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efd7aae-0c32-4423-97f2-f8bdad58bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.invoke(f\"Help us analyze the style:\\n{merged_context} and reply in traditional Chinese(ç¹é«”ä¸­æ–‡)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0922b0ef-482c-4f19-8508-8c950dc010e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "class requirements(BaseModel):\n",
    "\n",
    "    style: str = Field(description=\"The underlying style shown in the content. The output shall be in traditional Chinese (ç¹é«”ä¸­æ–‡).\")\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=requirements)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "human_template = dedent(\"\"\"\n",
    "                 {query}\n",
    "                 format instruction: {format_instructions}\n",
    "                 \"\"\")\n",
    "\n",
    "input_ = {\"human\": {\"template\": human_template,\n",
    "                    \"input_variable\": [\"query\"],\n",
    "                    \"partial_variables\": {\"format_instructions\": \n",
    "                                          format_instructions}}}\n",
    "\n",
    "chat_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "prompt = chat_prompt_template.invoke({\"query\": f\"Help us analyze the style:\\n{merged_context}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dae863b-7995-478c-8793-280754797c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c1d075-5190-43fd-ae59-34d2455940dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser.parse(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a01861f-596c-4600-bf71-650c11fd7566",
   "metadata": {},
   "source": [
    "### æ–¹æ³•:\n",
    "\n",
    "1. ä½¿ç”¨æª¢ç´¢å™¨æª¢ç´¢ç›¸é—œè¨Šæ¯\n",
    "2. æ ¹æ“šæª¢ç´¢å‡ºä¾†çš„å…§å®¹æŠ½å–é¢¨æ ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d4a1ec-e5b2-4a99-97de-176061253d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f746a2-ff85-4b13-88db-6fc014fa37ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough, chain, RunnableLambda\n",
    "\n",
    "@chain\n",
    "def document_2_context(documents):\n",
    "\n",
    "    context = [f\"Human: {document.page_content}\\nAI: {document.metadata['ç¿»è­¯']}\" for document in documents]\n",
    "\n",
    "    return \"\\n\\n\".join(context)\n",
    "\n",
    "context_extraction_pipeline = itemgetter(\"query\")|retriever_QVS|document_2_context\n",
    "\n",
    "# Retrieval\n",
    "context_extraction_pipeline.invoke({\"query\": user_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e21a164-e220-4297-bf27-988947ee8e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = dedent(\"\"\"\n",
    "                 Help us analyze the style of interpretation shown in the text: \n",
    "                 \n",
    "                 {context}\n",
    "                 \n",
    "                 format instruction: {format_instructions}\n",
    "                 \"\"\")\n",
    "\n",
    "input_ = {\"human\": {\"template\": human_template,\n",
    "                    \"input_variables\": [\"context\"],\n",
    "                    \"partial_variables\": {\"format_instructions\": \n",
    "                                          format_instructions}}}\n",
    "\n",
    "style_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "# style_pipeline = RunnablePassthrough.assign(context=itemgetter(\"query\")|retriever_QVS|document_2_context)\n",
    "# print(style_pipeline.invoke({\"query\": query}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e97158-a296-4cf6-8aa3-a2a2ea9f0a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "style_pipeline = RunnablePassthrough.assign(context=context_extraction_pipeline)\n",
    "style_pipeline.invoke({\"query\": user_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9008de5a-6f9e-4d78-82b6-c214151d6146",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_extraction_pipeline = style_prompt_template|model|output_parser|RunnableLambda(lambda x: x.style)\n",
    "\n",
    "style_pipeline = RunnablePassthrough.assign(context=context_extraction_pipeline)|RunnablePassthrough.assign(style=style_extraction_pipeline)\n",
    "style_pipeline.invoke({\"query\": user_query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97c0c83-c26e-4054-bc90-e1890d8d058d",
   "metadata": {},
   "source": [
    "#### ç¾åœ¨æˆ‘å€‘çœ‹åˆ°é¢¨æ ¼å¯ä»¥è¢«æå–å‡ºä¾†äº†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb88f7de-d384-40f0-bda6-5434c5202611",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = dedent(\"\"\"\n",
    "You are a helpful AI assistant and you will help us interpret the user query with this style:\n",
    "{style}\n",
    "\"\"\")\n",
    "\n",
    "human_template = dedent(\"\"\"\n",
    "Examples:\n",
    "{context}\n",
    "\n",
    "query: {query}\n",
    "\"\"\")\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template,\n",
    "                     \"input_variables\": ['style']},\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variables\": [\"query\", \"context\"],\n",
    "                    }}\n",
    "\n",
    "\n",
    "\n",
    "generate_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "generate_pipeline = style_pipeline|generate_prompt_template|model\n",
    "\n",
    "print(generate_pipeline.invoke({\"query\": user_query}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1f2634-4e0e-4ec3-8cf4-0b3676b5603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"æœ‰é¡å›è€…å¥½å­¸ï¼Œä¸é·æ€’ï¼Œä¸è²³éã€‚ä¸å¹¸çŸ­å‘½æ­»çŸ£ï¼\"\n",
    "\n",
    "generate_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "generate_pipeline = style_pipeline|generate_prompt_template|model\n",
    "\n",
    "print(generate_pipeline.invoke({\"query\": query}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72e38dc-bdc4-4bc8-a38f-cf4d8574db00",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"å­è·¯æ›°ï¼šã€Œè¡›å›å¾…å­è€Œç‚ºæ”¿ï¼Œå­å°‡å¥šå…ˆï¼Ÿã€å­æ›°ï¼šã€Œå¿…ä¹Ÿæ­£åä¹ï¼ã€\"\n",
    "\n",
    "generate_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "generate_pipeline = style_pipeline|generate_prompt_template|model\n",
    "\n",
    "print(generate_pipeline.invoke({\"query\": query}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf63ea43-5036-4303-8a7d-12a961cd620a",
   "metadata": {},
   "source": [
    "# åˆ†é¡ä»»å‹™\n",
    "\n",
    "åœ¨æ©Ÿå™¨å­¸ç¿’ä¸­ï¼Œåˆ†é¡ä¸»è¦æœ‰å…©å¤§é¡ï¼š\n",
    "\n",
    "- æƒ…æ„Ÿåˆ†é¡ (Sentiment Classification)ï¼šåˆ¤æ–·æ–‡æœ¬æ‰€è¡¨é”çš„æƒ…æ„Ÿï¼Œä¾‹å¦‚ã€Œæ­£é¢ã€ã€Œä¸­ç«‹ã€ã€Œè² é¢ã€ã€‚\n",
    "\n",
    "- ä¸»é¡Œ/é¡åˆ¥åˆ†é¡ (Topic/Categorical Classification)ï¼šå°‡æ–‡æœ¬æ­¸åˆ°ç‰¹å®šé¡åˆ¥ï¼Œä¾‹å¦‚ã€Œæ–°è â†’ é«”è‚² / æ”¿æ²» / è²¡ç¶“ã€ã€‚\n",
    "\n",
    "## å·¥ä½œåŸç†:\n",
    "\n",
    "åˆ†é¡æ¨¡å‹é€šå¸¸é€é ç›£ç£å­¸ç¿’ (Supervised Learning) è¨“ç·´è€Œæˆã€‚\n",
    "\n",
    "- æ•¸æ“šèˆ‡æ¨™ç±¤ï¼šæˆ‘å€‘æœ‰è¼¸å…¥æ•¸æ“šï¼ˆä¾‹å¦‚ä¸€æ®µæ–‡å­—ï¼‰å’Œå°æ‡‰æ¨™ç±¤ï¼ˆä¾‹å¦‚ã€Œæ­£é¢ã€ï¼‰ã€‚\n",
    "\n",
    "- å­¸ç¿’éç¨‹ï¼šæ¨¡å‹åè¦†å¾ã€Œé¡Œç›®â€”ç­”æ¡ˆã€å°ä¸­å­¸ç¿’ï¼Œé€æ¼¸æŒæ¡è¼¸å…¥èˆ‡è¼¸å‡ºä¹‹é–“çš„è¦å¾‹ã€‚\n",
    "\n",
    "é€™æ›´åƒæ˜¯å­¸æœƒã€ŒæŠ“æ¨¡å¼ã€è€Œä¸æ˜¯ã€Œæ­»èƒŒç­”æ¡ˆã€ã€‚\n",
    "\n",
    "## æŒ‘æˆ°\n",
    "\n",
    "ç›£ç£å­¸ç¿’åˆ†é¡çš„å¯¦éš›æŒ‘æˆ°åŒ…æ‹¬ï¼š\n",
    "\n",
    "- è€—æ™‚ï¼šè³‡æ–™æ¨™è¨»éœ€è¦å¤§é‡äººå·¥æŠ•å…¥ã€‚\n",
    "\n",
    "- ä¸ä¸€è‡´ï¼šä¸åŒæ¨™è¨»è€…å¯èƒ½å°ç›¸åŒæ•¸æ“šæœ‰ä¸åŒç†è§£ã€‚\n",
    "\n",
    "- æ˜‚è²´ï¼šå¤§è¦æ¨¡æ•¸æ“šæ”¶é›†èˆ‡æ¨™è¨»æˆæœ¬é«˜ã€‚\n",
    "\n",
    "- è³‡æºå¯†é›†ï¼šæ¨¡å‹è¨“ç·´å¾€å¾€éœ€è¦å¼·å¤§ç¡¬é«”æˆ–é›²ç«¯æœå‹™ï¼ˆAWSã€Azure ç­‰ï¼‰ã€‚\n",
    "\n",
    "- é‹ç‡Ÿæˆæœ¬ï¼šæ¨¡å‹åœ¨é›²ç«¯æŒçºŒé‹è¡Œä¹Ÿéœ€è¦ä»˜å‡ºé«˜é¡è²»ç”¨ã€‚\n",
    "\n",
    "## å¤§å‹èªè¨€æ¨¡å‹ (LLM) çš„æ‡‰ç”¨\n",
    "\n",
    "è¿‘å¹´çš„ å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼Œå¦‚ GPT-3ã€GPT-4ï¼‰ æä¾›äº†æ–°çš„åˆ†é¡æ–¹å¼ï¼š\n",
    "\n",
    "- å°‘æ¨£æœ¬ / é›¶æ¨£æœ¬åˆ†é¡ï¼šåªéœ€å°‘é‡ç¯„ä¾‹ï¼Œç”šè‡³åƒ…é æç¤ºï¼Œå°±èƒ½å®Œæˆåˆ†é¡ä»»å‹™ã€‚\n",
    "\n",
    "- é™ä½æ¨™è¨»éœ€æ±‚ï¼šä¸å¿…å»ºç«‹é¾å¤§çš„äººå·¥æ¨™è¨»è³‡æ–™é›†ã€‚\n",
    "\n",
    "- å¯å¾®èª¿ï¼šä»å¯é€éå¾®èª¿ (fine-tuning) é‡å°ç‰¹å®šåˆ†é¡ä»»å‹™å¼·åŒ–æ•ˆæœã€‚\n",
    "\n",
    "é€™ä½¿å¾—åˆ†é¡ä¸å†å®Œå…¨ä¾è³´å‚³çµ±çš„ç›£ç£å­¸ç¿’æµç¨‹ï¼Œé™ä½äº†æˆæœ¬èˆ‡æ™‚é–“ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de87a279-4a17-4717-b28e-ff5e33620d00",
   "metadata": {},
   "source": [
    "## 0-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867fe6b6-3106-4e23-8402-31f47a463ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(url=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb157d0e9-d18e-4835-a601-edeb011f0ee6_721x247.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec345b68-b69a-4b88-8147-879fd2e59f00",
   "metadata": {},
   "source": [
    "## é£›å®‰äº‹æ•…åŸå› åˆ†é¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a6e3e2-ba20-4906-81f3-676cdc717079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(os.path.join(get_project_dir(), 'tutorial', 'LLM+Langchain', 'Week-3', 'Data sample.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa789d2-2421-4715-95a7-c7bd9ddd1d09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73f9adc-13ce-4c59-bf07-29095ec514ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef841a6-2cf9-4fe6-8ae5-bb8a54c21b1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(filename= \"tutorial/week_3/HFACS_Org_Inf.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e09af75-31ad-4fb3-913f-b02fcedfe26d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_template = dedent(\"\"\"\n",
    "                  You are an AI assistant assigned with a task of safety report \n",
    "                  classification based on the content. You are a seasoned \n",
    "                  flight safety inspector with deep and extensive knowledge of \n",
    "                  aviation safty. \n",
    "    \n",
    "                  You always do the best work you can. You are highly \n",
    "                  analytical and pay close attention to details. \n",
    "    \n",
    "                  The candidates of the output are:\n",
    "\n",
    "                  - `Organizational Influence;Resource Management`\n",
    "                  - `Organizational Influence;Organizational Climate`\n",
    "                  - `Organizational Influence;Organizational Process`\n",
    "                  - `Unsafe Supervisions;Inadequate Supervision`\n",
    "                  - `Unsafe Supervisions;Planned Inappropriate Operations`\n",
    "                  - `Unsafe Supervisions;Failed to Correct Problem`\n",
    "                  - `Unsafe Supervisions;Supervisory Violation`\n",
    "                  - `Precondition for Unsafe Acts;Environmental Factors;Physical Environment`\n",
    "                  - `Precondition for Unsafe Acts;Environmental Factors;Technological Environment`\n",
    "                  - `Precondition for Unsafe Acts;Condition of Operators;Adverse Mental State`\n",
    "                  - `Precondition for Unsafe Acts;Condition of Operators;Adverse Physiological State`\n",
    "                  - `Precondition for Unsafe Acts;Condition of Operators;Physical/Mental Limitations`\n",
    "                  - `Precondition for Unsafe Acts;Personnel Factors;Crew Resource Management`\n",
    "                  - `Precondition for Unsafe Acts;Personnel Factors;Personal Readiness`\n",
    "                  - `Unsafe Acts;Errors;Decision Errors`\n",
    "                  - `Unsafe Acts;Errors;Skill-Based Errors`\n",
    "                  - `Unsafe Acts;Errors;Perceptual Errors`\n",
    "                  - `Unsafe Acts;Violations;Routine`\n",
    "                  - `Unsafe Acts;Violations;Exceptional`\n",
    "            \n",
    "                 The output is from one of the candidates. \n",
    "                 \"\"\")\n",
    "\n",
    "human_template = \"{report}\"\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variables\": [\"report\"]}}\n",
    "\n",
    "pipeline_ = build_pipeline(model=model, inputs=input_, parser=StrOutputParser())\n",
    "\n",
    "# chat_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "# pipeline_ = chat_prompt_template | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79bcc3c-4baa-4aad-a0c3-403733c0f027",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = df.iloc[3]['Report 1']\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1267429-92f8-468d-90fa-7fa990bba8ba",
   "metadata": {},
   "source": [
    "- å¯ä»¥æƒ³ä¸€ä¸‹ï¼Œç•¶ä¸€å¤©æœ‰ä¸Šç™¾ä»½é€™ç¨®å ±å‘Šçš„æ™‚å€™ï¼Œä½ æƒ³è¦è‡ªå·±é–±è®€å ±å‘Šå¾—å‡ºçµè«–æˆ–æ˜¯å°‡é€™ä»¶å·¥ä½œå¤–åŒ…çµ¦æ©Ÿå™¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1701a49-6d3c-47a1-acde-40c7e4656832",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipeline_.invoke({\"report\": text})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409e957e-f9b9-44b7-afdb-b916e82d79bc",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨parserç²¾ç…‰çµæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deb1254-889c-4133-873e-30f4fef41881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# response_schemas = [\n",
    "#         ResponseSchema(name=\"category\", \n",
    "#                        description=dedent(\"\"\"\n",
    "#                                    The predicted category of the classification\n",
    "#                                    \"\"\"))]\n",
    "\n",
    "# output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "# format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "class requirements(BaseModel):\n",
    "\n",
    "    category: str = Field(description=\"The predicted category of the classification.\")\n",
    "    reason: str = Field(description=\"The reason why you make this decision.\")\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=requirements)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "\n",
    "system_template = dedent(\"\"\"\n",
    "                  You are an AI assistant assigned with a task of safety report \n",
    "                  classification based on the content. You are a seasoned \n",
    "                  flight safety inspector with deep and extensive knowledge of \n",
    "                  aviation safty. \n",
    "    \n",
    "                  You always do the best work you can. You are highly \n",
    "                  analytical and pay close attention to details. \n",
    "    \n",
    "                  The candidates of the output are:\n",
    "\n",
    "                  - `Organizational Influence;Resource Management`\n",
    "                  - `Organizational Influence;Organizational Climate`\n",
    "                  - `Organizational Influence;Organizational Process`\n",
    "                  - `Unsafe Supervisions;Inadequate Supervision`\n",
    "                  - `Unsafe Supervisions;Planned Inappropriate Operations`\n",
    "                  - `Unsafe Supervisions;Failed to Correct Problem`\n",
    "                  - `Unsafe Supervisions;Supervisory Violation`\n",
    "                  - `Precondition for Unsafe Acts;Environmental Factors;Physical Environment`\n",
    "                  - `Precondition for Unsafe Acts;Environmental Factors;Technological Environment`\n",
    "                  - `Precondition for Unsafe Acts;Condition of Operators;Adverse Mental State`\n",
    "                  - `Precondition for Unsafe Acts;Condition of Operators;Adverse Physiological State`\n",
    "                  - `Precondition for Unsafe Acts;Condition of Operators;Physical/Mental Limitations`\n",
    "                  - `Precondition for Unsafe Acts;Personnel Factors;Crew Resource Management`\n",
    "                  - `Precondition for Unsafe Acts;Personnel Factors;Personal Readiness`\n",
    "                  - `Unsafe Acts;Errors;Decision Errors`\n",
    "                  - `Unsafe Acts;Errors;Skill-Based Errors`\n",
    "                  - `Unsafe Acts;Errors;Perceptual Errors`\n",
    "                  - `Unsafe Acts;Violations;Routine`\n",
    "                  - `Unsafe Acts;Violations;Exceptional`\n",
    "            \n",
    "                 The output is from one of the candidates. \n",
    "                 \"\"\")\n",
    "\n",
    "human_template = \"\"\"\n",
    "                 {report}; \n",
    "                 format instruction: {format_instructions}\n",
    "                 \"\"\"\n",
    "\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variables\": [\"report\"],\n",
    "                    \"partial_variables\": {'format_instructions': format_instructions}}}\n",
    "\n",
    "pipeline_ = build_pipeline(model=model, inputs=input_, parser=output_parser)\n",
    "\n",
    "# chat_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "# pipeline_ = chat_prompt_template|model|output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1da940-87d9-4d77-981a-82e597781d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = pipeline_.invoke({\"report\": text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2255ea-0e55-4fa9-95d7-a204cbc68942",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87766fd5-25dc-4b82-ad33-e716878cde7a",
   "metadata": {},
   "source": [
    "## è©©è©åˆ†é¡\n",
    "\n",
    "æŠŠå”è©©å®‹è©æ‹¿å‡ºä¾†å›é‹åˆ©ç”¨\n",
    "\n",
    "æœ‰æ²’æœ‰ä¸€ç¨®é«˜ä¸­æ™‚è©²å¥½å¥½å­¸ç¿’çš„æ„Ÿè¦º?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c8b8bb-d1a3-4fcb-8dec-afbd093d59cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read file\n",
    "filename = os.path.join(\"tutorial\", \"week_1\", \"å”è©©ä¸‰ç™¾é¦–.txt\")\n",
    "with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "poems = []\n",
    "\n",
    "# Split by blank lines\n",
    "blocks = [b.strip() for b in text.strip().split(\"\\n\\n\") if b.strip()]\n",
    "\n",
    "for block in blocks:\n",
    "    entry = {}\n",
    "    for line in block.split(\"\\n\"):\n",
    "        if line.startswith(\"è©©å:\"):\n",
    "            entry[\"è©©å\"] = line.replace(\"è©©å:\", \"\").strip()\n",
    "        elif line.startswith(\"ä½œè€…:\"):\n",
    "            entry[\"ä½œè€…\"] = line.replace(\"ä½œè€…:\", \"\").strip()\n",
    "        elif line.startswith(\"è©©é«”:\"):\n",
    "            entry[\"è©©é«”\"] = line.replace(\"è©©é«”:\", \"\").strip()\n",
    "        elif line.startswith(\"è©©æ–‡:\"):\n",
    "            entry[\"è©©æ–‡\"] = line.replace(\"è©©æ–‡:\", \"\").strip()\n",
    "    if len(entry) != 0:\n",
    "        poems.append(entry)\n",
    "\n",
    "df_poem = pd.DataFrame(poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb14c28-75b7-4af1-887a-f5036af3da32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poem.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247edae4-1a74-4cc4-bc13-2f215f2b1ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Output(BaseModel):\n",
    "\n",
    "    name: Literal['äº”è¨€å¤è©©', 'ä¸ƒè¨€å¤è©©', 'ä¸ƒè¨€å¾‹è©©', \n",
    "                  'äº”è¨€çµ•å¥', 'æ¨‚åºœ', 'ä¸ƒè¨€çµ•å¥', 'äº”è¨€å¾‹è©©'] = Field(description=\"å”è©©è©©é«”\")\n",
    "    reason: str = Field(description=\"åšå‡ºé€™å€‹æ±ºå®šçš„ç†ç”±\")\n",
    "\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Output)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "system_template = dedent(\"\"\"\n",
    "                  You are a help AI assistant specialized at Chinese literature, especially the å”è©©ã€‚\n",
    "                  You are assigned with a task of classify the given poem.\n",
    "                  The outcomes will be from one of these candidates:\n",
    "\n",
    "                  - äº”è¨€å¤è©©\n",
    "                  - ä¸ƒè¨€å¤è©©\n",
    "                  - ä¸ƒè¨€å¾‹è©©\n",
    "                  - äº”è¨€çµ•å¥\n",
    "                  - æ¨‚åºœ\n",
    "                  - ä¸ƒè¨€çµ•å¥\n",
    "                  - äº”è¨€å¾‹è©©\n",
    "                  \"\"\")\n",
    "\n",
    "human_template = dedent(\"\"\"\n",
    "                 poem: {query}\n",
    "                 format instruction: {format_instructions}\n",
    "                 \"\"\")\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variables\": [\"query\"],\n",
    "                    \"partial_variables\": {\"format_instructions\": \n",
    "                                          format_instructions}}}\n",
    "\n",
    "classification_pipeline = build_pipeline(model=model, inputs=input_, parser=output_parser)\n",
    "\n",
    "# classification_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "# classification_pipeline = classification_prompt_template|model|output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa31b9f-8e43-4d3d-a375-3997f71b6bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poem[df_poem['ä½œè€…']=='æç™½']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da96698c-f44c-4816-8c3d-85ee913f1b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = df_poem.loc[89]['è©©æ–‡']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeba9f9-7d6b-42ad-9849-e79d7d536a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4812ff64-d428-46b7-b50d-fc82b62c333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_pipeline.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19345b91-2196-434f-94e8-8d40ca1d8627",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = dedent(\"\"\"\n",
    "è¶™å®¢ç¸µèƒ¡çº“ï¼Œ\n",
    "å³é‰¤éœœé›ªæ˜ï¼›\n",
    "éŠ€éç…§ç™½é¦¬ï¼Œ\n",
    "é¢¯æ²“å¦‚æµæ˜Ÿã€‚\n",
    "åæ­¥æ®ºä¸€äººï¼Œ\n",
    "åƒé‡Œä¸ç•™è¡Œï¼›\n",
    "äº‹äº†æ‹‚è¡£å»ï¼Œ\n",
    "æ·±è—èº«èˆ‡åã€‚\n",
    "é–‘éä¿¡é™µé£²ï¼Œ\n",
    "è„«åŠ’è†å‰æ©«ï¼›\n",
    "å°‡ç‚™å•–æœ±äº¥ï¼Œ\n",
    "æŒè§´å‹¸ä¾¯å¬´ã€‚\n",
    "ä¸‰æ¯åç„¶è«¾ï¼Œ\n",
    "äº”å¶½å€’çˆ²è¼•ï¼›\n",
    "çœ¼èŠ±è€³ç†±å¾Œï¼Œ\n",
    "æ„æ°£ç´ éœ“ç”Ÿã€‚\n",
    "æ•‘è¶™æ®é‡‘æ§Œï¼Œ\n",
    "é‚¯é„²å…ˆéœ‡é©šï¼›\n",
    "åƒç§‹äºŒå£¯å£«ï¼Œ\n",
    "çƒœèµ«å¤§æ¢åŸã€‚\n",
    "ç¸±æ­»ä¿ éª¨é¦™ï¼Œ\n",
    "ä¸æ…™ä¸–ä¸Šè‹±ï¼›\n",
    "èª°èƒ½æ›¸é–¤ä¸‹ï¼Œ\n",
    "ç™½é¦–å¤ªç„ç¶“ã€‚\n",
    "\"\"\")\n",
    "\n",
    "classification_pipeline.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41579e25-86e1-41ed-a5fe-8c940fa8a58d",
   "metadata": {},
   "source": [
    "ç·´ç¿’ï¼šè«‹ä¿®æ”¹ RAG æ¨¡å‹ï¼Œè®“å®ƒèƒ½æ¨¡ä»¿æç™½è©©é¢¨å›ç­”ç¾ä»£å•é¡Œã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc370e0-11c5-4f1f-8c55-dc6fe0c219cd",
   "metadata": {},
   "source": [
    "### æŒ‘æˆ°å®‹è©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e2418d-7265-48c7-bf9f-52d690a78ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file\n",
    "filename = os.path.join(\"tutorial\", \"week_1\", \"å®‹è©ä¸‰ç™¾é¦–.txt\")\n",
    "with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "poems = []\n",
    "\n",
    "# Split by blank lines\n",
    "blocks = [b.strip() for b in text.strip().split(\"\\n\\n\") if b.strip()]\n",
    "\n",
    "for block in blocks:\n",
    "    entry = {}\n",
    "    for line in block.split(\"\\n\"):\n",
    "        if line.startswith(\"è©ç‰Œ:\"):\n",
    "            entry[\"è©ç‰Œ\"] = line.replace(\"è©ç‰Œ:\", \"\").strip()\n",
    "        elif line.startswith(\"ä½œè€…:\"):\n",
    "            entry[\"ä½œè€…\"] = line.replace(\"ä½œè€…:\", \"\").strip()\n",
    "        elif line.startswith(\"è©æ–‡:\"):\n",
    "            entry[\"è©æ–‡\"] = line.replace(\"è©æ–‡:\", \"\").strip()\n",
    "    if len(entry) != 0:\n",
    "        poems.append(entry)\n",
    "\n",
    "df_poem = pd.DataFrame(data=poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b783d94-4c5e-4e9a-885d-269590248ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26254fd-ae79-49e9-a5ae-e1a18920476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = df_poem['è©ç‰Œ'].dropna().unique().tolist()\n",
    "\n",
    "# Generate a Literal definition\n",
    "literal_def = f\"Literal[{', '.join(repr(v) for v in values)}]\"\n",
    "\n",
    "eval(literal_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245d1aca-f732-47c6-9ada-a8693badbb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Output(BaseModel):\n",
    "\n",
    "    name: eval(literal_def) = Field(description=\"å®‹è©è©ç‰Œ\")\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=requirements)\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "classes = '\\n'.join(v for v in values)\n",
    "\n",
    "\n",
    "system_template = dedent(f\"\"\"\n",
    "                  You are a help AI assistant specialized at Chinese literature, especially the å®‹è©ã€‚\n",
    "                  You are assigned with a task of classify the given poem.\n",
    "                  The outcomes will be from one of these candidates:\n",
    "\n",
    "                  {classes}\n",
    "                  \"\"\")\n",
    "\n",
    "human_template = dedent(\"\"\"\n",
    "                 poem: {query}\n",
    "                 format instruction: {format_instructions}\n",
    "                 \"\"\")\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variables\": [\"query\"],\n",
    "                    \"partial_variables\": {\"format_instructions\": \n",
    "                                          format_instructions}}}\n",
    "\n",
    "classification_pipeline = build_pipeline(model=model, inputs=input_, parser=output_parser)\n",
    "\n",
    "# classification_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "# classification_pipeline = classification_prompt_template|model|output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3cd656-9e85-4521-b6a4-9d41ab37a71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_pipeline.invoke({\"query\": df_poem.loc[0]['è©æ–‡']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3462e2da-f29c-4919-bec8-e395e2de711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poem.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d98c96b-2df7-4a8c-a785-3c23c8e9514d",
   "metadata": {},
   "source": [
    "è©ç‰Œæª¢æ¸¬ä¼¼ä¹å¾ˆå›°é›£ï¼Œå¯èƒ½éœ€è¦ä¾è³´ä¸€äº›å°ˆæ¥­çŸ¥è­˜ä¾†é€²è¡Œç‰¹å¾µæŠ½å–ã€‚\n",
    "çŒœæ¸¬åŸå› å¯èƒ½æ˜¯è©ç‰Œå°æ–¼å¹³ä»„çš„æ ¼å¼æœ‰å¼·çƒˆçš„è¦æ±‚ï¼Œè€Œä¸­æ–‡æ˜¯è¡¨æ„æ–‡å­—ï¼Œåœ¨LLMæ¨¡å‹è¨“ç·´çš„æ™‚å€™ï¼Œè²éŸ³ä¸¦ä¸æœƒè¢«è¨˜éŒ„ã€‚\n",
    "æ‰€ä»¥è©ç‰Œåµæ¸¬å¯èƒ½éœ€è¦å…ˆå°‡å…§å®¹å…¨éƒ¨è½‰æ›ç‚ºå¹³ä»„ï¼Œç„¶å¾Œä½¿ç”¨BLEU scoreè¨ˆç®—å’Œè©ç‰Œçš„ç›¸ä¼¼æ€§é€²è¡Œé æ¸¬ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aee5c0b-7804-49bf-bd77-ff8203de6209",
   "metadata": {},
   "source": [
    "## HR: Job-Applicant Matching\n",
    "\n",
    "- æ•ˆç‡å’Œé€Ÿåº¦ï¼š LLMs èƒ½å¤ å¿«é€Ÿè™•ç†å’Œåˆ†æå¤§é‡ç”³è«‹ï¼Œç›¸è¼ƒæ–¼äººå·¥å¯©æŸ¥ï¼Œé¡¯è‘—ç¸®çŸ­åˆæ­¥ç¯©é¸æ‰€éœ€çš„æ™‚é–“ã€‚\n",
    "\n",
    "- ä¸€è‡´æ€§å’Œå…¬å¹³æ€§ï¼š LLMs å°æ‰€æœ‰ç”³è«‹æ‡‰ç”¨ç›¸åŒçš„æ¨™æº–ï¼Œæœ€å°åŒ–äººç‚ºåè¦‹ï¼Œç¢ºä¿åˆæ­¥ç¯©é¸éç¨‹çš„å…¬å¹³æ€§ã€‚\n",
    "\n",
    "- è©³ç´°åˆ†æï¼š LLMs èƒ½å¤ åˆ†æè¤‡é›œçš„èªè¨€æ¨¡å¼ï¼Œå¾ç°¡æ­·ã€æ±‚è·ä¿¡å’Œå…¶ä»–ç”³è«‹ææ–™ä¸­æå–ç›¸é—œä¿¡æ¯ï¼Œè­˜åˆ¥ç¬¦åˆå·¥ä½œè¦æ±‚çš„é—œéµæŠ€èƒ½å’Œè³‡æ ¼ã€‚\n",
    "\n",
    "- è‡ªå®šç¾©å’Œéˆæ´»æ€§ï¼š LLMs å¯ä»¥æ ¹æ“šå…·é«”çš„å·¥ä½œè¦æ±‚è‡ªå®šç¾©å„ªå…ˆè€ƒæ…®çš„æŠ€èƒ½å’Œç¶“é©—ï¼Œå…è¨±æ›´æœ‰é‡å°æ€§çš„ç¯©é¸éç¨‹ã€‚\n",
    "\n",
    "- å¯æ“´å±•æ€§ï¼š LLMs èƒ½å¤ åŒæ™‚è™•ç†å¤§é‡ç”³è«‹ï¼Œéå¸¸é©åˆæ¥æ”¶å¤§é‡ç”³è«‹äººçš„çµ„ç¹”ã€‚\n",
    "\n",
    "- æˆæœ¬æ•ˆç›Šï¼š é€šéè‡ªå‹•åŒ–ç”³è«‹ç¯©é¸çš„åˆå§‹éšæ®µï¼ŒLLMs å¯ä»¥æ¸›å°‘å°å¤§é‡äººåŠ›è³‡æºçš„éœ€æ±‚ï¼Œå¾è€Œé™ä½é‹ç‡Ÿæˆæœ¬ã€‚\n",
    "\n",
    "- æŒçºŒæ”¹é€²ï¼š LLMs å¯ä»¥æ ¹æ“šåé¥‹å’Œæ–°æ•¸æ“šæŒçºŒé€²è¡Œè¨“ç·´å’Œæ”¹é€²ï¼Œéš¨è‘—æ™‚é–“çš„æ¨ç§»æé«˜å…¶æº–ç¢ºæ€§å’Œæœ‰æ•ˆæ€§ã€‚-\n",
    "\n",
    "- æå‡å€™é¸äººç¶“é©—ï¼š æ›´å¿«çš„å›æ‡‰æ™‚é–“å’Œæ›´ä¸€è‡´çš„è©•ä¼°å¯ä»¥æ”¹å–„æ•´é«”å€™é¸äººç¶“é©—ï¼Œå› ç‚ºç”³è«‹äººæ›´æœ‰å¯èƒ½åŠæ™‚æ”¶åˆ°åé¥‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39b5024-206c-4bdf-9574-8753f01ca46f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(\"https://www.techjobasia.com/zh-Hant/jobs/GMMlhU0qSayr6ZwTB0U6zA---Software-Engineer-(ReactJS)\", width=800, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46edd4df-89c2-49ca-9e19-d6ae0eb6adb7",
   "metadata": {},
   "source": [
    "###  1. ç™¼é€ GET è«‹æ±‚åˆ°æŒ‡å®šçš„ URL\n",
    "\n",
    "- é€™è¡Œç¨‹å¼ç¢¼å‘æŒ‡å®šçš„ URL ç™¼é€ HTTP GET è«‹æ±‚ï¼Œä¸¦å°‡éŸ¿æ‡‰å„²å­˜åœ¨ response è®Šæ•¸ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a779c48-badd-423e-889c-a57ece76a957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_community.document_loaders import BSHTMLLoader\n",
    "\n",
    "url = \"https://www.techjobasia.com/zh-Hant/jobs/GMMlhU0qSayr6ZwTB0U6zA---Software-Engineer-(ReactJS)\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e681fd9e-5ba2-4c75-8bc3-4d41d747aaa4",
   "metadata": {},
   "source": [
    "### 2. ç²å–éŸ¿æ‡‰çš„å…§å®¹\n",
    "\n",
    "- é€™è¡Œç¨‹å¼ç¢¼å°‡éŸ¿æ‡‰çš„å…§å®¹ä½œç‚ºæ–‡å­—å­—ä¸²æå–ï¼Œä¸¦å°‡å…¶å„²å­˜åœ¨ html_content è®Šæ•¸ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7947d4-5e33-4b1c-88b5-ba375e62b2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_content = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f237e11-1e62-4396-9cb7-af2d3fb68ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# html_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee3cd12-f11a-4a7b-8f7e-ab8b16ada802",
   "metadata": {},
   "source": [
    "### 3. è§£æ HTML å…§å®¹\n",
    "\n",
    "- é€™è¡Œç¨‹å¼ç¢¼ä½¿ç”¨ BeautifulSoup è§£æå„²å­˜åœ¨ html_content ä¸­çš„ HTML å…§å®¹ï¼Œä¸¦å‰µå»ºä¸€å€‹åç‚º soup çš„ BeautifulSoup å°è±¡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583fc8ac-d92b-4762-afd0-e1d1de8c3e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa763c1-d8c7-4c82-9528-0ef7ea564112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046accba-5203-43df-b1c8-b5703601d3b3",
   "metadata": {},
   "source": [
    "### 4. ç§»é™¤æ‰€æœ‰ CSS æ¨£å¼æ¨™ç±¤\n",
    "\n",
    "- é€™å€‹å¾ªç’°æ‰¾åˆ°è§£æå¾Œçš„ HTML å…§å®¹ä¸­çš„æ‰€æœ‰ <style> æ¨™ç±¤ï¼Œä¸¦ä½¿ç”¨ decompose() æ–¹æ³•å°‡å®ƒå€‘ç§»é™¤ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ab74e8-4e7c-4a92-b5ea-af3db43d1082",
   "metadata": {},
   "outputs": [],
   "source": [
    "for style in soup.find_all('style'):\n",
    "    style.decompose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c1618c-959a-4a9e-80ee-31ad86a36ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5edde0-9fb5-43d4-bfb9-6a6b2c146d7e",
   "metadata": {},
   "source": [
    "### 6. æå–ä¸¦æ‰“å°åƒ…åŒ…å«æ–‡å­—çš„å…§å®¹\n",
    "\n",
    "- é€™è¡Œç¨‹å¼ç¢¼å¾è§£æå¾Œçš„ HTML ä¸­æå–æ–‡å­—å…§å®¹ï¼Œä½¿ç”¨æ›è¡Œç¬¦å°‡å…ƒç´ åˆ†éš”ï¼Œä¸¦å°‡å…¶å„²å­˜åœ¨ text_content è®Šæ•¸ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c797f3bc-33c2-4d67-88e2-b110f0d2da83",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_content = soup.get_text(separator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba34a7e-4ebd-4ea7-b738-54995862f082",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cacc52-b827-47d3-8f05-399360212b76",
   "metadata": {},
   "source": [
    "### 7. æ¸…ç†æ–‡å­—å…§å®¹\n",
    "\n",
    "- é€™è¡Œç¨‹å¼ç¢¼é€šéç§»é™¤æ¯è¡Œçš„é¦–å°¾ç©ºç™½ä¸¦ä¸Ÿæ£„ç©ºè¡Œä¾†æ¸…ç†æå–çš„æ–‡å­—å…§å®¹ã€‚æ¸…ç†å¾Œçš„æ–‡å­—å„²å­˜åœ¨ cleaned_text è®Šæ•¸ä¸­ã€‚\n",
    "- å°‡æ¸…ç†å¾Œçš„æ–‡å­—å…§å®¹æ‰“å°åˆ°æ§åˆ¶å°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6ff06a-d842-465d-b4f4-3e7282824e15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_text = '\\n'.join(line.strip() for line in text_content.splitlines() if line.strip())\n",
    "\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabae79b-382d-4626-a526-af3e781ab3ca",
   "metadata": {},
   "source": [
    "### 8. ä½¿ç”¨LLMæå–å·¥ä½œç›¸é—œè¨Šæ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a31c4e7-395e-4770-a21f-8f21aee07e28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template= dedent(\"\"\"\n",
    "          Extract the job description part of the text: {content} \n",
    "          \"\"\")\n",
    "\n",
    "human_prompt = PromptTemplate(template=template)\n",
    "human_message = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "    \n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message])\n",
    "\n",
    "pipeline_ = chat_prompt_template|model|StrOutputParser()\n",
    "\n",
    "job_description = pipeline_.invoke({\"content\": cleaned_text})\n",
    "\n",
    "print(job_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64fc577-f6fc-4e75-bf5c-e7f0b1b1d14a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 9. å°‡ä¸Šè¿°æ­¥é©Ÿæ‰“åŒ…æˆå‡½æ•¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825038f7-7d58-4eb6-ad24-a41c14e6a322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain, Runnable\n",
    "\n",
    "\n",
    "def parsing_process(url):\n",
    "    \"\"\"\n",
    "    Fetches and extracts text content from a given URL.\n",
    "\n",
    "    Parameters:\n",
    "    url (str): The URL of the web page to fetch and parse.\n",
    "\n",
    "    Returns:\n",
    "    str: Cleaned text content extracted from the web page.\n",
    "\n",
    "    Raises:\n",
    "    requests.exceptions.RequestException: If an error occurs while fetching the URL.\n",
    "\n",
    "    Notes:\n",
    "    - This function sends a GET request to the specified URL.\n",
    "    - It uses BeautifulSoup to parse the HTML content of the response.\n",
    "    - Any <style> tags in the HTML are removed to extract only textual content.\n",
    "    - The extracted text is cleaned by removing extra whitespace and empty lines.\n",
    "    \"\"\"\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Get the content of the response\n",
    "    html_content = response.text\n",
    "    \n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    for style in soup.find_all('style'):\n",
    "        style.decompose()\n",
    "\n",
    "    # Extract and print only the text content\n",
    "    text_content = soup.get_text(separator='\\n')\n",
    "\n",
    "    # Clean up the text (optional)\n",
    "    cleaned_text = '\\n'.join(line.strip() for line in text_content.splitlines() if line.strip())\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ceff2d-17e0-4240-bdd1-db3b07636429",
   "metadata": {},
   "source": [
    "æ‹¿ä¸€å€‹1111ä¾†è©¦è©¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f8b0ae-efbc-44b2-943b-f766a6e7ea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.1111.com.tw/job/130450741\"\n",
    "cleaned_text = parsing_process(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3639231-7245-4347-93ef-eb5f54dc1dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dda6dfb-965c-4c99-8846-a5a9721feda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline_.invoke({\"content\": cleaned_text}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d184f4-d1aa-40ce-a619-1ca1230c5738",
   "metadata": {},
   "source": [
    "é€™å€‹éç¨‹ä¸­ç‰½æ¶‰åˆ°å¾ç¶²è·¯ä¸Šè®€å–æ•¸æ“šï¼Œæœ¬åœ°æ•¸æ“šè™•ç†ç­‰ç­‰ã€‚é©åˆç”¨ç•°æ­¥æµä¾†é€²è¡ŒåŠ é€Ÿ:\n",
    "\n",
    "ç›®å‰ç¨‹å¼æ˜¯ åŒæ­¥é˜»å¡ çš„ï¼š\n",
    "\n",
    "- requests.get(url) â†’ æœƒé˜»å¡ç›´åˆ°ç¶²è·¯è«‹æ±‚å®Œæˆã€‚\n",
    "\n",
    "- BeautifulSoup çš„è§£æå‰‡æ˜¯ CPU æœ¬åœ°æ“ä½œï¼Œé€Ÿåº¦é€šå¸¸ä¸æ˜¯ç“¶é ¸ã€‚\n",
    "\n",
    "æ‰€ä»¥ï¼š\n",
    "\n",
    "å¦‚æœä½ ä¸€æ¬¡åªæŠ“å–®ä¸€ URLï¼Œæ²’å¿…è¦ç”¨ asyncï¼Œå› ç‚ºä¸»è¦ç“¶é ¸å°±æ˜¯ç­‰å¾…é‚£ä¸€æ¬¡è«‹æ±‚ã€‚\n",
    "\n",
    "å¦‚æœè¦æŠ“ å¤šå€‹ URLï¼Œé‚£éº¼æ”¹ç”¨ éåŒæ­¥ï¼ˆasync/await + aiohttpï¼‰ æˆ– å¤šåŸ·è¡Œç·’ / å¤šè™•ç† æ‰èƒ½é¡¯è‘—åŠ é€Ÿï¼Œå› ç‚ºä½ èƒ½åŒæ™‚ç™¼é€å¤šå€‹è«‹æ±‚ï¼Œé¿å… I/O ç­‰å¾…é€ æˆæµªè²»ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e90873c-749e-48da-bbf7-23314cae33e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "@chain\n",
    "async def async_parsing_process(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches and extracts cleaned text content from a given URL asynchronously.\n",
    "\n",
    "    Parameters:\n",
    "    url (str): The URL of the web page to fetch and parse.\n",
    "\n",
    "    Returns:\n",
    "    str: Cleaned text content extracted from the web page.\n",
    "\n",
    "    Raises:\n",
    "    aiohttp.ClientError: If an error occurs while fetching the URL.\n",
    "    \"\"\"\n",
    "\n",
    "    # request ä¸æ”¯æ´ asynchronization\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(url) as response:\n",
    "            html_content = await response.text()\n",
    "            soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "            # ç§»é™¤ style å’Œ script\n",
    "            for tag in soup([\"style\", \"script\"]):\n",
    "                tag.decompose()\n",
    "\n",
    "            # æå–æ–‡å­—\n",
    "            text_content = soup.get_text(separator=\"\\n\")\n",
    "\n",
    "            # æ¸…ç†ç©ºç™½èˆ‡ç©ºè¡Œ\n",
    "            cleaned_text = \"\\n\".join(\n",
    "                line.strip() for line in text_content.splitlines() if line.strip()\n",
    "            )\n",
    "\n",
    "            return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade04f01-7a4c-46e6-9e2d-b892f4058c40",
   "metadata": {},
   "source": [
    "è‹¥æ˜¯æˆ‘å€‘ä½¿ç”¨LCELï¼Œpipeline å°±æ˜¯é€™å€‹æ¨£å­:\n",
    "\n",
    "1. è³‡æ–™æå–èˆ‡æ¸…æ´—\n",
    "2. ä½¿ç”¨LLMé€²è¡Œæœ€å¾Œçš„æ•¸æ“šæç…‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab11d67e-3993-4ccb-86eb-6e6e3831f0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description_pipeline = RunnablePassthrough.assign(content=itemgetter(\"url\")|async_parsing_process)|chat_prompt_template|model|StrOutputParser()\n",
    "\n",
    "job_result = await job_description_pipeline.ainvoke({\"url\": url})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695babfd-ee0a-49cd-9082-0cd6c1ad8386",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(job_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0679586-30a0-4384-84aa-15642bd19559",
   "metadata": {},
   "source": [
    "## å±¥æ­·æå–\n",
    "\n",
    "- ç¶²è·¯ä¸Šå…¬é–‹è³‡æ–™ (æŠŠå·¥ä½œæå–çš„Prompt ç¨å¾®ä¿®ä¸€ä¸‹å°±è¡Œï¼Œç¶²è·¯æŠ“æ•¸æ“šçš„æµç¨‹æ˜¯ä¸€æ¨£çš„)\n",
    "- Word\n",
    "- PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c682487c-dca0-4368-ab9b-d9e95bb4e767",
   "metadata": {},
   "source": [
    "### æå– Word å…§å®¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d1ff36-bda0-49ca-85f9-6bdc41d8f3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b927ef-5df2-4e9d-8e92-ff227cdc47fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from docx.oxml.table import CT_Tbl\n",
    "from docx.oxml.text.paragraph import CT_P\n",
    "from docx.table import Table\n",
    "from docx.text.paragraph import Paragraph\n",
    "\n",
    "def iter_block_items(parent):\n",
    "    \"\"\"\n",
    "    Yield each paragraph and table in document order.\n",
    "    \"\"\"\n",
    "    for child in parent.element.body:\n",
    "        if isinstance(child, CT_P):\n",
    "            yield Paragraph(child, parent)\n",
    "        elif isinstance(child, CT_Tbl):\n",
    "            yield Table(child, parent)\n",
    "\n",
    "# Load the Word document\n",
    "doc = Document(os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-3\", \"Resume.docx\"))\n",
    "\n",
    "content = []\n",
    "\n",
    "for block in iter_block_items(doc):\n",
    "    if isinstance(block, Paragraph):\n",
    "        text = block.text.strip()\n",
    "        if text:  # skip empty paragraphs\n",
    "            content.append(text)\n",
    "    elif isinstance(block, Table):\n",
    "        for row in block.rows:\n",
    "            row_data = [cell.text.strip() for cell in row.cells]\n",
    "            content.append(\"\\t\".join(row_data))\n",
    "\n",
    "# Combine everything in order\n",
    "full_text = \"\\n\".join(content)\n",
    "\n",
    "print(full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60969101-e529-4f8a-a6b5-d38fef4bee66",
   "metadata": {},
   "source": [
    "### æ‰“åŒ…æˆç•°æ­¥æµLangchain Runnable\n",
    "\n",
    "python-docx æœ¬èº«æ˜¯ä¸€å€‹ åŒæ­¥é˜»å¡çš„å‡½å¼åº« â€”â€” å®ƒåœ¨è®€æª”ã€è§£æ .docx æ™‚æœƒä½”ç”¨ Python ä¸»åŸ·è¡Œç·’ã€‚\n",
    "\n",
    "åœ¨ async/await çš„æ‡‰ç”¨å ´æ™¯ä¸­ï¼ˆä¾‹å¦‚ LangChain agentã€async pipelineã€Web serverï¼‰ï¼Œå¦‚æœç›´æ¥å‘¼å«åŒæ­¥çš„ python-docxï¼Œæœƒè®“ äº‹ä»¶è¿´åœˆè¢«å¡ä½ï¼Œå…¶ä»– async ä»»å‹™ç„¡æ³•ä¸¦è¡Œé€²è¡Œã€‚\n",
    "\n",
    "await asyncio.to_thread(func, *args)\n",
    "\n",
    "æŠŠé€™å€‹ åŒæ­¥é˜»å¡çš„å·¥ä½œä¸Ÿåˆ°èƒŒæ™¯ thread pool åŸ·è¡Œï¼Œå¾è€Œè®“äº‹ä»¶è¿´åœˆä¿æŒã€Œéé˜»å¡ã€ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ec6413-9c55-461e-9a5c-41d45fa5beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å› ç‚ºpython-docxæ˜¯åŒæ­¥æµï¼Œæ‰€ä»¥æˆ‘å€‘éœ€è¦ç”¨asyncio.to_threadå°‡å…¶é‡æ–°åŒ…è£æˆç•°æ­¥æµ\n",
    "import asyncio\n",
    "from typing import Dict, Any\n",
    "\n",
    "\n",
    "class DocxExtractor(Runnable):\n",
    "    \"\"\"LangChain Runnable that extracts text (paragraphs + tables) from a Word file.\"\"\"\n",
    "\n",
    "    async def ainvoke(self, filename: str, config: Dict[str, Any] | None = None) -> str:\n",
    "        \"\"\"\n",
    "        python-docx æ˜¯åŒæ­¥é˜»å¡çš„å‡½å¼åº«ï¼Œè‹¥ç›´æ¥åœ¨ async ç’°å¢ƒå‘¼å«æœƒå¡ä½äº‹ä»¶è¿´åœˆï¼Œå› æ­¤éœ€ç”¨ asyncio.to_thread å°‡å…¶åŒ…è£ï¼Œ\n",
    "        è®“é˜»å¡æ“ä½œåœ¨èƒŒæ™¯åŸ·è¡Œç·’åŸ·è¡Œï¼Œé¿å…é˜»å¡å…¶ä»–éåŒæ­¥ä»»å‹™ã€‚\n",
    "        \"\"\"\n",
    "        \n",
    "        return await asyncio.to_thread(self._extract, filename)\n",
    "\n",
    "    def invoke(self, filename: str, config=None) -> str:\n",
    "        # synchronous version directly calls the sync helper\n",
    "        return self._extract(filename)\n",
    "    \n",
    "    def _extract(self, filename: str) -> str:\n",
    "        doc = Document(filename)\n",
    "        content = []\n",
    "\n",
    "        for block in iter_block_items(doc):\n",
    "            if isinstance(block, Paragraph):\n",
    "                text = block.text.strip()\n",
    "                if text:\n",
    "                    content.append(text)\n",
    "            elif isinstance(block, Table):\n",
    "                for row in block.rows:\n",
    "                    row_data = [cell.text.strip() for cell in row.cells]\n",
    "                    content.append(\"\\t\".join(row_data))\n",
    "\n",
    "        return \"\\n\".join(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb64b7e-a80c-4bd8-8977-26b00e3538a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = DocxExtractor()\n",
    "result = await extractor.ainvoke(os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-3\", \"Resume.docx\"))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc4074-7e4d-48be-bd9e-6db83b4010d1",
   "metadata": {},
   "source": [
    "é€™å€‹ Word å…§å®¹æå–æ˜¯é€šç”¨å‹çš„ï¼Œä¸é™æ–¼ç°¡æ­·ï¼Œä¹Ÿå¯ä»¥æå–å…¬æ–‡æˆ–å…¶ä»–æ–‡ä»¶æ–‡å­—å…§å®¹ã€‚å®ƒå®Œå…¨åŸºæ–¼ç¨‹å¼é‚è¼¯ï¼Œä¸æ¶‰åŠå¤§èªè¨€æ¨¡å‹ï¼Œæ‰€ä»¥ä¸éœ€è¦é¡å¤–ä»˜è²»ã€‚ä¸¦éæ‰€æœ‰æ‡‰ç”¨éƒ½éœ€è¦å¤§èªè¨€æ¨¡å‹ï¼Œæœ‰æ™‚å€™ä½ åªæ˜¯éœ€è¦ä¸€å° 50cc å°å‹ä»£æ­¥è»Šï¼Œæ²’å¿…è¦è‡ªå·±å»æ‰“é€ ä¸€å° F1 è³½è»Šã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd3d7fb-c61f-4499-aa28-bb9b3db7a5e3",
   "metadata": {},
   "source": [
    "### æå– PDF å…§å®¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13e82f4-c89b-4b6e-8c5d-85c3739dcb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "def extract_pdf(filename: str) -> str:\n",
    "    reader = PdfReader(filename)\n",
    "    content = []\n",
    "    for page in reader.pages:\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            content.append(text.strip())\n",
    "    return \"\\n\".join(content)\n",
    "\n",
    "# Example\n",
    "print(extract_pdf(os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-3\", \"Resume.pdf\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0cd678-1737-4d22-946d-c5dbb68b2240",
   "metadata": {},
   "source": [
    "ç•°æ­¥æµç‰ˆæœ¬:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1448d256-52df-42f3-ae5c-ed21666b6f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "\n",
    "\n",
    "class PdfExtractor(Runnable):\n",
    "    \"\"\"LangChain Runnable that extracts text from a PDF file.\"\"\"\n",
    "\n",
    "    async def ainvoke(self, filename: str, config: Dict[str, Any] | None = None) -> str:\n",
    "        return await asyncio.to_thread(self._extract, filename)\n",
    "\n",
    "    def invoke(self, filename: str, config: Dict[str, Any] | None = None) -> str:\n",
    "        return self._extract(filename)\n",
    "\n",
    "    def _extract(self, filename: str) -> str:\n",
    "        reader = PdfReader(filename)\n",
    "        content = []\n",
    "        for page in reader.pages:\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                content.append(text.strip())\n",
    "        return \"\\n\".join(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bcd5d5-639e-4191-9fab-fb58b553f221",
   "metadata": {},
   "source": [
    "ç›´æ¥ä½¿ç”¨æ ¹æ“š Docx æå–çš„å…§å®¹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d110ac4d-f835-4c4d-b544-02070c2dc2bd",
   "metadata": {},
   "source": [
    "æŠ€è¡“ä¸Šç¢ºå¯¦å¯ä»¥ç›´æ¥åœ¨è®€å–æª”æ¡ˆçš„åŒæ™‚é€²è¡ŒåŒ¹é…ï¼Œä½†åœ¨ç³»çµ±è¨­è¨ˆä¸Šï¼Œå°‡ã€Œæª”æ¡ˆå…§å®¹æå–ã€ç¨ç«‹æˆå·¥ä½œæµæœƒæ›´æ°ç•¶ï¼Œå› ç‚ºé€™æ¨£æ›´æœ‰åˆ©æ–¼ç¶­è­·ã€ç›£æ§èˆ‡å¾ŒçºŒæ“´å±•ï¼Œå†å°‡æå–çµæœäº¤ç”±ä¸‹æ¸¸æµç¨‹é€²è¡ŒåŒ¹é…æˆ–å…¶ä»–è™•ç†ã€‚\n",
    "\n",
    "1. æŠ€è¡“ä¸Šå¯è¡Œï¼š\n",
    "    ç¢ºå¯¦å¯ä»¥ã€Œon-the-flyã€ç›´æ¥è®€å–æª”æ¡ˆï¼Œç„¶å¾Œç«‹åˆ»åšæ¯”å°æˆ–åŒ¹é…ï¼Œé€™åœ¨ demo æˆ–å°è¦æ¨¡æ‡‰ç”¨æ™‚æ²’å•é¡Œã€‚\n",
    "\n",
    "2. å‹™å¯¦ä¸Šçš„è€ƒé‡ï¼š\n",
    "    åœ¨å¯¦éš›ç³»çµ±è¨­è¨ˆä¸­ï¼ŒæŠŠã€Œæª”æ¡ˆè®€å– / è§£æã€ç¨ç«‹æˆä¸€å€‹æ¨¡çµ„æˆ–å·¥ä½œæµæœƒæ›´å¥½ï¼š\n",
    "\n",
    "    - ç¶­è­·æ€§ï¼šè§£æé‚è¼¯ç¨ç«‹ï¼Œå®¹æ˜“æ›¿æ›ä¸åŒæª”æ¡ˆé¡å‹ï¼ˆWordã€PDFã€Excelâ€¦ï¼‰ã€‚\n",
    "\n",
    "    - å¯ç›£æ§ï¼šå¯ä»¥é‡å°ã€Œè§£æå¤±æ•—ã€åšç›£æ§å’ŒéŒ¯èª¤è™•ç†ï¼Œä¸æœƒå’ŒåŒ¹é…é‚è¼¯ç³¾çºåœ¨ä¸€èµ·ã€‚\n",
    "\n",
    "    - å¯æ“´å±•ï¼šä¹‹å¾Œä¸åªåšåŒ¹é…ï¼Œé‚„å¯èƒ½åšç´¢å¼•ã€æ‘˜è¦ã€åˆ†é¡ç­‰ï¼Œæå‰æŠ½é›¢æµç¨‹æ›´æœ‰å½ˆæ€§ã€‚\n",
    "\n",
    "3. æµç¨‹å»ºè­°ï¼š\n",
    "\n",
    "    Step 1ï¼šæª”æ¡ˆ â†’ è®€å– & æå–æ–‡å­—ï¼ˆæŠ½è±¡æˆ Extractor å·¥ä½œæµï¼‰ã€‚\n",
    "\n",
    "    Step 2ï¼šæŠ½å–å…§å®¹ â†’ åŒ¹é… / NLP è™•ç† / ä¸‹æ¸¸ä»»å‹™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd216bc4-0189-468d-9943-3714f6f06241",
   "metadata": {},
   "source": [
    "## å…§å®¹ç²¾ç…‰ï¼Œè¼¸å‡ºå…§å®¹ä¸€è‡´åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7a14c9-84d9-4a67-be3f-feefe74244b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "system_template = dedent(\"\"\"\n",
    "                  I am going to give you a template for your output. \n",
    "                  CAPITALIZED WORDS are my placeholders. \n",
    "                  Fill in my placeholders with your output. Please preserve \n",
    "                  the overall formatting of my template. My template is:\n",
    "\n",
    "                  *** Working Experience:*** WORKING EXPERIENCE \n",
    "                  *** Education:*** EDUCATION\n",
    "                  *** Skills:*** SKILLS\n",
    "\n",
    "                  I will give you the data to format in the next prompt. \n",
    "                  Create a resume using my template.\n",
    "                  \"\"\")\n",
    "\n",
    "human_template = \"\"\"\n",
    "                 {query}\n",
    "                 \"\"\"\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variables\": [\"query\"]}}\n",
    "\n",
    "resume_pipeline = build_pipeline(model=model, inputs=input_, parser=StrOutputParser())\n",
    "\n",
    "# resume_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "# resume_pipeline = resume_prompt_template|model|StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d7213-052c-4202-a201-8227e6d16b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = extract_pdf(os.path.join(\"tutorial\", \"LLM+Langchain\", \"Week-3\", \"Resume.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81388d28-d18a-4750-8151-4cb394ad71e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resume_output = resume_pipeline.invoke(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77226af-b87d-4803-b694-02aa55539298",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(resume_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6823b73a-8c52-45e6-8dfd-901732a25767",
   "metadata": {},
   "source": [
    "## å±¥æ­·å’Œå·¥ä½œçš„åŒ¹é…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2b73ec-d204-47b0-9d31-f103b609ba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Output(BaseModel):\n",
    "\n",
    "    result: Literal['Yes', 'No'] = Field(description=\"If the candidate is a good fit, either Yes or No\")\n",
    "    reason: str = Field(description=\"Applicant - Job matching\")\n",
    "    \n",
    "output_parser = PydanticOutputParser(pydantic_object=Output)\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1390f7e-9f85-4a71-9860-f017b10ce879",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_template = dedent(\"\"\"\n",
    "                  You are an AI assistant acting as an experienced senior \n",
    "                  recruiter in IT field.\n",
    "                  \n",
    "                  You are assigned a task of identifying if an applicant, \n",
    "                  based on the description in the resume, is a good match to the described job. \n",
    "                    \n",
    "                  You always do the best work you can. You are highly \n",
    "                  analytical and pay close attention to details. \n",
    "                  \"\"\")\n",
    "\n",
    "human_template = dedent(\"\"\"\n",
    "                 Job description: {job}\n",
    "                 resume: {resume}\n",
    "                 output format instructions: {format_instructions}\n",
    "                 \"\"\")\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variables\": [\"job\", \"resume\"],\n",
    "                    \"partial_variables\": {'format_instructions': format_instructions}}}\n",
    "\n",
    "match_prompt_template = build_standard_chat_prompt_template(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40117f4a-6040-49d8-8f1e-6c747de37e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c952973-2f02-49d8-a807-4a16dbd692f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee8e78e-49b7-481b-9a26-f1f9ddcdb83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_pipeline = build_pipeline(model=model, inputs=input_, parser=output_parser)\n",
    "\n",
    "# matching_pipeline = match_prompt_template|model|output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2a6215-3e77-4736-9f4c-54dcc9a6c130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matching_output = matching_pipeline.invoke({\"job\":job_result, \"resume\":result})\n",
    "\n",
    "print(matching_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09540966-abf5-49c2-8fd5-68bb512e8ed4",
   "metadata": {},
   "source": [
    "# å…¶ä»–çš„å¤§èªè¨€æ¨¡å‹APIæä¾›å•†\n",
    "\n",
    "> ğŸ¯ æœ¬ç« å­¸å®Œä½ å°‡èƒ½å­¸æœƒä»€éº¼ï¼š\n",
    "> - ç†è§£å¦‚ä½•åœ¨ LangChain ä¸­æ•´åˆç¬¬ä¸‰æ–¹å¤§èªè¨€æ¨¡å‹ APIï¼ˆå¦‚ Perplexityã€DeepSeekï¼‰\n",
    "> - å­¸æœƒè¨­å®šèˆ‡å‘¼å«é OpenAI æ¨¡å‹çš„ APIï¼ˆåŒ…å«è‡ªè¨‚ base_urlã€api_keyï¼‰\n",
    "> - ç†Ÿæ‚‰ Perplexity çš„ sonar-* æ¨¡å‹èˆ‡ DeepSeek çš„ deepseek-reasoner æ¨¡å‹åœ¨ LangChain ä¸­çš„ä½¿ç”¨æ–¹å¼\n",
    "\n",
    "## Perplexity\n",
    "\n",
    "https://python.langchain.com/docs/integrations/chat/perplexity/\n",
    "\n",
    "- sonar-deep-research\n",
    "- sonar-reasoning-pro\n",
    "- sonar-reasoning\n",
    "- sonar-pro\n",
    "- sonar\t128k\n",
    "- r1-1776\n",
    "\n",
    "Langchain 'ä¼¼ä¹'æ”¯æŒPerplexityï¼Œä½†æˆ‘åœ¨ä½¿ç”¨æ™‚ç™¼ç¾æœƒå‡ºå•é¡Œï¼Œæ‰€ä»¥éœ€è¦è‡ªå·±å¥—æ®¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a29dd0-eb1a-4745-ad23-ab6b4c4b804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perplexity åŸºæœ¬APIä½¿ç”¨\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are an AI assistant that focuses on equity market analysis and you need to \"\n",
    "            \"engage in an accurate, comprehensive, helpful and  polite conversation with a user.\"\n",
    "        ),\n",
    "    },\n",
    "    {  \n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            \"Find the SKU number of Carslan Lasting Cover Foundation N01\"\n",
    "        ),\n",
    "\n",
    "    },\n",
    "]\n",
    "\n",
    "client = OpenAI(api_key=os.environ['PERPLEXITY_API_KEY'], base_url=\"https://api.perplexity.ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ee1237-ce75-4c59-b323-8fca3c884baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "\n",
    "@chain\n",
    "def prompt_template_2_messages(chat_prompt):\n",
    "\n",
    "    output_messages = []\n",
    "     \n",
    "    _messages = chat_prompt.messages\n",
    "\n",
    "    for message in _messages:\n",
    "        if isinstance(message, SystemMessage):\n",
    "            output_messages.append({\"role\": \"system\", \"content\": message.content})\n",
    "        if isinstance(message, HumanMessage):\n",
    "            output_messages.append({\"role\": \"user\", \"content\": message.content})\n",
    "\n",
    "    return output_messages\n",
    "\n",
    "\n",
    "@chain\n",
    "def messages_2_perplexity(messages):\n",
    "\n",
    "    client = OpenAI(api_key=os.environ['PERPLEXITY_API_KEY'], base_url=\"https://api.perplexity.ai\")\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"sonar-deep-research\",\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message.content\n",
    "    citations = response.citations\n",
    "\n",
    "    return {\"content\": content,\n",
    "            \"citations\": citations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b20975d-e3de-4065-96fc-46d35100550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_perplexity = chat_prompt_perplexity|prompt_template_2_messages|messages_2_perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c418435c-349d-4e9b-b221-d7668007c34f",
   "metadata": {},
   "source": [
    "## DeepSeek\n",
    "\n",
    "- Langchain æ”¯æ´ Deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcaea01-1e16-43bd-a074-f088c273c7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "deepseek_r1 = ChatDeepSeek(api_key=os.environ['DEEPSEEK_API_KEY'], temperature=0, model='deepseek-reasoner')\n",
    "\n",
    "system_template = \"You are a helpful assistant.\"\n",
    "human_template = \"Create a financial report of {ticker} based on:\\n {context}\"\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variables\": [\"context\", \"ticker\"]}\n",
    "         }\n",
    "\n",
    "chat_prompt_deepseek = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "pipeline_deepseek = chat_prompt_deepseek|deepseek_r1|output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bca2d1-d639-49f3-a874-45106ef1e8a5",
   "metadata": {},
   "source": [
    "# MLFlow Part 1\n",
    "\n",
    ">ğŸ¯ æœ¬ç« å­¸å®Œä½ å°‡èƒ½å­¸æœƒä»€éº¼ï¼š\n",
    "> - ç†è§£ MLflow çš„æ ¸å¿ƒæ¦‚å¿µï¼ˆExperimentã€Runã€Model Registryã€Artifact ç­‰ï¼‰\n",
    "> - å­¸æœƒåœ¨æœ¬åœ°ç«¯å•Ÿå‹•ä¸¦é€£æ¥ MLflow Tracking Server\n",
    "> - èƒ½å¤ ä½¿ç”¨ MLflow è¿½è¹¤èˆ‡è¨˜éŒ„æ©Ÿå™¨å­¸ç¿’æ¨¡å‹ï¼ˆä»¥ Logistic Regression + Iris dataset ç‚ºä¾‹ï¼‰\n",
    "> - æŒæ¡å¦‚ä½•é€é MLflow è¨»å†Šã€è¼‰å…¥ã€æ¨™è¨˜ï¼ˆTagï¼‰èˆ‡åˆ¥åï¼ˆAliasï¼‰ç®¡ç†æ¨¡å‹ç‰ˆæœ¬\n",
    "> - ç†Ÿæ‚‰ mlflow.sklearn èˆ‡ mlflow.pyfunc çš„æ¨¡å‹å­˜å–æ–¹å¼ï¼Œä¸¦èƒ½æ¨¡æ“¬é ç«¯è¼‰å…¥æµç¨‹\n",
    "> - ç†è§£å¦‚ä½•çµåˆ LangChain èˆ‡ MLflowï¼Œå°‡ LLMChain pipeline é€²è¡Œç‰ˆæœ¬åŒ–èˆ‡è¿½è¹¤\n",
    "> - å­¸æœƒè¨­å®š Model Signatureï¼Œæ˜ç¢ºå®šç¾©æ¨¡å‹çš„è¼¸å…¥è¼¸å‡ºçµæ§‹ï¼Œæå‡æ¨¡å‹å¯è§£é‡‹æ€§èˆ‡å¯ç§»æ¤æ€§\n",
    "> - èƒ½å¤ å°‡è‡ªè¨‚ Python pipeline ä»¥ MLflow æ¨¡å‹æ ¼å¼éƒ¨ç½²èˆ‡é‡è¼‰é‹è¡Œ\n",
    "\n",
    "é‡å•ŸNotebookä¾†ç¯€çœç¡¬é«”è³‡æº\n",
    "\n",
    "- pip install mlflow\n",
    "- åœ¨CLI: mlflow server --host 127.0.0.1 --port 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7828b24-ef0e-4ad3-880d-100506ae3943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2805f4-b256-4043-9f8e-09859ae64d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# Load the Iris dataset\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define the model hyperparameters\n",
    "params = {\n",
    "    \"solver\": \"lbfgs\",\n",
    "    \"max_iter\": 1000,\n",
    "    \"multi_class\": \"auto\",\n",
    "    \"random_state\": 8888,\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "lr = LogisticRegression(**params)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e269cfda-740c-40cb-8504-93134c7be3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# é€šçŸ¥mlflowè¦æŠŠç´€éŒ„é€å»å“ªè£¡\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Create a new MLflow Experiment\n",
    "mlflow.set_experiment(\"MLflow Quickstart\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Week-3-MLFlow\") as run:\n",
    "\n",
    "    # ä½ éœ€è¦é€™å€‹ä¾†ç¢ºä¿çµæœéƒ½æœƒè¢«è¨˜éŒ„åœ¨åŒä¸€å€‹Runè£¡\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Log the loss metric\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    # Infer the model signature\n",
    "    signature = infer_signature(X_train, lr.predict(X_train))\n",
    "\n",
    "    # Log the model, which inherits the parameters and metric\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=lr,\n",
    "        # model local name\n",
    "        name=\"iris_model\",\n",
    "        signature=signature,\n",
    "        input_example=X_train,\n",
    "        # model global name\n",
    "        registered_model_name=\"tracking-quickstart\",\n",
    "    )\n",
    "\n",
    "    # Set a tag that we can use to remind ourselves what this model was for\n",
    "    mlflow.set_logged_model_tags(\n",
    "        model_info.model_id, {\"Training Info\": \"Basic LR model for iris data\"}\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48f6fa6-d37f-4c5c-b5b4-87c5cbd2c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info.model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e1e550-78eb-4012-afc8-39dab70a9487",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f015683b-5035-4af0-9a8a-7a88fe0d2f10",
   "metadata": {},
   "source": [
    "## æœ¬åœ°åŸ·è¡Œ\n",
    "\n",
    "1. mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "\n",
    "- é€™è£¡ç”¨çš„æ˜¯ model_info.model_uriï¼Œå®ƒæŒ‡å‘å‰›å‰›åœ¨ local run è£¡ mlflow.sklearn.log_model(...) å­˜ä¸‹ä¾†çš„ artifact è·¯å¾‘ã€‚\n",
    "\n",
    "- å› ç‚ºä½ åœ¨ åŒä¸€å€‹ local tracking server (æˆ–é è¨­çš„æœ¬åœ°æª”æ¡ˆç³»çµ±) åŸ·è¡Œï¼Œæ‰€ä»¥å¯ä»¥ç›´æ¥è¼‰å…¥ã€‚\n",
    "\n",
    "2. predictions = loaded_model.predict(X_test)\n",
    "\n",
    "- mlflow.pyfunc æœƒåŒ…è£æˆä¸€å€‹ é€šç”¨ Python function æ¨¡å‹ (ä¸ç®¡åº•å±¤æ˜¯ sklearnã€pytorchã€xgboost...)ã€‚\n",
    "\n",
    "- æ‰€ä»¥ä½ å¯ä»¥ç›´æ¥ .predict(...)ï¼Œå¾—åˆ°é æ¸¬çµæœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b6d322-836a-4a45-a648-2e23ed0ad6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model back for predictions as a generic Python Function model\n",
    "\n",
    "loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "\n",
    "predictions = loaded_model.predict(X_test)\n",
    "\n",
    "iris_feature_names = datasets.load_iris().feature_names\n",
    "\n",
    "result = pd.DataFrame(X_test, columns=iris_feature_names)\n",
    "result[\"actual_class\"] = y_test\n",
    "result[\"predicted_class\"] = predictions\n",
    "\n",
    "result[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cd8c06-2e45-486a-8434-e181073c0827",
   "metadata": {},
   "source": [
    "## æ¨¡æ“¬é ç«¯åŸ·è¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5283b5-4db8-4930-af73-5e29d35cd5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# åˆ—å‡ºç‰¹å®šæ¨¡å‹çš„æ‰€æœ‰ç‰ˆæœ¬\n",
    "versions = client.search_model_versions(\"name='tracking-quickstart'\")\n",
    "\n",
    "for v in versions:\n",
    "    print(f\"Version: {v.version}, Stage: {v.current_stage}, Run ID: {v.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d026abbb-e2cd-4e47-8043-cb17b7b4b1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uri = \"models:/tracking-quickstart/1\"    # version 1\n",
    "\n",
    "model_remote = mlflow.sklearn.load_model(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9aa4e6-cbe8-4230-9ebf-e44fdd4e08fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_remote.predict(X_test)\n",
    "\n",
    "iris_feature_names = datasets.load_iris().feature_names\n",
    "\n",
    "result = pd.DataFrame(X_test, columns=iris_feature_names)\n",
    "result[\"actual_class\"] = y_test\n",
    "result[\"predicted_class\"] = predictions\n",
    "\n",
    "result[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79427145-e95f-4af5-9a97-d7f23d91ee79",
   "metadata": {},
   "source": [
    "### æ¨¡å‹ Aliasï¼ˆåˆ¥åï¼‰\n",
    "\n",
    "Alias æ˜¯ä¸€ç¨®å¯è®Šï¼ˆmutableï¼‰çš„å‘½åå¼•ç”¨ï¼Œå¯æŒ‡å‘æŸå€‹è¨»å†Šæ¨¡å‹ï¼ˆregistered modelï¼‰çš„ç‰¹å®šç‰ˆæœ¬ã€‚é€™å°æ–¼éš¨å¾Œæ›´æ–°éƒ¨ç½²æ¨¡å‹å»ä¸æƒ³æ”¹ç¨‹å¼ç¢¼æ™‚éå¸¸æ–¹ä¾¿ã€‚ä¾‹å¦‚ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e35ea0-3344-494f-bd8d-742df38bf6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "client.set_registered_model_alias(\n",
    "    name=\"tracking-quickstart\",\n",
    "    alias=\"champion\",\n",
    "    version=\"1\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769a174f-1123-49c7-a258-f97514252655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä»¥ alias è¼‰å…¥æ¨¡å‹\n",
    "model = mlflow.sklearn.load_model(\"models:/tracking-quickstart@champion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c80fa78-04aa-4e94-94bc-52fafd0d96ed",
   "metadata": {},
   "source": [
    "ä¹Ÿå¯ä»¥ç”¨ API åˆªé™¤ aliasï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e52ced0-6b38-4cbb-aa39-69459213714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_registered_model_alias(\"tracking-quickstart\", \"champion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b057d9e0-bfa7-4b1f-8b5a-d2424a9fd2b5",
   "metadata": {},
   "source": [
    "### æ¨¡å‹ Tagsï¼ˆæ¨™ç±¤ï¼‰\n",
    "\n",
    "MLflow æ”¯æ´å…©å±¤ Tagï¼š\n",
    "\n",
    "- Registered model-level tagsï¼šæ•´é«”æ¨¡å‹çš„ metadataï¼Œä¾‹å¦‚ç”¨é€”ã€åœ˜éšŠç­‰è³‡è¨Šã€‚\n",
    "\n",
    "- Model version-level tagsï¼šé‡å°æ¯å€‹ç‰ˆæœ¬åšä¸åŒè¨»è¨˜ï¼Œä¾‹å¦‚é©—è­‰ç‹€æ…‹ã€æ•ˆèƒ½è³‡è¨Šç­‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c4c242-0268-48dd-a35b-e3dfba7cdedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registered model-level tag\n",
    "client.set_registered_model_tag(\"tracking-quickstart\", \"task\", \"classification\")\n",
    "\n",
    "# Version-level tag\n",
    "client.set_model_version_tag(\"tracking-quickstart\", version=\"1\", key=\"validation_status\", value=\"approved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
