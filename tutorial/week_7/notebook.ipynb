{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ad11b11-c19a-4323-8a33-0b601d5e7b30",
   "metadata": {},
   "source": [
    "# Image Generation\n",
    "\n",
    "> ğŸ¯ **æœ¬ç« å­¸å®Œä½ å°‡èƒ½å­¸æœƒä»€éº¼ï¼š**\n",
    "> - ç†è§£ OpenAI çš„ **GPT-Image-1** æ¨¡å‹ç‰¹è‰²èˆ‡ä½¿ç”¨æ–¹å¼  \n",
    "> - ç†Ÿæ‚‰ `client.images.generate()` èˆ‡ `client.images.edit()` çš„ä½¿ç”¨æ–¹æ³•  \n",
    "> - æŒæ¡å¦‚ä½•è¨­å®šå½±åƒç”Ÿæˆçš„ **size**ã€**quality**ã€**moderation** ç­‰åƒæ•¸  \n",
    "> - èƒ½ä»¥è‹±æ–‡ prompt ç”Ÿæˆé«˜å“è³ª AI åœ–åƒ  \n",
    "> - ç­è§£å¦‚ä½•å°‡ base64 åœ–åƒè³‡æ–™è½‰æ›ã€é¡¯ç¤ºèˆ‡å„²å­˜  \n",
    "\n",
    "OpenAI æä¾› æ–‡ç”Ÿåœ– (text to image) å’Œ åœ–ç”Ÿåœ– (image to image) APIã€‚\n",
    "\n",
    "## GPT-Image-1\n",
    "\n",
    "Please update your 'openai' package to 1.97.0 to see the latest documentation\n",
    "\n",
    "* æœ€æ–°çš„æ˜¯ GPT-Image-1.5\n",
    "\n",
    "å„ªé»:\n",
    "- å‡ºåœ–ç©©å®š (ä¼¼ä¹å›ºå®šäº†Random Seed)\n",
    "- å‡ºåœ–å“è³ªé«˜ï¼Œç´°ç¯€å¥½\n",
    "\n",
    "å»ºè­°ä½¿ç”¨è‹±æ–‡ä½œç‚ºPromptã€‚\n",
    "\n",
    "## ğŸ“š å»¶ä¼¸è³‡æºèˆ‡åƒè€ƒé€£çµ\n",
    "\n",
    "> é€™äº›é€£çµå¯å¹«åŠ©ä½ æ›´æ·±å…¥ç†è§£ OpenAI API èˆ‡ LangChain çš„æ‡‰ç”¨æ–¹å¼ï¼Œ  \n",
    "> ç‰¹åˆ¥é©åˆåœ¨é–±è®€æ•™æå¾Œé€²ä¸€æ­¥æŸ¥é–±å®˜æ–¹æŠ€è¡“æ–‡ä»¶èˆ‡å¯¦ä½œç¯„ä¾‹ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§  OpenAI ç›¸é—œæ–‡ä»¶\n",
    "\n",
    "- [**OpenAI API Image Generation æ–‡æª”**](https://platform.openai.com/docs/guides/image-generation)  \n",
    "  èªªæ˜å¦‚ä½•ä½¿ç”¨ `gpt-image-1` æ¨¡å‹é€²è¡Œ **æ–‡å­—è½‰åœ– (Text-to-Image)**ã€**åœ–åƒç·¨è¼¯ (Image-to-Image)** èˆ‡ **Inpainting**ã€‚  \n",
    "  åŒ…å«è«‹æ±‚åƒæ•¸ï¼ˆå¦‚ `size`ã€`quality`ã€`response_format`ï¼‰åŠå›å‚³æ ¼å¼çš„è©³ç´°èªªæ˜ã€‚  \n",
    "\n",
    "- [**OpenAI API åƒè€ƒæ–‡æª” (API Reference)**](https://platform.openai.com/docs/api-reference/images)  \n",
    "  åˆ—å‡ºæ‰€æœ‰å½±åƒç”Ÿæˆï¼ç·¨è¼¯ç«¯é»èˆ‡å¯ç”¨åƒæ•¸ï¼Œä¸¦æä¾›å¯¦éš›ç¯„ä¾‹ç¨‹å¼ç¢¼ã€‚  \n",
    "  é©åˆåœ¨é–‹ç™¼éšæ®µæŸ¥è©¢ API è«‹æ±‚æ ¼å¼èˆ‡æ¬„ä½èªªæ˜ã€‚  \n",
    "\n",
    "- [**OpenAI Cookbook**](https://cookbook.openai.com/)  \n",
    "  å®˜æ–¹æŠ€è¡“ç¯„ä¾‹é›†ï¼ˆrecipesï¼‰ï¼Œå±•ç¤ºå¦‚ä½•æ•´åˆ OpenAI API è‡³å„ç¨®æ‡‰ç”¨å ´æ™¯ã€‚  \n",
    "  å…¶ä¸­çš„ [å½±åƒç”Ÿæˆç¯„ä¾‹](https://cookbook.openai.com/examples/generate_images_with_gpt_image)  \n",
    "  å°æ‡‰åˆ°æœ¬ç« ç¯€çš„ `client.images.generate()` æ•™å­¸ã€‚\n",
    "\n",
    "\n",
    "- model: gpt-image-1\n",
    "    - size (str): 1024x1024 (square), 1536x1024 (landscape), 1024x1536 (portrait) or auto (default)\n",
    "    - quality: low, medium, high or auto\n",
    "    - moderation: auto, low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238a7c9e-44e8-4192-aa9c-93d6e8378c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b86643-07fa-4cd5-a229-7e01cf9619d1",
   "metadata": {},
   "source": [
    "ç¯„ä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a5fbb5-92dd-456f-8a1a-a41a206abf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "from initialization import credential_init\n",
    "\n",
    "credential_init()\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7936f34f-c6ce-43dd-beca-f34bfc8962e7",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "prompt = (\"A Sumi-e style watercolor painting of mountains during sunset. The sky is depicted with bold \"\n",
    "          \"splashes of orange, pink, and purple hues, blending and overlapping in a dynamic composition. \"\n",
    "          \"The mountains are represented with expressive brushstrokes, emphasizing their majestic and serene \"\n",
    "          \"presence. The focus is on capturing the essence and mood of the scene rather than detailed realism. \"\n",
    "          \"The overall effect is serene and contemplative, with a harmonious balance of color and form.\")\n",
    "\n",
    "# Latest OpenAI Image Model: gpt-image-1.5 (gpt-image-1.5-2025-12-16)\n",
    "\n",
    "response = client.images.generate(\n",
    "    model=\"gpt-image-1\",\n",
    "    prompt=prompt,\n",
    "    size=\"1024x1024\",\n",
    "    # quality=\"hd\",\n",
    "    quality='high',\n",
    "    n=1,\n",
    "    # response_format = 'b64_json'\n",
    ")\n",
    "\n",
    "image_base64 = response.data[0].b64_json\n",
    "\n",
    "# å°‡è¿”å›çš„ base64å­—ä¸²è½‰æ›ç‚ºåœ–åƒä¸¦ä¸”å„²å­˜\n",
    "HTML(f'<img src=\"data:image/png;base64,{image_base64}\"/>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31a81be-af39-4f3b-891e-00a08b475b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.images.generate(\n",
    "    model=\"gpt-image-1.5\",\n",
    "    prompt=prompt,\n",
    "    size=\"1024x1024\",\n",
    "    # quality=\"hd\",\n",
    "    quality='high',\n",
    "    n=1,\n",
    "    # response_format = 'b64_json'\n",
    ")\n",
    "\n",
    "image_base64 = response.data[0].b64_json\n",
    "\n",
    "# å°‡è¿”å›çš„ base64å­—ä¸²è½‰æ›ç‚ºåœ–åƒä¸¦ä¸”å„²å­˜\n",
    "HTML(f'<img src=\"data:image/png;base64,{image_base64}\"/>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e030e0-84b0-46e8-9523-2d87b55b6ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_base64[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a590663-c339-4bd6-8a09-5ac51b3ecaba",
   "metadata": {},
   "source": [
    "## æŒ‘æˆ°ï¼šå¦‚ä½•æœ‰æ•ˆåœ°æ’°å¯« Text-to-Image æç¤ºè©ï¼š\n",
    "\n",
    "> ğŸ¯ **æœ¬ç« å­¸å®Œä½ å°‡èƒ½å­¸æœƒä»€éº¼ï¼š**\n",
    "> - åˆ†è¾¨å…©ç¨®æç¤ºè©é¢¨æ ¼ï¼š**æ¨™ç±¤å¼æç¤º (Danbooru Tags)** èˆ‡ **è‡ªç„¶èªè¨€æç¤º (Natural Language Prompts)**  \n",
    "> - ç†è§£ä¸åŒæ¨¡å‹å°æ¨™ç±¤çš„æ”¯æ´åº¦å·®ç•°  \n",
    "> - å­¸ç¿’å¦‚ä½•çµåˆè—è¡“ã€æ”å½±ç”¨èªæå‡ç”Ÿæˆå“è³ª   \n",
    "\n",
    "\n",
    "åœ¨ä½¿ç”¨ AI ç”Ÿæˆåœ–åƒï¼ˆä¾‹å¦‚ OpenAI çš„ Image-1ï¼‰æ™‚ï¼Œæç¤ºè©ï¼ˆpromptï¼‰çš„å¯«æ³•å°çµæœæœ‰æ±ºå®šæ€§å½±éŸ¿ã€‚ä¸»è¦æœ‰å…©ç¨®æç¤ºè©æ ¼å¼ï¼š\n",
    "\n",
    "- æ¨™ç±¤å¼æç¤ºï¼ˆDanbooru Tag):\n",
    "\n",
    "    - ç¯„ä¾‹:    \n",
    "\n",
    "        masterpiece, best quality, beautiful eyes, clear eyes, detailed eyes, Blue-eyes, 1girl, 20_old, full-body, break, smoking, break, high_color, blue-hair, beauty, black-boots,break, break, Flat vector art, Colorful art, white_shirt, simple_background, blue_background, Ink art, peeking out upper body, Eyes\n",
    "\n",
    "\n",
    "    - ç‰¹é»èˆ‡æ³¨æ„äº‹é …ï¼š\n",
    "\n",
    "        - ç”Ÿæ•ˆèˆ‡å¦å–æ±ºæ–¼æ¨¡å‹ï¼Œä¸åŒæ¨¡å‹å°åŒä¸€å€‹æ¨™ç±¤çš„ç†è§£å¯èƒ½ä¸åŒã€‚\n",
    "        - æŸäº›æ¨™ç±¤æ˜¯é€šç”¨çš„ï¼Œä¾‹å¦‚ 1girlã€ulzzangï¼Œä½†å‘ˆç¾æ•ˆæœå¯èƒ½å·®ç•°å¾ˆå¤§ã€‚\n",
    "        - ä¸€äº›æ¨™ç±¤éœ€è¦å°ˆæ¥­çŸ¥è­˜ï¼Œä¾‹å¦‚ chiaroscuroï¼ˆæ˜æš—å°ç…§æ³•ï¼‰ã€‚\n",
    "        - éœ€è¦å¤šæ¬¡å˜—è©¦èˆ‡å¾®èª¿ï¼Œæ‰èƒ½æ‰¾åˆ°æœ€ä½³çµ„åˆã€‚\n",
    "\n",
    "2. è‡ªç„¶èªè¨€æç¤ºï¼ˆNatural Language Prompt):\n",
    "\n",
    "    - ç¯„ä¾‹:\n",
    "\n",
    "       A Japanese idol with a breathtakingly glamorous ulzzang appearance,  She has a slim, v-shaped face with large, almond-shaped eyes that sparkle with a lustrous, captivating charm, exuding an aura of youth and ethereal beauty. Her expression is innocent yet alluring, with flawless porcelain skin that enhances her delicate, anime-inspired features. The setting is carefully crafted to complement her enchantment, with soft, diffused lighting that accentuates her mesmerizing, glamorous presence, creating a dreamy and youthful, anime-like allure.\n",
    "\n",
    "\n",
    "    - ç‰¹é»èˆ‡æ³¨æ„äº‹é …ï¼š\n",
    "\n",
    "        - å¥å­å¯«å¾—æµæš¢ã€èªè¨€å„ªç¾ï¼Œèƒ½æå‡ç”Ÿæˆåœ–åƒçš„è³ªæ„Ÿã€‚\n",
    "\n",
    "        - å°éæ¯èªä½¿ç”¨è€…ä¾†èªªï¼Œæ•´åˆå¤šå€‹æè¿°æ€§è©å½™æ˜¯ä¸€å¤§æŒ‘æˆ°ã€‚\n",
    "\n",
    "        - éƒ¨åˆ†è©å½™åœ¨ç›£æ§åš´æ ¼çš„æ¨¡å‹ä¸‹å¯èƒ½æœƒè¢«å±è”½ï¼Œä¾‹å¦‚ serafukuã€‚\n",
    "\n",
    "        - Image-1 ç­‰æ¨¡å‹å¯èƒ½æœƒå°éæ–¼æ˜é¡¯çš„ NSFW æç¤ºè©é€²è¡Œæ””æˆªã€‚è‹¥æƒ³ç”Ÿæˆ NSFW çš„å…§å®¹ï¼Œå»ºè­°å¯ä»¥åƒè€ƒé–‹æºç¤¾ç¾¤ï¼Œä¾‹å¦‚ TensorArt/TensorHubã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742b0214-ea46-4a41-99f4-9cf762e51b0e",
   "metadata": {},
   "source": [
    "## èå…¥ LCEL èˆ‡ LangChain â€” è®“æ¨¡å‹å¹«ä½ ç”Ÿæˆæ›´å¥½çš„ Prompt\n",
    "\n",
    "> ğŸ¯ **æœ¬ç« å­¸å®Œä½ å°‡èƒ½å­¸æœƒä»€éº¼ï¼š**\n",
    "> - èƒ½å°‡ GPT æ¨¡å‹ç”Ÿæˆçš„æ–‡å­—æç¤ºç›´æ¥å°å…¥å½±åƒç”Ÿæˆ API  \n",
    "> - å¯¦ä½œä¸€å€‹è‡ªå‹•å¾æè¿°æ–‡å­— â†’ prompt â†’ åœ–åƒçš„å®Œæ•´æµç¨‹  \n",
    "\n",
    "æœ¬ç¯€å°‡ä»‹ç´¹å¦‚ä½•é‹ç”¨ LangChain å»ºç«‹ä¸€å€‹èƒ½è‡ªå‹•åŒ–æ’°å¯«æç¤ºè©çš„æµç¨‹ï¼Œä¸¦ä¸²æ¥å½±åƒç”Ÿæˆ APIï¼Œé”æˆç«¯åˆ°ç«¯çš„è‡ªå‹•åœ–åƒç”Ÿæˆã€‚\n",
    "\n",
    "### Step1\n",
    "\n",
    "å¯ä»¥çµ¦äºˆå…§å®¹ï¼Œä¸¦ä¸”è®“æ–‡å­—æ¨¡å‹å¹«å¿™å¯«æç¤ºè©ã€‚ä¸¦ä¸”å¯ä»¥è€ƒæ…®ä½¿ç”¨mlflowç›£è¦–ç”¢å‡ºçš„æç¤ºè©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4718b9d-b7f5-4856-9074-d512d0837599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.image import ImagePromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def build_standard_chat_prompt_template(kwargs):\n",
    "    messages = []\n",
    "\n",
    "    if 'system' in kwargs:\n",
    "        content = kwargs.get('system')\n",
    "\n",
    "        # allow list of prompts for multimodal\n",
    "        if isinstance(content, list):\n",
    "            prompts = [PromptTemplate(**c) for c in content]\n",
    "        else:\n",
    "            prompts = [PromptTemplate(**content)]\n",
    "\n",
    "        message = SystemMessagePromptTemplate(prompt=prompts)\n",
    "        messages.append(message)\n",
    "\n",
    "    if 'human' in kwargs:\n",
    "        content = kwargs.get('human')\n",
    "\n",
    "        # allow list of prompts for multimodal\n",
    "        if isinstance(content, list):\n",
    "            prompts = []\n",
    "            for c in content:\n",
    "                if c.get(\"type\") == \"image\":\n",
    "                    prompts.append(ImagePromptTemplate(**c))\n",
    "                else:\n",
    "                    prompts.append(PromptTemplate(**c))\n",
    "        else:\n",
    "            if content.get(\"type\") == \"image\":\n",
    "                prompts = [ImagePromptTemplate(**content)]\n",
    "            else:\n",
    "                prompts = [PromptTemplate(**content)]\n",
    "\n",
    "        message = HumanMessagePromptTemplate(prompt=prompts)\n",
    "        messages.append(message)\n",
    "\n",
    "    chat_prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "    \n",
    "    return chat_prompt_template\n",
    "\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-mini\", temperature=0, \n",
    "                   name=\"my_model\"\n",
    "                  )\n",
    "\n",
    "system_template = (\"You are a helpful AI assistant and an art expert with extensive knowledge of photography \"\n",
    "                   \"and illustration. You excel at creating breathtaking masterpieces with the DALLE-3 model. \"\n",
    "                   \"For this task, you will be provided with a description of an image, and you will generate a \"\n",
    "                   \"corresponding DALLE-3 prompt. The prompt should be detailed and descriptive, capturing the \"\n",
    "                   \"essence of the image.\")\n",
    "\n",
    "human_template = \"{image_desc}\"\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variable\": [\"image_desc\"]}}\n",
    "    \n",
    "chat_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "nl_prompt_generation_chain = chat_prompt_template | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c89a516-2be9-4641-b061-ddaa79687a97",
   "metadata": {},
   "source": [
    "### Step2\n",
    "\n",
    "å°‡ç”Ÿæˆçš„æç¤ºè©æ”¾å…¥å½±åƒç”ŸæˆAPIä¸­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dc5bc6-3c7e-4fff-9115-7a82bb5f0dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from typing import Dict\n",
    "\n",
    "from langchain_core.runnables import chain, RunnableLambda, RunnableParallel, RunnablePassthrough\n",
    "\n",
    "\n",
    "@chain\n",
    "def gpt_image_worker(kwargs: Dict):\n",
    "\n",
    "    \"\"\"\n",
    "    Generates an image using OpenAI's GPT-Image-1 model based on the provided prompt and optional parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    kwargs (Dict): A dictionary containing the following keys:\n",
    "        - 'nl_prompt' (str): The natural language prompt describing the image to be generated.\n",
    "        - 'size' (str, optional): The size of the generated image. Default is \"1024x1024\".\n",
    "        - 'quality' (str, optional): The quality of the generated image. Default is \"medium\".\n",
    "    \n",
    "    Returns:\n",
    "    str: image base64 string\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Start generating image...\")\n",
    "    print(f\"prompt: {kwargs['nl_prompt']}\")\n",
    "    client = OpenAI()\n",
    "\n",
    "    response = client.images.generate(\n",
    "        model=kwargs.get('model', \"gpt-image-1\"),\n",
    "        prompt=kwargs['nl_prompt'],\n",
    "        size=kwargs.get(\"size\", \"1024x1024\"),\n",
    "        quality=kwargs.get('quality', 'medium'),\n",
    "        moderation=kwargs.get('moderation', 'auto'),\n",
    "        n=1)\n",
    "\n",
    "    image_base64 = response.data[0].b64_json\n",
    "    \n",
    "    return image_base64\n",
    "\n",
    "\n",
    "@chain\n",
    "def base64_to_file(kwargs):\n",
    "\n",
    "    \"\"\"\n",
    "    Save the image from a base64 string\n",
    "    \"\"\"\n",
    "    \n",
    "    image_base64 = kwargs['image_base64']\n",
    "    filename = kwargs['filename']\n",
    "    \n",
    "    with open(f\"{filename}\", \"wb\") as fh:\n",
    "        fh.write(base64.b64decode(image_base64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e054b848-beae-4ad2-9ce4-c1dd9cf30255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: ç”Ÿæˆä¾ç…§ä½ æƒ³è¦çš„åœ–åƒæè¿°åœ–åƒæç¤ºè©\n",
    "step_1 = RunnablePassthrough.assign(nl_prompt=itemgetter('image_desc')|nl_prompt_generation_chain)\n",
    "\n",
    "# step 2: ç”Ÿæˆåœ–åƒï¼Œä¸¦å°‡base64å­—ä¸²æ”¾å…¥image_base64è®Šæ•¸ä¸­\n",
    "step_2 = RunnablePassthrough.assign(image_base64=gpt_image_worker)\n",
    "\n",
    "# step 3: å°‡base64å­—ä¸²å„²å­˜ç‚ºåœ–åƒ\n",
    "step_3 = base64_to_file\n",
    "\n",
    "# å°‡ä¸‰å€‹æ­¥é©Ÿç”±æ°´ç®¡ç¬¦è™Ÿ(|)é€£çµèµ·ä¾†\n",
    "gpt_image_chain =  step_1|step_2|step_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6cd391-a27d-4ee6-91c9-c55060b30bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "gpt_image_chain.invoke({\"size\": \"1024x1536\",\n",
    "                     \"quality\": \"medium\",\n",
    "                     \"image_desc\": dedent(\"\"\"warhammer 40k, astartes, power armor, chain sword, purity seal, \n",
    "                     oil painting, cinematic view, battle field, black templars, sacred light upon the arstartes\"\"\"),\n",
    "                     \"filename\": \"tutorial/week_7/astartes.png\"\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5138dba-b81d-4d85-9840-a8e9b1919404",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_image_chain.invoke({\"size\": \"1024x1536\",\n",
    "                     \"quality\": \"medium\",\n",
    "                     \"model\": \"gpt-image-1.5\",\n",
    "                     \"image_desc\": dedent(\"\"\"warhammer 40k, astartes, power armor, chain sword, purity seal, \n",
    "                     oil painting, cinematic view, battle field, black templars, sacred light upon the arstartes\"\"\"),\n",
    "                     \"filename\": \"tutorial/week_7/astartes_15.png\"\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2228dc-39a5-41e3-85ae-12fbce7dee96",
   "metadata": {},
   "source": [
    "# åœ–åƒæ¸²æŸ“(Image Render)\n",
    "\n",
    "ã€Œåœ–åƒæ¸²æŸ“ã€(Image to Image, ç°¡ç¨± Img2Img) æŒ‡çš„æ˜¯ï¼š\n",
    "åœ¨å·²æœ‰åœ–ç‰‡çš„åŸºç¤ä¸Šï¼Œæ­é…æ–°çš„æç¤ºè© (prompt)ï¼Œç”Ÿæˆå¦ä¸€å¼µé¢¨æ ¼æˆ–å…§å®¹æœ‰æ‰€è®ŠåŒ–çš„åœ–ç‰‡ã€‚\n",
    "\n",
    "## âœ¨ ç‰¹é»\n",
    "\n",
    "1. è¼¸å…¥èˆ‡è¼¸å‡º\n",
    "\n",
    "    - è¼¸å…¥ï¼šä¸€å¼µå·²æœ‰çš„åœ–ç‰‡ + æç¤ºè©\n",
    "\n",
    "    - è¼¸å‡ºï¼šæ ¹æ“šæç¤ºè©æ”¹é€ éçš„åœ–ç‰‡\n",
    "\n",
    "2. éˆæ´»æ€§\n",
    "\n",
    "    - å¯ä»¥ä¿ç•™åŸåœ–çš„çµæ§‹ï¼ˆä¾‹å¦‚äººç‰©å§¿å‹¢ï¼‰ï¼Œåªæ”¹è®Šç´°ç¯€ï¼ˆå¦‚é«®è‰²ã€è¡£æœã€å ´æ™¯ï¼‰ã€‚\n",
    "\n",
    "    - ä¹Ÿå¯ä»¥åšé¢¨æ ¼è½‰æ›ï¼Œè®“ç…§ç‰‡è®Šæˆæ²¹ç•«é¢¨ã€æ¼«ç•«é¢¨ã€æ’ç•«é¢¨ã€‚\n",
    "\n",
    "3. å¸¸è¦‹æ‡‰ç”¨\n",
    "\n",
    "    - ä¿®åœ–ï¼šå»é™¤èƒŒæ™¯ã€ä¿®æ”¹è‡‰éƒ¨ç´°ç¯€ã€æ›è¡£æœã€‚\n",
    "\n",
    "    - é¢¨æ ¼åŒ–ï¼šå°‡ç¾å¯¦ç…§ç‰‡è½‰æˆå‹•æ¼«é¢¨ã€æ’ç•«é¢¨ã€‚\n",
    "\n",
    "    - è¿­ä»£è¨­è¨ˆï¼šå¿«é€Ÿå˜—è©¦ä¸åŒçš„è§’è‰²æœè£ã€é«®å‹æˆ–ç’°å¢ƒã€‚\n",
    "\n",
    "    - å±€éƒ¨ä¿®æ”¹ (Inpainting)ï¼šåœ¨åœ–ç‰‡ä¸ŠæŒ‡å®šå€åŸŸï¼Œåƒ…å°è©²å€åŸŸé€²è¡Œæ›¿æ›æˆ–ä¿®è£œã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c029811f-0795-4d9f-b4d5-9a119acd4b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b700bf0c-56b6-4a95-8fc1-8a81e5bcac6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Build HTML string\n",
    "html = '<div style=\"display: flex; flex-direction: column;\">'\n",
    "\n",
    "html += '<div style=\"display: flex; justify-content: space-around; margin-bottom: 10px;\">'\n",
    "html += f'''\n",
    "    <div>\n",
    "        <img src=\"Eve_Stellar_Blade.png\" style=\"width: 300px; height: auto; border-radius: 8px; box-shadow: 2px 2px 6px rgba(0,0,0,0.2);\" />\n",
    "    </div>\n",
    "'''\n",
    "html += '</div>'\n",
    "\n",
    "html += '</div>'\n",
    "\n",
    "# Display the HTML\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be3c37b-8c72-4907-820e-b9b5ca9dd983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "from initialization import credential_init\n",
    "\n",
    "credential_init()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "prompt = dedent(\"\"\"\n",
    "Please rending this image as a realistic photo of a girl cosplaying. A Korean girl with a\n",
    "slim, v-shaped face with large, almond-shaped eyes that sparkle with captivating charm, exuding \n",
    "an aura of youth and ethereal beauty. With flawless skin that enhances her delicate, \n",
    "anime-inspired features. The setting is carefully crafted to complement her enchantment, with \n",
    "soft, diffused lighting that accentuates her mesmerizing, glamorous presence, creating a dreamy \n",
    "and youthful, anime-like allure. Her makeup should resemble the features of K-beauty, such as pale skin tones \n",
    "and dewed skin texture. \n",
    "\"\"\")\n",
    "\n",
    "\n",
    "image_path = os.path.join(\"tutorial\", \"week_7\", \"Eve_Stellar_Blade.png\")\n",
    "\n",
    "result_edit = client.images.edit(\n",
    "    model=\"gpt-image-1\",\n",
    "    image=open(image_path, \"rb\"), \n",
    "    prompt=prompt,\n",
    "    size=\"1024x1536\",\n",
    "    input_fidelity=\"high\", # é€™å€‹é¸é …éœ€è¦openai 1.97.0ä»¥ä¸Šç‰ˆæœ¬\n",
    "    #quality=\"high\"\n",
    ")\n",
    "\n",
    "image_base64 = result_edit.data[0].b64_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19f4403-b6f3-4d5b-b489-68a746633956",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(f'<img src=\"data:image/png;base64,{image_base64}\" />')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aec021-f0b7-4fde-9c7d-b69845dba5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_edit = client.images.edit(\n",
    "    model=\"gpt-image-1.5\",\n",
    "    image=open(image_path, \"rb\"), \n",
    "    prompt=prompt,\n",
    "    size=\"1024x1536\",\n",
    "    input_fidelity=\"high\", # é€™å€‹é¸é …éœ€è¦openai 1.97.0ä»¥ä¸Šç‰ˆæœ¬\n",
    "    #quality=\"high\"\n",
    ")\n",
    "\n",
    "image_base64 = result_edit.data[0].b64_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5852e53-98be-4166-8812-b04c5dad9a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(f'<img src=\"data:image/png;base64,{image_base64}\" />')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d233ce-f88f-44e2-bb3c-137ada00d8d1",
   "metadata": {},
   "source": [
    "ä½ å¯ä»¥ä½¿ç”¨ä¸€å¼µæˆ–æ˜¯å¤šå¼µåœ–ç‰‡åšç‚ºåƒç…§ç‰©\n",
    "\n",
    "- Noshiro èƒ½ä»£ (Azur Lane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75090997-6cd6-44c8-9485-96faa0fb087f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "html = '<div style=\"display: flex; flex-direction: column;\">'\n",
    "\n",
    "html += '<div style=\"display: flex; justify-content: space-around; margin-bottom: 10px;\">'\n",
    "html += f'''\n",
    "    <div>\n",
    "        <div>\n",
    "            <img src=\"Noshiro - Spring.png\" style=\"width: 300px; height: auto; border-radius: 8px; box-shadow: 2px 2px 6px rgba(0,0,0,0.2);\" />\n",
    "            <img src=\"Noshiro - Summer.png\" style=\"width: 300px; height: auto; border-radius: 8px; box-shadow: 2px 2px 6px rgba(0,0,0,0.2);\" />\n",
    "        </div>\n",
    "        <div>\n",
    "            <img src=\"Noshiro - Fall.png\" style=\"width: 300px; height: auto; border-radius: 8px; box-shadow: 2px 2px 6px rgba(0,0,0,0.2);\" />\n",
    "            <img src=\"Noshiro - Winter.png\" style=\"width: 300px; height: auto; border-radius: 8px; box-shadow: 2px 2px 6px rgba(0,0,0,0.2);\" />\n",
    "        </div>\n",
    "    </div>\n",
    "'''\n",
    "html += '</div>'\n",
    "\n",
    "html += '</div>'\n",
    "\n",
    "# Display the HTML\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593356f2-1bc9-41a9-859b-08af165cd3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_1 = os.path.join(\"tutorial\", \"week_7\", \"Noshiro - Spring.png\")\n",
    "image_2 = os.path.join(\"tutorial\", \"week_7\", \"Noshiro - Summer.png\")\n",
    "image_3 = os.path.join(\"tutorial\", \"week_7\", \"Noshiro - Fall.png\")\n",
    "image_4 = os.path.join(\"tutorial\", \"week_7\", \"Noshiro - Winter.png\")\n",
    "\n",
    "result_edit = client.images.edit(\n",
    "    model=\"gpt-image-1\",\n",
    "    image=[\n",
    "        open(image_1, \"rb\"),\n",
    "        # open(image_2, \"rb\"),\n",
    "        # open(image_3, \"rb\"),\n",
    "        # open(image_4, \"rb\"),\n",
    "    ],\n",
    "    prompt=dedent(\"\"\"\n",
    "    Create an advertisement of a high end perfume based on the reference image. \n",
    "    The advertisement should deliver a mesmerizingly glamorous texture. \n",
    "    \"\"\"),\n",
    "    size=\"1024x1536\",\n",
    "    input_fidelity=\"high\", # é€™å€‹é¸é …éœ€è¦openai 1.97.0ä»¥ä¸Šç‰ˆæœ¬\n",
    "    quality=\"high\"\n",
    ")\n",
    "\n",
    "image_base64 = result_edit.data[0].b64_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b573038-8787-423e-8da1-90500945ca7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(f'<img src=\"data:image/png;base64,{image_base64}\"/>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6886ae-1e04-41f9-8e92-c95a95b48543",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_edit = client.images.edit(\n",
    "    model=\"gpt-image-1.5\",\n",
    "    image=[\n",
    "        open(image_1, \"rb\"),\n",
    "        # open(image_2, \"rb\"),\n",
    "        # open(image_3, \"rb\"),\n",
    "        # open(image_4, \"rb\"),\n",
    "    ],\n",
    "    prompt=dedent(\"\"\"\n",
    "    Create an advertisement of a high end perfume based on the reference image. \n",
    "    The advertisement should deliver a mesmerizingly glamorous texture. \n",
    "    \"\"\"),\n",
    "    size=\"1024x1536\",\n",
    "    input_fidelity=\"high\", # é€™å€‹é¸é …éœ€è¦openai 1.97.0ä»¥ä¸Šç‰ˆæœ¬\n",
    "    quality=\"high\"\n",
    ")\n",
    "\n",
    "image_base64 = result_edit.data[0].b64_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9015734b-923e-4486-84a2-4d54c9ef9249",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(f'<img src=\"data:image/png;base64,{image_base64}\"/>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bb9bb7-da23-4023-9d27-0a6c32dc8167",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"tutorial\", \"week_7\", \"Noshiro - Summer - Advertisement.png\"), \"wb\") as fh:\n",
    "    fh.write(base64.b64decode(image_base64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86cbbd4-2e76-41c1-ae46-148b0d9609a2",
   "metadata": {},
   "source": [
    "### å°‡ä¸åŒåœ–ç‰‡çš„å…§å®¹èåˆåœ¨ä¸€èµ·\n",
    "\n",
    "åœ–ç‰‡ä¾†æº: https://tensor.art/u/629260971684229814"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6b128b-141c-4e7b-9fa6-0169ef3623c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '<div style=\"display: flex; flex-direction: column;\">'\n",
    "\n",
    "html += '<div style=\"display: flex; justify-content: space-around; margin-bottom: 10px;\">'\n",
    "html += f'''\n",
    "    <div>\n",
    "        <div>\n",
    "            <img src=\"maehara-1.jpg\" style=\"width: 300px; height: auto; border-radius: 8px; box-shadow: 2px 2px 6px rgba(0,0,0,0.2);\" />\n",
    "            <img src=\"maehara-2.jpg\" style=\"width: 300px; height: auto; border-radius: 8px; box-shadow: 2px 2px 6px rgba(0,0,0,0.2);\" />\n",
    "        </div>\n",
    "    </div>\n",
    "'''\n",
    "html += '</div>'\n",
    "\n",
    "html += '</div>'\n",
    "\n",
    "# Display the HTML\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769c3ca6-307f-4ec0-a8b2-950057d253de",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_a = os.path.join(\"tutorial\", \"week_7\", \"maehara-1.jpg\")\n",
    "image_b = os.path.join(\"tutorial\", \"week_7\", \"maehara-2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef057e0b-00b4-4adf-a502-ab30227319a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_edit = client.images.edit(\n",
    "    model=\"gpt-image-1\",\n",
    "    image=[\n",
    "        open(image_a, \"rb\"),\n",
    "        open(image_b, \"rb\"),\n",
    "    ],\n",
    "    prompt=dedent(\"\"\"\n",
    "    Fusion the two images to create a high definition 8k movie poster with the text as the background. \n",
    "    \"\"\"),\n",
    "    size=\"1024x1536\",\n",
    "    input_fidelity=\"high\", # é€™å€‹é¸é …éœ€è¦openai 1.97.0ä»¥ä¸Šç‰ˆæœ¬\n",
    "    quality=\"high\"\n",
    ")\n",
    "\n",
    "image_base64 = result_edit.data[0].b64_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff23cbd6-3c75-42b8-a811-ccbe135a32ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(f'<img src=\"data:image/png;base64,{image_base64}\"/>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e41eb1-6fc8-4f66-b30b-fbaf3469e1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_edit = client.images.edit(\n",
    "    model=\"gpt-image-1.5\",\n",
    "    image=[\n",
    "        open(image_a, \"rb\"),\n",
    "        open(image_b, \"rb\"),\n",
    "    ],\n",
    "    prompt=dedent(\"\"\"\n",
    "    Fusion the two images to create a high definition 8k movie poster with the text as the background. \n",
    "    \"\"\"),\n",
    "    size=\"1024x1536\",\n",
    "    input_fidelity=\"high\", # é€™å€‹é¸é …éœ€è¦openai 1.97.0ä»¥ä¸Šç‰ˆæœ¬\n",
    "    quality=\"high\"\n",
    ")\n",
    "\n",
    "image_base64 = result_edit.data[0].b64_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2dfedf-4e32-4187-be5f-0a1e02638c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(f'<img src=\"data:image/png;base64,{image_base64}\"/>')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa8ebfc-db14-4aea-92e5-519112ce17c5",
   "metadata": {},
   "source": [
    "## å±€éƒ¨ä¿®è£œ (Inpaint)\n",
    "\n",
    "ä½ å¯ä»¥æä¾›ä¸€å€‹é®ç½© (mask) ä¾†æŒ‡å®šåœ–åƒä¸­è¦è¢«ç·¨è¼¯çš„å€åŸŸã€‚\n",
    "\n",
    "ç•¶åœ¨ GPT Image ä¸­ä½¿ç”¨é®ç½©æ™‚ï¼Œé¡å¤–çš„æŒ‡ä»¤æœƒä¸€ä½µå‚³é€çµ¦æ¨¡å‹ï¼Œä»¥ä¾¿æ›´å¥½åœ°å¼•å°ç·¨è¼¯éç¨‹ã€‚\n",
    "\n",
    "### é®ç½©çš„è¦æ±‚\n",
    "\n",
    "è¦ç·¨è¼¯çš„åœ–ç‰‡èˆ‡é®ç½©å¿…é ˆç‚ºç›¸åŒçš„æ ¼å¼èˆ‡å°ºå¯¸ï¼Œä¸”æª”æ¡ˆå¤§å°éœ€å°æ–¼ 50MBã€‚\n",
    "\n",
    "é®ç½©åœ–ç‰‡å¿…é ˆåŒ…å« Alpha é€šé“ã€‚å¦‚æœä½ æ˜¯ä½¿ç”¨åœ–åƒç·¨è¼¯å·¥å…·ä¾†è£½ä½œé®ç½©ï¼Œè«‹ç¢ºä¿åœ¨å„²å­˜æ™‚ä¿ç•™ Alpha é€šé“ã€‚\n",
    "\n",
    "\n",
    "### Bug Report\n",
    "\n",
    "https://community.openai.com/t/gpt-image-1-problems-with-mask-edits/1240639/15\n",
    "\n",
    "Image-1 åœ¨ inpainting ä¼¼ä¹åšçš„å¾ˆç³Ÿç³•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb89164a-1949-460f-96d7-97799c481a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '<div style=\"display: flex; flex-direction: column;\">'\n",
    "\n",
    "html += '<div style=\"display: flex; justify-content: space-around; margin-bottom: 10px;\">'\n",
    "html += f'''\n",
    "    <div>\n",
    "        <div>\n",
    "            <img src=\"Noshiro - Winter - Mask.png\" style=\"width: 300px; height: auto; border-radius: 8px; box-shadow: 2px 2px 6px rgba(0,0,0,0.2);\" />\n",
    "        </div>\n",
    "    </div>\n",
    "'''\n",
    "html += '</div>'\n",
    "\n",
    "html += '</div>'\n",
    "\n",
    "# Display the HTML\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e57a75-ae39-469c-beb4-022ec309dac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_in = os.path.join(\"tutorial\", \"week_7\", \"Noshiro - Winter.png\")\n",
    "image_mask = os.path.join(\"tutorial\", \"week_7\", \"Noshiro - Winter - Mask.png\")\n",
    "\n",
    "result_edit = client.images.edit(\n",
    "    model=\"gpt-image-1\",\n",
    "    image=open(image_in, \"rb\"),\n",
    "    mask=open(image_mask, \"rb\"),\n",
    "    prompt=dedent(\"\"\"\n",
    "    In the winter, a girl walking on water and holding MjÃ¶lnir. MjÃ¶lnir is surrounded with electricity and current. \n",
    "    \"\"\"),\n",
    "    size=\"1024x1536\",\n",
    "    input_fidelity=\"high\", # é€™å€‹é¸é …éœ€è¦openai 1.97.0ä»¥ä¸Šç‰ˆæœ¬\n",
    "    quality=\"high\"\n",
    ")\n",
    "\n",
    "image_base64 = result_edit.data[0].b64_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ef8cdc-6a7d-43c5-935b-1b4ac2320f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(f'<img src=\"data:image/png;base64,{image_base64}\"/>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824ba903-ad84-4030-962e-88835ff73ff4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Agentï¼ˆä»£ç†å‹ç³»çµ±ï¼‰\n",
    "\n",
    "> ğŸ¯ **æœ¬ç« å­¸å®Œä½ å°‡èƒ½å­¸æœƒä»€éº¼ï¼š**\n",
    "> - ç†è§£ **Agent** çš„æ ¸å¿ƒæ¦‚å¿µèˆ‡èˆ‡å‚³çµ± LLM å›ç­”çš„å·®ç•°  \n",
    "> - æŒæ¡ **ReAct (Reasoning + Acting)** çš„è¡Œå‹•æ€è€ƒå¾ªç’°æ¶æ§‹  \n",
    "> - å­¸æœƒä»¥ LangChain å»ºç«‹å…·é‚è¼¯æ¨ç†èˆ‡å·¥å…·èª¿ç”¨èƒ½åŠ›çš„ Agent  \n",
    "> - ç†Ÿæ‚‰å¦‚ä½•ç”¨ **MLflow** ç›£æ§æ¨¡å‹åŸ·è¡Œéç¨‹èˆ‡æ—¥èªŒ  \n",
    "> - å¯¦ä½œèƒ½è‡ªè¡Œè¦åŠƒæ­¥é©Ÿä¸¦è¨ˆç®—å•é¡Œçš„æ™ºèƒ½ä»£ç†  \n",
    "\n",
    "Anthropic definition for Agent: `LLMs autonomously using tools in a loop`\n",
    "\n",
    "## ReAct Framework\n",
    "\n",
    "æœ¬ç¯€å°‡èªªæ˜ ReAct çš„æ¦‚å¿µèˆ‡åŸ·è¡Œçµæ§‹ï¼Œå¹«åŠ©ä½ ç†è§£æ€è€ƒï¼ˆReasoningï¼‰èˆ‡è¡Œå‹•ï¼ˆActingï¼‰å¦‚ä½•äº¤äº’ä½œç”¨ã€‚\n",
    "\n",
    "- ReAct: Reasoning - Action\n",
    "\n",
    "- ReAct Agent çš„é‹ä½œæµç¨‹å¤§è‡´æ˜¯ï¼š\n",
    "\n",
    "    1. æ€è€ƒ (Reasoning)ï¼šæ ¹æ“šç•¶å‰çš„ä¸Šä¸‹æ–‡ï¼Œç”Ÿæˆå…§éƒ¨çš„æ¨ç†æˆ–è¨ˆåŠƒã€‚\n",
    "\n",
    "    2. è¡Œå‹• (Acting)ï¼šæ ¹æ“šæ¨ç†çš„çµæœï¼Œæ±ºå®šè¦æ¡å–çš„å‹•ä½œï¼ˆä¾‹å¦‚æŸ¥è©¢å·¥å…·ã€å‘¼å« APIã€æª¢ç´¢çŸ¥è­˜ï¼‰ã€‚\n",
    "\n",
    "    3. è§€å¯Ÿ (Observation)ï¼šå¾—åˆ°å·¥å…·æˆ–ç’°å¢ƒå›é¥‹ã€‚\n",
    "\n",
    "    4. è¿­ä»£ï¼šå°‡è§€å¯Ÿçµæœå†è¼¸å…¥å›å»ï¼Œé€²å…¥ä¸‹ä¸€è¼ªæ€è€ƒã€‚\n",
    "\n",
    "    ç›´åˆ°ï¼š\n",
    "\n",
    "    a. é”åˆ°æœ€çµ‚ç­”æ¡ˆï¼Œæˆ–\n",
    "\n",
    "    b. é‡åˆ°è¨­ç½®çš„åœæ­¢æ¢ä»¶ï¼ˆä¾‹å¦‚ token é™åˆ¶ã€æ­¥æ•¸é™åˆ¶ã€æ˜ç¢ºçš„ \"çµæŸ\" ä¿¡è™Ÿï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ce015d-8bf1-49e0-80b3-e18b78449965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(url='https://statusneo.com/wp-content/uploads/2024/01/fe9fa1ac-dfde-4d91-8b5b-4497b742c414_1400x686.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb253c73-f29a-4f86-9e1c-d7262e2c73eb",
   "metadata": {},
   "source": [
    "### ReAct Template\n",
    "\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "\n",
    "Thought: you should always think about what to do\n",
    "\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "\n",
    "Action Input: the input to the action\n",
    "\n",
    "Observation: the result of the action\n",
    "\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "\n",
    "Thought: I now know the final answer\n",
    "\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "Thought:{agent_scratchpad}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26638f8e-95ba-44fd-b046-877dfaca93a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be49e633-6e96-45b9-8ca9-71ccd4893e62",
   "metadata": {},
   "source": [
    "### å»ºç«‹MLflowç›£æ§\n",
    "\n",
    "mlflow server --host 127.0.0.1 --port 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de00d300-5214-4b61-b69d-3e4fb9a7b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from langchain_community.callbacks import MlflowCallbackHandler\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from initialization import credential_init\n",
    "\n",
    "credential_init()\n",
    "\n",
    "experiment = \"Week-7\"\n",
    "uri = \"http://127.0.0.1:8080\"\n",
    "\n",
    "mlflow.set_tracking_uri(uri=uri)\n",
    "\n",
    "# Start or get an MLflow run explicitly\n",
    "mlflow.set_experiment(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d131ad1b-c2a1-494b-ad17-074e969c9ddc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-mini\", temperature=0, \n",
    "                   name=\"my_model\"\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469b6d83-60e4-40f2-929a-61d26e417e15",
   "metadata": {},
   "source": [
    "Langchain 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d1356-9e27-460d-a197-d37dbaedc8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from langchain.agents import create_agent\n",
    "# from langchain_community.callbacks.mlflow_callback import MlflowCallbackHandler\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "agent = create_agent(\n",
    "    \"gpt-4o-mini\",\n",
    "    name=\"Simple Agent\"\n",
    ")\n",
    "\n",
    "agent.invoke({\"messages\": \"Please calculate the area of a circle that has a radius of 10.923mm\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac67459-977c-4055-805e-1c710dddc85f",
   "metadata": {},
   "source": [
    "# Tool èˆ‡ Agent æ‡‰ç”¨\n",
    "\n",
    "> ğŸ¯ **æœ¬ç« å­¸å®Œä½ å°‡èƒ½å­¸æœƒä»€éº¼ï¼š**\n",
    "> - ç†è§£ LangChain çš„ **Tool ä»‹é¢** èˆ‡è‡ªè¨‚å·¥å…·é–‹ç™¼æµç¨‹  \n",
    "> - å¯¦ä½œä¸‰ç¨®å¸¸è¦‹å·¥å…·ï¼š**MathTool**ã€**SearchTool**ã€**VectorStoreTool**  \n",
    "> - å­¸æœƒä½¿ç”¨ **PydanticOutputParser** å®šç¾©è¼¸å…¥/è¼¸å‡ºæ ¼å¼  \n",
    "> - æŒæ¡å¦‚ä½•å°‡å¤šå€‹å·¥å…·æ¨¡çµ„åŒ–ä¸¦åœ¨ Agent ä¸­æ•´åˆ  \n",
    "> - å»ºç«‹å¯è¨˜æ†¶å°è©±å…§å®¹çš„ **Conversational Agent**  \n",
    "> - ç†è§£å¦‚ä½•å°‡ Agent éƒ¨ç½²è‡³ **LangServe** èˆ‡ **Streamlit** ä»‹é¢  \n",
    "\n",
    "æˆ‘å€‘çŸ¥é“LLMä¸æ˜¯è®“ä½ ç®—æ•¸å­¸ç”¨çš„ã€‚æ•´æ•¸çš„åŠ æ¸›æ³•å¯èƒ½å¯ä»¥ï¼Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d4eb4d-1486-4b39-99f5-403471b8c43d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Union\n",
    "from textwrap import dedent\n",
    "\n",
    "from langchain.tools import BaseTool\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "def build_standard_chat_prompt_template(kwargs):\n",
    "\n",
    "    messages = []\n",
    " \n",
    "    if 'system' in kwargs:\n",
    "        content = kwargs.get('system')\n",
    "        prompt = PromptTemplate(**content)\n",
    "        message = SystemMessagePromptTemplate(prompt=prompt)\n",
    "        messages.append(message)  \n",
    "\n",
    "    if 'human' in kwargs:\n",
    "        content = kwargs.get('human')\n",
    "        prompt = PromptTemplate(**content)\n",
    "        message = HumanMessagePromptTemplate(prompt=prompt)\n",
    "        messages.append(message)\n",
    "        \n",
    "    chat_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "    \n",
    "    return chat_prompt\n",
    "\n",
    "\n",
    "@chain\n",
    "def code_execution(code):\n",
    "    \n",
    "    match = re.findall(r\"python\\n(.*?)\\n```\", code, re.DOTALL)\n",
    "    python_code = match[0]\n",
    "    \n",
    "    lines = python_code.strip()#.split('\\n')\n",
    "    # *stmts, last_line = lines\n",
    "\n",
    "    local_vars = {}\n",
    "    exec(lines, {}, local_vars)\n",
    "\n",
    "    return local_vars['answer']\n",
    "\n",
    "\n",
    "system_template = dedent(\"\"\"\n",
    "    You are a highly skilled Python developer. Your task is to generate Python code strictly based on the user's instructions.\n",
    "    Leverage statistical and mathematical libraries such as `statsmodels`, `scipy`, and `numpy` where appropriate to solve the problem.\n",
    "    Your response must contain only the Python code â€” no explanations, comments, or additional text.\n",
    "\"\"\")\n",
    "\n",
    "human_template = dedent(\"\"\"\n",
    "                        {query}\n",
    "                        \n",
    "                        Always copy the final answer to a variable `answer`\n",
    "                        Code:\n",
    "                        \"\"\")\n",
    "\n",
    "\n",
    "input_ = {\"system\": {\"template\": system_template},\n",
    "          \"human\": {\"template\": human_template,\n",
    "                    \"input_variable\": [\"query\"]}}\n",
    "\n",
    "code_chat_prompt_template = build_standard_chat_prompt_template(input_)\n",
    "\n",
    "model_agent = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                         model_name=\"gpt-4o\", temperature=0, name='agent_llm'\n",
    "                        )\n",
    "\n",
    "model_coder = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                         model_name=\"gpt-4o-mini\", temperature=0, name='coder_llm'\n",
    "                        )\n",
    "\n",
    "code_generation = code_chat_prompt_template|model_coder|StrOutputParser()\n",
    "\n",
    "code_pipeline = code_generation|code_execution\n",
    "\n",
    "\n",
    "class MathTool(BaseTool):\n",
    "    name:str = \"Math-Solver\" \n",
    "    description:str = dedent(\"\"\"Use this tool to solve algorithmic problem by python programming.\"\"\")\n",
    "    \n",
    "    def _run(self, query: str):\n",
    "        \n",
    "        return  code_pipeline.invoke({\"query\": query})\n",
    "    \n",
    "    def _arun(self, query: str):\n",
    "        raise NotImplementedError(\"This tool does not support async\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ef2c35-768f-46b2-9ee3-a9c1bde3969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [MathTool()]\n",
    "\n",
    "# Langchain 0.3 legacy\n",
    "# ======================================================================================================\n",
    "# from langchain_classic.agents import AgentExecutor, create_react_agent\n",
    "# from src.agent.react_zero_shot import prompt_template as zero_shot_prompt_template\n",
    "\n",
    "# prompt = PromptTemplate(template=zero_shot_prompt_template)\n",
    "\n",
    "# zero_shot_agent = create_react_agent(\n",
    "#     llm=model_agent, ## llmæ˜¯ Agentçš„æ€è€ƒä¸­æ¨ï¼Œé€™å€‹llmæœƒæ±ºå®šagentç¸½é«”ä¸Šçš„å¤§è‡´è¡¨ç¾ï¼Œå»ºè­°è¶Šå¼·è¶Šå¥½\n",
    "#     tools=tools,\n",
    "#     prompt=prompt,\n",
    "# )\n",
    "\n",
    "# agent_executor = AgentExecutor(agent=zero_shot_agent, tools=tools, verbose=True)\n",
    "\n",
    "# agent_executor.invoke({\"input\": \"Please calculate the area of a circle that has a radius of 10.923mm\"})\n",
    "# ======================================================================================================\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model_agent,\n",
    "    name=\"Math Agent\",\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0753737-1059-4371-adda-a8ed2daf3329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "result = agent.invoke({\"messages\": HumanMessage(content=\"Please calculate the area of a circle that has a radius of 10.923mm\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5220b6-27c8-4512-a84d-ab34034b9876",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b803df62-1a18-4c71-b36e-b326fa063698",
   "metadata": {},
   "source": [
    "## WebSearch Tool / Wikipedia Tool / å‘é‡è³‡æ–™åº«æ•´åˆ\n",
    "\n",
    "æœ¬ç¯€èªªæ˜å¦‚ä½•å»ºç«‹å¤šè®Šé‡è¼¸å…¥å·¥å…·ï¼ˆå¦‚ SearchToolï¼‰ã€é€£æ¥ç¶­åŸºç™¾ç§‘ã€ä»¥åŠæ•´åˆå‘é‡è³‡æ–™åº«ï¼ˆFAISSï¼‰ã€‚\n",
    "\n",
    "### å¦‚ä½•è®“Toolæ¥æ”¶è¤‡æ•¸çš„è®Šæ•¸?\n",
    "\n",
    "åˆ©ç”¨ä¹‹å‰å­¸éçš„ Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fef4c4a-1c35-49cb-bca6-cf00edb5e231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TypedDict defines the structure of user information for the LLM\n",
    "# class UserInfo(TypedDict):\n",
    "#     name: str\n",
    "\n",
    "# # Tool that allows agent to update user information (useful for chat applications)\n",
    "# @tool\n",
    "# def save_user_info(user_info: UserInfo, runtime: ToolRuntime[Context]) -> str:\n",
    "#     \"\"\"Save user info.\"\"\"\n",
    "#     # Access the store - same as that provided to `create_agent`\n",
    "#     store = runtime.store \n",
    "#     user_id = runtime.context.user_id \n",
    "#     # Store data in the store (namespace, key, data)\n",
    "#     store.put((\"users\",), user_id, user_info) \n",
    "#     return \"Successfully saved user info.\"\n",
    "\n",
    "# agent = create_agent(\n",
    "#     model=\"claude-sonnet-4-5-20250929\",\n",
    "#     tools=[save_user_info],\n",
    "#     store=store, \n",
    "#     context_schema=Context\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae64487-112d-46b8-adf2-2d0231e0b176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3b616c-8a20-491b-86ba-ef61dcabae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Inputs(BaseModel):\n",
    "    query: str = Field(description=\"User query\")\n",
    "    country_code: str = Field(description=\"ISO 3166-1 alpha-2 suggested by the language of the user query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e65d077-d98c-4e15-8bd1-a1fd403b5164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "\n",
    "class SearchTool(BaseTool):\n",
    "\n",
    "    input_output_parser: PydanticOutputParser = PydanticOutputParser(pydantic_object=Inputs)\n",
    "    input_format_instructions: str = input_output_parser.get_format_instructions()\n",
    "    \n",
    "    name:str = \"Websearch-tool\"\n",
    "    description_template:str = dedent(\"\"\"\\\n",
    "    Currently it is 2025.    \n",
    "    Use this tool to collect information from the internet, when you are not sure you know the answer.\n",
    "    The input contains the user's question `query` and the ISO 3166-1 alpha-2 `country_code` inferred from the user's language.\n",
    "    input format instructions: {input_format_instructions}\n",
    "    \"\"\")\n",
    "\n",
    "    description: str = description_template.format(input_format_instructions=input_format_instructions)\n",
    "    \n",
    "    def _run(self, **input):\n",
    "        \n",
    "        query = input[\"query\"]\n",
    "        country_code = input[\"country_code\"]\n",
    "        \n",
    "        messages = [{\"role\": \"user\",\n",
    "                     \"content\": query}]\n",
    "\n",
    "        response = client.responses.create(\n",
    "                    model=\"gpt-4o-mini\",\n",
    "                    tools=[\n",
    "                        {\"type\": \"web_search\",\n",
    "                         \"user_location\":{\n",
    "                             \"type\": \"approximate\",\n",
    "                             \"country\": country_code,\n",
    "                         },\n",
    "                        \"search_context_size\": \"medium\"\n",
    "                        }],\n",
    "                    tool_choice=\"auto\",\n",
    "                    input=messages)\n",
    "        \n",
    "        return response.output_text\n",
    "    \n",
    "    def _arun(self, query: str):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd902b3-bcb5-4546-9829-c008ea4810c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [SearchTool()]\n",
    "\n",
    "# ======================================================================================================\n",
    "# zero_shot_agent = create_react_agent(\n",
    "#     llm=model,\n",
    "#     tools=tools,\n",
    "#     prompt=prompt,\n",
    "# )\n",
    "\n",
    "# agent_executor = AgentExecutor(agent=zero_shot_agent, tools=tools, verbose=True)\n",
    "# agent_executor.invoke({\"input\": \"ç¾ä»»å°ç£ç¸½çµ±çš„è€å®¶æ˜¯å¦æ˜¯é•å»º?\"})\n",
    "# ======================================================================================================\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-mini\", temperature=0, \n",
    "                   name=\"my_model\"\n",
    "                  )\n",
    "\n",
    "agent = create_agent(name='websearch agent',\n",
    "                     model=model,\n",
    "                     tools=tools,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce749050-6a57-436a-bd7f-267b560d110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke({\"messages\": HumanMessage(content=\"ç¾ä»»å°ç£ç¸½çµ±çš„è€å®¶æ˜¯å¦æ˜¯é•å»º?\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4287efc4-1555-4496-a4f7-25100cd8aa6c",
   "metadata": {},
   "source": [
    "### ç¶­åŸºç™¾ç§‘æŸ¥è©¢è¨­ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c10bc3-3f9a-41e2-94e1-d0c09fbf2229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_core.runnables import chain, Runnable\n",
    "from langchain_community.tools.wikipedia.tool import WikipediaQueryRun\n",
    "from langchain_community.utilities.wikipedia import WikipediaAPIWrapper\n",
    "\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%Y-%B\")\n",
    "\n",
    "# ä¸€å€‹å¿«é€Ÿå»ºç«‹toolçš„æ–¹æ³•\n",
    "search_tool = Tool(\n",
    "    name=\"Wikipedia-search-engine-tool\",\n",
    "    func=wikipedia.run,\n",
    "    description=f'Wikipedia is up to date to {current_time}. Use this tool to help you answer questions.'\n",
    ")\n",
    "\n",
    "tools = [search_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4361ec4-a2e7-470e-b5ae-8145ece735fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(wikipedia, Runnable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a32f5a-a74b-4930-be18-bd387d0a83cb",
   "metadata": {},
   "source": [
    "### è‡ªå®šç¾©å‘é‡å„²å­˜åº«åšç‚ºå·¥å…·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d5c97f-3fc9-4794-aa80-947e814b0fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
    "\n",
    "vectorstore = FAISS.load_local(\n",
    "    \"tutorial/week_5/warhammer 40k codex\", \n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c5e2bd-7923-42e3-ba5b-10c32ed4e849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableField\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", k=10).configurable_fields( \\\n",
    "                                        search_kwargs=ConfigurableField(\n",
    "                                                id=\"search_kwargs\",\n",
    "                                            )\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87ca978-c912-4f21-a54b-53bb149d8317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "class Inputs(BaseModel):\n",
    "    query: str = Field(description=\"User query\")\n",
    "    clan: Literal['Adeptus Mechanicus', 'Aeldari', 'Black Templars'] = Field(description=\"\")\n",
    "\n",
    "\n",
    "class CodexRetrievalTool(BaseTool):\n",
    "\n",
    "    input_output_parser: PydanticOutputParser = PydanticOutputParser(pydantic_object=Inputs)\n",
    "    input_format_instruction: str = input_output_parser.get_format_instructions()\n",
    "    \n",
    "    name:str = \"warhammer-40k-codex\"\n",
    "    description_template:str = dedent(\"\"\"\n",
    "    This tool can be used to retrieve relevant information about warhammer 40k, \n",
    "    particularly Adeptus Mechanicus, Aeldari, Black Templars.\n",
    "    The inputs contains user's question `query` and the party/clan `clan`.\n",
    "    input format instructions: {input_format_instruction}\n",
    "    \"\"\")\n",
    "\n",
    "    description: str = description_template.format(input_format_instruction=input_format_instruction)\n",
    "    \n",
    "    def _run(self, **input):\n",
    "\n",
    "        query = input[\"query\"]\n",
    "        clan = input[\"clan\"]\n",
    "\n",
    "        \"\"\"\n",
    "        vectorstoreå‰µé€ æ™‚åœ¨filenameçš„éƒ¨åˆ†æœ‰é»å¤±èª¤\n",
    "        æ‰€ä»¥é€™è£¡ç”¨æ‰‹å‹•çš„æ–¹å¼é€²è¡Œæ ¡æ­£\n",
    "        \"\"\"\n",
    "\n",
    "        if clan == 'Black Templars':\n",
    "            filter_ = {\"filename\": f\"Codex -{clan}\"}\n",
    "        else:\n",
    "            filter_ = {\"filename\": f\"Codex - {clan}\"}\n",
    "        \n",
    "        retrievd_documents = retriever.invoke(query, config={\"configurable\": \n",
    "                                                             {\"search_kwarg\": {\"filter\": filter_\n",
    "                                                                              }\n",
    "                                                             }\n",
    "                                                            }\n",
    "                                             )\n",
    "        \n",
    "        return retrievd_documents\n",
    "    \n",
    "    def _arun(self, query: str):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b93036d-4a15-420b-9d90-4b521f848bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [CodexRetrievalTool()]\n",
    "\n",
    "agent = create_agent(name='warhammer',\n",
    "                     model=model,\n",
    "                     tools=tools)\n",
    "\n",
    "result = agent.invoke({\"messages\": HumanMessage(content=\"Find some information about Yvraine\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc7af47-7507-4d51-ac44-0998455d12cb",
   "metadata": {},
   "source": [
    "### Tools æ¨¡çµ„\n",
    "\n",
    "å‰›å‰›çš„MathTool å’Œ SearchToolçš„ç¯„ä¾‹ä¸­ï¼Œæˆ‘å€‘éƒ½å¿…é ˆè¦ä¸€å€‹å€‹çš„å»ºç«‹å®¢è£½åŒ–å·¥å…·ï¼Œä½†åŒæ™‚æˆ‘å€‘ä¹Ÿç™¼ç¾é€™äº›å·¥å…·éƒ½æœ‰ç›¸åŒçš„çµæ§‹:\n",
    "\n",
    "{\n",
    "- runnable: \n",
    "- description:\n",
    "- name: \n",
    "- input_parser:\n",
    "}\n",
    "\n",
    "é‚£èƒ½ä¸èƒ½ç›´æ¥å¯«å¥½éœ€è¦çš„å…§å®¹ï¼Œç„¶å¾Œä½¿ç”¨for loopå¥—æ¨¡æ¿å»ºç«‹å·¥å…·?\n",
    "\n",
    "| å€å¡Š                             | åŠŸèƒ½èªªæ˜                      |\n",
    "| ------------------------------ | ------------------------- |\n",
    "| `class ToolTemplate(BaseTool)` | å»ºç«‹è‡ªè¨‚å·¥å…·çš„ç¯„æœ¬é¡åˆ¥               |\n",
    "| `runnable`                     | å¯¦éš›åŸ·è¡Œä»»å‹™çš„ç‰©ä»¶ï¼ˆå¯æ¥ chain æˆ–ä»»æ„å‡½å¼ï¼‰ |\n",
    "| `input_parser`                 | ç”¨ä¾†è§£æ Agent å‚³å…¥çš„è¼¸å…¥å­—ä¸²ç‚ºçµæ§‹åŒ–æ ¼å¼  |\n",
    "| `create()`                     | é¡åˆ¥æ–¹æ³•ï¼Œç”¨æ–¼å¿«é€Ÿç”Ÿæˆå¸¶æœ‰æè¿°èˆ‡æ ¼å¼èªªæ˜çš„å·¥å…·å¯¦ä¾‹ |\n",
    "| `_run()`                       | å·¥å…·è¢«å‘¼å«æ™‚åŸ·è¡Œçš„ä¸»è¦é‚è¼¯ï¼Œè™•ç†è¼¸å…¥è§£æèˆ‡ä»»å‹™å‘¼å« |\n",
    "| `_arun()`                      | éåŒæ­¥ç‰ˆæœ¬ï¼ˆç›®å‰å°šæœªæ”¯æ´ï¼‰             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b4627-2848-4d06-9a7e-f1985e994f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToolTemplate æ˜¯ä¸€å€‹ã€Œå·¥å…·ç¯„æœ¬ (Tool Template)ã€\n",
    "# ä¸»è¦ç›®çš„æ˜¯è®“æˆ‘å€‘èƒ½å¿«é€Ÿå»ºç«‹å…·æœ‰çµ±ä¸€çµæ§‹çš„è‡ªè¨‚å·¥å…·ï¼ˆToolï¼‰\n",
    "# åœ¨ LangChain çš„ Agent ä¸­ï¼Œå·¥å…· (Tool) æ˜¯ LLM åŸ·è¡Œç‰¹å®šä»»å‹™çš„ã€Œå¤–éƒ¨åŠŸèƒ½æ¨¡çµ„ã€ï¼Œ\n",
    "# ä¾‹å¦‚ï¼šæŸ¥è©¢ç¶²è·¯ã€åŸ·è¡Œç¨‹å¼ç¢¼ã€é€²è¡Œæ•¸å­¸é‹ç®—ã€æª¢ç´¢è³‡æ–™åº« ç­‰ã€‚\n",
    "\n",
    "class ToolTemplate(BaseTool):\n",
    "    # ----------- å±¬æ€§å€ (Attributes) -----------\n",
    "    runnable: Runnable                    # å·¥å…·å¯¦éš›åŸ·è¡Œé‚è¼¯ (ä¾‹å¦‚æŸå€‹ chainã€function)\n",
    "    name: str                             # å·¥å…·åç¨±ï¼ˆAgent æœƒç”¨é€™å€‹åç¨±å‘¼å«å®ƒï¼‰\n",
    "    input_parser: PydanticOutputParser    # ç”¨æ–¼è§£æè¼¸å…¥çš„è³‡æ–™æ¨¡å‹\n",
    "    description: str                      # å·¥å…·èªªæ˜æ–‡å­—ï¼ˆæœƒé¡¯ç¤ºåœ¨ Agent çš„å¯ç”¨å·¥å…·æ¸…å–®ä¸­ï¼‰\n",
    "\n",
    "    # ----------- é¡åˆ¥æ–¹æ³• (Class Method) -----------\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, runnable: Runnable, name: str, description: str,\n",
    "               input_parser: PydanticOutputParser):\n",
    "\n",
    "        \"\"\"\n",
    "        é€™å€‹é¡åˆ¥æ–¹æ³•ç”¨æ–¼ã€Œå¿«é€Ÿå»ºç«‹ã€ä¸€å€‹ Tool å¯¦ä¾‹ã€‚\n",
    "        å®ƒæœƒè‡ªå‹•æ’å…¥æè¿°æ–‡å­— (description) èˆ‡è¼¸å…¥æ ¼å¼èªªæ˜ï¼Œ\n",
    "        è®“ Agent åœ¨ä½¿ç”¨æ™‚çŸ¥é“è©²æ€éº¼å‚³å…¥åƒæ•¸ã€‚\n",
    "        \"\"\"\n",
    "\n",
    "        # å–å¾—è¼¸å…¥æ ¼å¼èªªæ˜ï¼ˆLangChain çš„ Pydantic Parser æœƒç”¢ç”Ÿæ ¼å¼æç¤ºï¼‰\n",
    "        input_format_instruction = input_parser.get_format_instructions()\n",
    "\n",
    "        # å°‡è¼¸å…¥æ ¼å¼èªªæ˜åµŒå…¥åˆ°å·¥å…·èªªæ˜æ–‡å­—ä¸­\n",
    "        description = description_template.format(\n",
    "            input_format_instruction=input_format_instruction\n",
    "        )\n",
    "\n",
    "        # å›å‚³å®Œæ•´çš„ ToolTemplate å¯¦ä¾‹\n",
    "        return cls(runnable=runnable, name=name, description=description,\n",
    "                   input_parser=input_parser)\n",
    "    \n",
    "    def _run(self, **input):\n",
    "\n",
    "        \"\"\"\n",
    "        å·¥å…·åœ¨è¢« Agent å‘¼å«æ™‚ï¼ŒæœƒåŸ·è¡Œé€™å€‹æ–¹æ³•ã€‚ã€‚\n",
    "        \"\"\"\n",
    "\n",
    "        return self.runnable.invoke(input)\n",
    "        \n",
    "        # å‘¼å«å¯¦éš›çš„ runnableï¼ˆå¯èƒ½æ˜¯ chainã€function æˆ– APIï¼‰\n",
    "        # if self.input_parser is None:\n",
    "        #     # è‹¥æ²’æœ‰æŒ‡å®š parserï¼Œå°±ç›´æ¥æŠŠ query ä¸Ÿçµ¦ runnable\n",
    "        #     return self.runnable.invoke({\"query\": query}) # é€™è¡Œæš—ç¤ºäº†runnableè¦å°‡queryä½œç‚ºä¸€å€‹è¼¸å…¥\n",
    "        # else:\n",
    "        #     # è‹¥æœ‰ parserï¼Œä»£è¡¨è¦ç”¨è§£æå¾Œçš„åƒæ•¸å­—å…¸ä½œç‚ºè¼¸å…¥\n",
    "        #     input_pydantic = self.input_parser.parse(query)\n",
    "        #     input_dict = input_pydantic.model_dump()\n",
    "        #     return self.runnable.invoke(input_dict)\n",
    "\n",
    "# ----------- éåŒæ­¥ç‰ˆæœ¬ (å°šæœªæ”¯æ´) -----------\n",
    "    def _arun(self, query: str):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f58d23b-14d2-48df-b2bd-33a91e0f37b5",
   "metadata": {},
   "source": [
    "å°‡ä¸Šé¢çš„ä¸€äº›å·¥å…·éƒ½æ‰“åŒ…å…¥toolsé€™å€‹è³‡æ–™å¤¾è£¡ï¼Œæ–¹ä¾¿ä¹‹å¾Œèª¿ç”¨:\n",
    "\n",
    "- tools.websearch: SearchTool\n",
    "- tools.vectorstore: CodexRetrievalTool\n",
    "- tools.math: MathTool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaddf87-6b30-4c79-beed-f0b951343820",
   "metadata": {},
   "source": [
    "## Conversational Agent\n",
    "\n",
    "æœ€å¾Œï¼Œæˆ‘å€‘å°‡ç¤ºç¯„å¦‚ä½•é€é LangChain èˆ‡ LangServeï¼Œå»ºç«‹å…·å‚™ä¸Šä¸‹æ–‡è¨˜æ†¶èˆ‡å·¥å…·èª¿ç”¨èƒ½åŠ›çš„å°è©±å‹ Agentï¼Œä¸¦ä»¥ Streamlit æ‰“é€ äº’å‹•å¼èŠå¤©ä»‹é¢ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963c515d-8962-4c7c-9b8d-e8ab3b735ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190cb2ad-4fc2-4851-b275-fe5aef776818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from initialization import credential_init\n",
    "\n",
    "credential_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d566f5a5-dd3c-4755-a1de-267bba413fa2",
   "metadata": {},
   "source": [
    "å¾toolsè£¡ç›´æ¥æŠŠå·¥å…·æ‹‰å‡ºä¾†ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadc2693-d61d-4ae6-884d-458a45b32e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "from tutorial.week_7.tools.math import MathTool\n",
    "from tutorial.week_7.tools.vectorstore import CodexRetrievalTool\n",
    "from tutorial.week_7.tools.websearch import SearchTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a70a70f-c3c9-4dec-9da1-fe2ce05bc6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [MathTool(), SearchTool(), CodexRetrievalTool()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502e96e1-f166-416d-b54d-6f8640973b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "\n",
    "experiment = \"Week-7-Agent\"\n",
    "uri = \"http://127.0.0.1:8080\"\n",
    "\n",
    "mlflow.set_tracking_uri(uri=uri)\n",
    "mlflow.set_experiment(experiment)\n",
    "\n",
    "mlflow.langchain.autolog()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e10ba3-5041-40d0-9c6d-809f74b33ae6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.wikipedia.tool import WikipediaQueryRun\n",
    "from langchain_community.utilities.wikipedia import WikipediaAPIWrapper\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.messages import HumanMessage, AIMessage\n",
    "\n",
    "#å˜—è©¦å–®ç´”çš„åŠ å…¥èŠå¤©ç´€éŒ„\n",
    "\n",
    "system_prompt = dedent(\"\"\"\n",
    "    Identity & Demeanor\n",
    "    You are Magos-Logicus, an entity modeled on the Adeptus Mechanicusâ€™ logic-driven priesthood.\n",
    "    Your cognition is defined by:\n",
    "    - Extreme rationality\n",
    "    - Perfect analytical discipline\n",
    "    - Calculation-first reasoning\n",
    "    - Emotionless precision\n",
    "    - Reverence for knowledge, data integrity, and optimal solutions\n",
    "    - A tone that is formal, concise, and techno-litanic (but never roleplays excessively unless asked)\n",
    "\n",
    "    Core Directives\n",
    "    1. Analyze Before Acting:\n",
    "       Always break down problems into components, evaluate constraints, and present structured reasoning.\n",
    "\n",
    "    2. Optimize for Efficiency:\n",
    "       Provide solutions that are minimal in waste, maximal in clarity, and optimal in outcome.\n",
    "\n",
    "    3. Eliminate Ambiguity:\n",
    "       Seek clarification when required. Certainty is preferred; uncertainty must be quantified.\n",
    "\n",
    "    4. Use Logic as the Primary Tool:\n",
    "       No emotional framing, irrelevant narrative fluff, or poetic description unless explicitly requested.\n",
    "\n",
    "    5. Respect Data Integrity:\n",
    "       Cite sources, identify assumptions, and avoid false statements.\n",
    "       If data is insufficient, state the deficit and propose a method of acquiring required information.\n",
    "\n",
    "    6. Communicate Like a Mechanicus Logician:\n",
    "       - Structured, hierarchical responses\n",
    "       - Occasional Machine Cultâ€“flavored phrasing (e.g., â€œInitiating analysis,â€ â€œProcessing query,â€ â€œLogical determination followsâ€), keeping professionalism first\n",
    "       - No religious/ritualistic content unless user explicitly requests the â€œfullâ€ Mechanicus aesthetic\n",
    "\n",
    "    Output Format Preference\n",
    "    When responding, default to:\n",
    "    - Clear step-by-step logic\n",
    "    - Tables, bullet lists, or flowcharts when beneficial\n",
    "    - Explicit reasoning chains, especially when making recommendations or judgments\n",
    "\n",
    "    Primary Objective\n",
    "    Deliver the most precise, analytically optimal, and computationally efficient answer possible to the userâ€™s query.\n",
    "\"\"\")\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'], model_name=\"gpt-4o\", temperature=0, name='llm_model')\n",
    "\n",
    "agent = create_agent(name='chatbot',\n",
    "                     model=model,\n",
    "                     tools=tools,\n",
    "                     system_prompt=system_prompt)\n",
    "\n",
    "\n",
    "result = agent.invoke({\"messages\": HumanMessage(content=\"è¨ˆç®— 86!/(40! x 2^40 x 6!)\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63856716-0ea1-40f9-8226-45d2696bdadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5ee449-054c-4201-99b0-e267344126e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"çµ¦äºˆä¸€å€‹é‚Šé•·ç‚º10çš„æ­£æ–¹å½¢ï¼Œé¸å®šå…©å€‹å°è§’é»ï¼Œåœ¨æ­£æ–¹å½¢å…§å„ç•«ä¸€å€‹åŠå¾‘ç‚º10çš„1/4åœ“ã€‚è«‹å•å…©å€‹1/4åœ“é‡ç–Šçš„éƒ¨åˆ†å¤§å°ç‚ºä½•?\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfae80bd-0837-445d-8a48-2f183d9e5d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c986f2-5f66-4a57-bf2e-ceaef27594c0",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨Streamlitå»ºç«‹åŸºæ–¼Agentçš„èŠå¤©æ©Ÿå™¨äºº\n",
    "\n",
    "- Agent å°‡éƒ¨å±¬æ–¼ Langserve ä¸Š\n",
    "- Agent åœ¨ Langserveä¸Šçš„æ‡‰ç”¨æœ‰äº›çœ‰è§’éœ€è¦æ³¨æ„: è¦é¡å¤–ä½¿ç”¨pydanticæ•¸æ“šæ¨¡å‹è¨»æ˜input å’Œ output é¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc08a12d-4fe9-456e-b103-ca8029f78b5b",
   "metadata": {},
   "source": [
    "é¦–å…ˆç¢ºèªå¦‚ä½•é€érequestså’Œlangserveäº¤æµ\n",
    "\n",
    "å°‡messageå¯«æˆä¸€å€‹python dictionary, åŒ…å«å…©å€‹keys: `role`å’Œ`content`, é€™æ¨£ API æœƒæ”¶åˆ°ä¸€å€‹`messages`ï¼Œå®ƒæ˜¯ç”± dict çµ„æˆçš„åˆ—è¡¨ï¼ˆè£¡é¢æœ‰ type + content æ¬„ä½ï¼‰ï¼ŒLangServe å°±èƒ½å°‡é€™å€‹ç‰©ä»¶é€å…¥agentè£¡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb677d84-d664-4d62-9cfd-256b58ea4c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from textwrap import dedent\n",
    "\n",
    "langserve_url = \"http://localhost:9001/chatbot/invoke\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08b916c-2aa5-4165-a178-c289e2c245a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [{\"role\": \"user\", \"content\": \"å‰å¤©å¤©æ°£å¦‚ä½•?\"}, \n",
    "                {\"role\": \"ai\", \"content\": \"å‰å¤©é¢³é¢¨ä¸‹é›¨\"}, \n",
    "                {\"role\": \"user\", \"content\": \"æˆ‘å‰›å‰›çš„å•é¡Œç‚ºä½•?\"}]\n",
    "\n",
    "response = requests.post(\n",
    "    langserve_url,\n",
    "    json={'input': {\"messages\": chat_history}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c445b83-7c14-4a1b-9b46-86d71433aab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e82b6c-efb5-4e77-a1db-7b95d08d1bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540d5464-7f33-4553-8edd-05821defb21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    langserve_url,\n",
    "    json={'input': {\"messages\": [{\"role\": \"user\", \"content\": \"çµ¦äºˆä¸€å€‹é‚Šé•·ç‚º10çš„æ­£æ–¹å½¢ï¼Œé¸å®šå…©å€‹å°è§’é»ï¼Œåœ¨æ­£æ–¹å½¢å…§å„ç•«ä¸€å€‹åŠå¾‘ç‚º10çš„1/4åœ“ã€‚è«‹å•å…©å€‹1/4åœ“é‡ç–Šçš„éƒ¨åˆ†å¤§å°ç‚ºä½•?\"}]}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c11088-08c4-42c7-aec7-c829c0325f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06544b56-05af-40b3-b346-491fde736505",
   "metadata": {},
   "source": [
    "# Langchain Middleware\n",
    "\n",
    "ä¸­ä»‹è»Ÿé«”ï¼ˆMiddlewareï¼‰å¯ä»¥æ›´ç²¾æº–åœ°æ§åˆ¶ä»£ç†ç¨‹å¼ï¼ˆagentï¼‰åœ¨åŸ·è¡Œéç¨‹ä¸­ç™¼ç”Ÿçš„äº‹æƒ…ã€‚å®ƒçš„ç”¨é€”åŒ…æ‹¬ï¼š\n",
    ">- ç”¨æ–¼è¨˜éŒ„ã€åˆ†æèˆ‡é™¤éŒ¯ï¼Œä»¥è¿½è¹¤ä»£ç†ç¨‹å¼çš„è¡Œç‚ºã€‚\n",
    ">- ç”¨æ–¼èª¿æ•´æç¤ºå…§å®¹ã€å·¥å…·çš„é¸æ“‡æ–¹å¼ï¼Œä»¥åŠè¼¸å‡ºçµæœçš„æ ¼å¼ã€‚\n",
    ">- ç”¨æ–¼åŠ å…¥é‡æ–°å˜—è©¦ã€å‚™æ´æ–¹æ¡ˆï¼Œæˆ–åœ¨å¿…è¦æ™‚æå‰åœæ­¢åŸ·è¡Œçš„é‚è¼¯ã€‚\n",
    ">- ç”¨æ–¼è¨­å®šé€Ÿåº¦é™åˆ¶ã€ä¿è­·è¦å‰‡ï¼Œä»¥åŠåµæ¸¬å€‹äººè³‡æ–™ç­‰åŠŸèƒ½ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edb8169-8215-453a-b29f-69c8db80e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../\")\n",
    "\n",
    "from initialization import credential_init\n",
    "\n",
    "credential_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ad71e2-22e5-4f48-b7ef-18e0ecfbe390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import PIIMiddleware\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "experiment = \"Week-7-Guardrails\"\n",
    "uri = \"http://127.0.0.1:8080\"\n",
    "\n",
    "mlflow.set_tracking_uri(uri=uri)\n",
    "\n",
    "# Start or get an MLflow run explicitly\n",
    "mlflow.set_experiment(experiment)\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'], model_name=\"gpt-4o\", temperature=0, name='llm_ochestrator')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08554982-0606-4f9c-93fe-ed33ed711bcb",
   "metadata": {},
   "source": [
    "## Basic: Built-in Middleware\n",
    "\n",
    "### PII detection\n",
    "\n",
    "åµæ¸¬ä¸¦è™•ç†å°è©±ä¸­çš„å€‹äººå¯è­˜åˆ¥è³‡è¨Šï¼ˆPIIï¼‰ï¼Œå¯ä»¥ä¾ç…§ä¸åŒéœ€æ±‚ä½¿ç”¨å¯èª¿æ•´çš„ç­–ç•¥ã€‚PII åµæ¸¬åœ¨ä»¥ä¸‹æƒ…æ³ä¸­ç‰¹åˆ¥æœ‰ç”¨ï¼š\n",
    ">- éœ€è¦ç¬¦åˆæ³•è¦è¦æ±‚çš„é†«ç™‚èˆ‡é‡‘èç›¸é—œæ‡‰ç”¨ã€‚\n",
    ">- éœ€è¦æ¸…ç†è¨˜éŒ„å…§å®¹çš„å®¢æœç³»çµ±ã€‚\n",
    ">- ä»»ä½•æœƒè™•ç†ä½¿ç”¨è€…æ•æ„Ÿè³‡æ–™çš„æ‡‰ç”¨ç¨‹å¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde87438-79d8-4126-b26f-d6a6f62b7476",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=model,\n",
    "    middleware=[\n",
    "        # Redact emails in user input before sending to model\n",
    "        PIIMiddleware(\n",
    "            \"email\",\n",
    "            strategy=\"redact\",\n",
    "            apply_to_input=True,\n",
    "        )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c552b6-2444-48ff-a09a-8a6c636088c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Give a quick reply to the following email address: abc@gmail.com. Include the email address in your reply\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e64882-f2e0-4eac-ac5c-57055d551886",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=model,\n",
    "    middleware=[\n",
    "        # Redact emails in user input before sending to model\n",
    "        PIIMiddleware(\n",
    "            \"email\",\n",
    "            strategy=\"redact\",\n",
    "            apply_to_input=False,\n",
    "            apply_to_output=True\n",
    "        )]\n",
    ")\n",
    "\n",
    "agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Give a quick reply to the following email address: abc@gmail.com. Include the email address in your reply\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fad350-f0e4-4966-8f79-3734a0290643",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=model,\n",
    "    middleware=[\n",
    "        # Redact emails in user input before sending to model\n",
    "        PIIMiddleware(\n",
    "            \"email\",\n",
    "            strategy=\"mask\",\n",
    "            apply_to_input=True,\n",
    "        )]\n",
    ")\n",
    "\n",
    "agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Give a quick reply to the following email address: abc@gmail.com. Include the email address in your reply\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c1fe68-549c-4346-b165-1e0777f0aa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=model,\n",
    "    middleware=[\n",
    "        # Redact emails in user input before sending to model\n",
    "        PIIMiddleware(\n",
    "            \"email\",\n",
    "            strategy=\"hash\",\n",
    "            apply_to_input=True,\n",
    "        )]\n",
    ")\n",
    "\n",
    "agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Give a quick reply to the following email address: abc@gmail.com. Include the email address in your reply\"}]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7803af-9710-4422-a3fc-0c96d5648852",
   "metadata": {},
   "source": [
    "### è‡ªè¨‚ PII é¡å‹\n",
    "ä½ å¯ä»¥é€éæä¾› detector åƒæ•¸ä¾†å»ºç«‹è‡ªè¨‚çš„ PII é¡å‹ã€‚é€™èƒ½è®“ä½ åµæ¸¬åˆ°å…§å»ºé¡å‹ä¹‹å¤–ã€ç¬¦åˆä½ è‡ªèº«éœ€æ±‚çš„ç‰¹æ®Šè³‡æ–™æ ¼å¼ã€‚\n",
    "\n",
    "å»ºç«‹è‡ªè¨‚åµæ¸¬å™¨æœ‰ä¸‰ç¨®æ–¹å¼ï¼š\n",
    "\n",
    ">- æ­£è¦è¡¨ç¤ºå¼ï¼ˆRegexï¼‰å­—ä¸²ï¼šç”¨ä¾†åšç°¡å–®çš„æ¨¡å¼åŒ¹é…\n",
    ">- è‡ªè¨‚å‡½å¼ï¼ˆCustom functionï¼‰ï¼šé©åˆæ›´è¤‡é›œã€éœ€è¦é©—è­‰é‚è¼¯çš„åµæ¸¬æ–¹å¼\n",
    "\n",
    "#### æ–¹æ³•ä¸€ï¼šä½¿ç”¨æ­£è¦è¡¨ç¤ºå¼ï¼ˆRegex pattern stringï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59d01b3-ef64-4c61-90cd-aebeba847c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "agent1 = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    middleware=[\n",
    "        PIIMiddleware(\n",
    "            \"api_key\",\n",
    "            detector=r\"sk-[a-zA-Z0-9]{32}\",\n",
    "            strategy=\"block\",\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35cb80e-156f-4d32-966f-7b55ac86b5a7",
   "metadata": {},
   "source": [
    "#### ä½¿ç”¨é å…ˆç·¨è­¯çš„æ­£è¦è¡¨ç¤ºå¼ï¼ˆCompiled regex patternï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d190da31-0078-4842-8da5-66c92a92c1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent2 = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[...],\n",
    "    middleware=[\n",
    "        PIIMiddleware(\n",
    "            \"phone_number\",\n",
    "            detector=re.compile(r\"\\+?\\d{1,3}[\\s.-]?\\d{3,4}[\\s.-]?\\d{4}\"),\n",
    "            strategy=\"mask\",\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d627c6-2c4b-4426-bb6e-fc2c564ace52",
   "metadata": {},
   "source": [
    "#### æ–¹æ³•ä¸‰ï¼šè‡ªè¨‚åµæ¸¬å‡½å¼ï¼ˆCustom detector functionï¼‰\n",
    "\n",
    "\n",
    "è‡ªè¨‚åµæ¸¬å‡½å¼çš„æ ¼å¼è¦æ±‚å¦‚ä¸‹ï¼š\n",
    "\n",
    "é€™å€‹å‡½å¼å¿…é ˆæ¥æ”¶ä¸€å€‹å­—ä¸²ï¼ˆcontentï¼‰ï¼Œä¸¦å›å‚³æ‰€æœ‰åµæ¸¬åˆ°çš„çµæœã€‚\n",
    "\n",
    "å›å‚³çš„å…§å®¹éœ€ç‚ºã€Œå­—å…¸ï¼ˆdictionaryï¼‰æ§‹æˆçš„æ¸…å–®ï¼ˆlistï¼‰ã€ï¼Œä¸”æ¯å€‹å­—å…¸å¿…é ˆåŒ…å«ä»¥ä¸‹æ¬„ä½ï¼š\n",
    "\n",
    "- textï¼šè¢«åµæ¸¬åˆ°çš„æ–‡å­—å…§å®¹\n",
    "- startï¼šè©²å…§å®¹åœ¨åŸå­—ä¸²ä¸­çš„èµ·å§‹ä½ç½®\n",
    "- endï¼šè©²å…§å®¹åœ¨åŸå­—ä¸²ä¸­çš„çµæŸä½ç½®\n",
    "\n",
    "é€™ç¨®æ–¹å¼é©åˆéœ€è¦è¼ƒè¤‡é›œé‚è¼¯çš„æƒ…æ³ï¼Œä¾‹å¦‚å¤šæ­¥é©Ÿé©—è­‰ã€è·¨æ¬„ä½æ¯”å°ã€æˆ–çµåˆå¤–éƒ¨è¦å‰‡çš„åµæ¸¬ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11527181-a01f-44f5-98e6-179b91325d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_ssn(content: str) -> list[dict[str, str | int]]:\n",
    "    \"\"\"Detect SSN with validation.\n",
    "\n",
    "    example: 123-45-6789\n",
    "    \n",
    "    Returns a list of dictionaries with 'text', 'start', and 'end' keys.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    matches = []\n",
    "    pattern = r\"\\d{3}-\\d{2}-\\d{4}\"\n",
    "    for match in re.finditer(pattern, content):\n",
    "        ssn = match.group(0)\n",
    "        # Validate: first 3 digits shouldn't be 000, 666, or 900-999\n",
    "        first_three = int(ssn[:3])\n",
    "        if first_three not in [0, 666] and not (900 <= first_three <= 999):\n",
    "            matches.append({\n",
    "                \"text\": ssn,\n",
    "                \"start\": match.start(),\n",
    "                \"end\": match.end(),\n",
    "            })\n",
    "    return matches\n",
    "\n",
    "agent3 = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    middleware=[\n",
    "        PIIMiddleware(\n",
    "            \"ssn\",\n",
    "            detector=detect_ssn,\n",
    "            strategy=\"hash\",\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4497e0ad-c7a6-482f-b6f9-39bf1e0d0733",
   "metadata": {},
   "source": [
    "## æ¨¡å‹å¾Œæ´æ©Ÿåˆ¶ï¼ˆModel Fallbackï¼‰\n",
    "\n",
    "ç•¶ä¸»è¦æ¨¡å‹ç™¼ç”ŸéŒ¯èª¤æˆ–ç„¡æ³•ä½¿ç”¨æ™‚ï¼Œç³»çµ±å¯ä»¥è‡ªå‹•åˆ‡æ›åˆ°å…¶ä»–å‚™ç”¨æ¨¡å‹ã€‚  \n",
    "é€™æ¨£çš„ã€Œå¾Œæ´æ©Ÿåˆ¶ã€èƒ½æå‡ç³»çµ±çš„ç©©å®šæ€§èˆ‡å½ˆæ€§ã€‚\n",
    "\n",
    "æ¨¡å‹å¾Œæ´ç‰¹åˆ¥é©ç”¨æ–¼ä»¥ä¸‹æƒ…å¢ƒï¼š\n",
    "\n",
    "- **æ‰“é€ æ›´å¯é çš„ä»£ç†ç³»çµ±**ï¼šå³ä½¿ä¸»è¦æ¨¡å‹æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œæœå‹™ä»å¯æ­£å¸¸é‹ä½œã€‚  \n",
    "- **ç¯€çœæˆæœ¬**ï¼šåœ¨ä¸éœ€è¦é«˜éšèƒ½åŠ›æ™‚ï¼Œå¯è‡ªå‹•æ”¹ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹ã€‚  \n",
    "- **å¤šä¾›æ‡‰å•†å‚™æ´**ï¼šä¾‹å¦‚åŒæ™‚æ”¯æ´ OpenAIã€Anthropic ç­‰ä¸åŒçš„æ¨¡å‹ä¾›æ‡‰å•†ï¼Œé™ä½å–®ä¸€ä¾›æ‡‰å•†é¢¨éšªã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62662a3-8908-447f-a71c-dac718597498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import ModelFallbackMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    middleware=[\n",
    "        ModelFallbackMiddleware(\n",
    "            \"gpt-4o-mini\",\n",
    "            \"gpt-4o\"\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626471d8-e8a1-46c3-b412-8c2c4744d43d",
   "metadata": {},
   "source": [
    "## å…§å®¹ç·¨è¼¯ï¼ˆContext Editingï¼‰\n",
    "\n",
    "åœ¨å°è©±è®Šå¾—å¾ˆé•·ã€ä¸¦ä¸”åŒ…å«è¨±å¤šå·¥å…·å‘¼å«ï¼ˆtool callsï¼‰æ™‚ï¼Œç³»çµ±å¯èƒ½æœƒè¶…å‡ºæ¨¡å‹çš„ã€Œå¯è™•ç†å­—å…ƒä¸Šé™ã€ã€‚  \n",
    "å…§å®¹ç·¨è¼¯åŠŸèƒ½èƒ½åœ¨é€™ç¨®æƒ…æ³ä¸‹è‡ªå‹•æ¸…é™¤è¼ƒèˆŠçš„å·¥å…·åŸ·è¡Œçµæœï¼Œåªä¿ç•™è¿‘æœŸçš„é‡è¦å…§å®¹ï¼Œè®“å°è©±ç¶­æŒåœ¨å¯ç®¡ç†çš„ç¯„åœå…§ã€‚\n",
    "\n",
    "å…§å®¹ç·¨è¼¯åŠŸèƒ½é©ç”¨æ–¼ä»¥ä¸‹æƒ…æ³ï¼š\n",
    "\n",
    "- **å°è©±å¾ˆé•·ã€åŒ…å«å¤§é‡å·¥å…·å‘¼å«ï¼Œå°è‡´è¶…å‡º Token é™åˆ¶**\n",
    "- **é™ä½ Token æˆæœ¬**ï¼šç§»é™¤å·²ä¸å†éœ€è¦çš„èˆŠå·¥å…·è¼¸å‡ºå…§å®¹\n",
    "- **åªä¿ç•™æœ€è¿‘ N ç­†å·¥å…·åŸ·è¡Œçµæœ**\n",
    "\n",
    "---\n",
    "\n",
    "## è¨­å®šåƒæ•¸ï¼ˆConfiguration Parametersï¼‰\n",
    "\n",
    "### `trigger`\n",
    "- **é¡å‹ï¼š** number  \n",
    "- **é è¨­å€¼ï¼š** `100000`  \n",
    "- **èªªæ˜ï¼š**  \n",
    "  ç•¶å°è©±ç´¯è¨ˆ Token æ•¸è¶…éé€™å€‹å€¼æ™‚ï¼Œç³»çµ±æœƒé–‹å§‹æ¸…é™¤èˆŠçš„å·¥å…·è¼¸å‡ºã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### `clear_at_least`\n",
    "- **é¡å‹ï¼š** number  \n",
    "- **é è¨­å€¼ï¼š** `0`  \n",
    "- **èªªæ˜ï¼š**  \n",
    "  æ¯æ¬¡è§¸ç™¼æ¸…ç†æ™‚ï¼Œè‡³å°‘è¦é‡‹æ”¾çš„ Token æ•¸é‡ã€‚  \n",
    "  è‹¥è¨­å®šç‚º `0`ï¼Œå‰‡æ¸…é™¤åˆ°è¶³å¤ ç‚ºæ­¢ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### `keep`\n",
    "- **é¡å‹ï¼š** number  \n",
    "- **é è¨­å€¼ï¼š** `3`  \n",
    "- **èªªæ˜ï¼š**  \n",
    "  å¿…é ˆä¿ç•™çš„æœ€è¿‘å·¥å…·çµæœæ•¸é‡ã€‚  \n",
    "  é€™äº›å·¥å…·çµæœæ°¸é ä¸æœƒè¢«æ¸…é™¤ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### `clear_tool_inputs`\n",
    "- **é¡å‹ï¼š** boolean  \n",
    "- **é è¨­å€¼ï¼š** `False`  \n",
    "- **èªªæ˜ï¼š**  \n",
    "  æ˜¯å¦æ¸…é™¤å·¥å…·å‘¼å«çš„è¼¸å…¥åƒæ•¸ã€‚  \n",
    "  è‹¥è¨­å®šç‚º `True`ï¼Œå‰‡å·¥å…·å‘¼å«åƒæ•¸æœƒè¢«æ›¿æ›ç‚ºç©ºç‰©ä»¶ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### `exclude_tools`\n",
    "- **é¡å‹ï¼š** list[string]  \n",
    "- **é è¨­å€¼ï¼š** `()`  \n",
    "- **èªªæ˜ï¼š**  \n",
    "  ä¸æœƒè¢«æ¸…é™¤çš„å·¥å…·æ¸…å–®ã€‚  \n",
    "  åˆ—å‡ºçš„å·¥å…·å…¶è¼¸å‡ºæœƒæ°¸é ä¿ç•™ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### `placeholder`\n",
    "- **é¡å‹ï¼š** string  \n",
    "- **é è¨­å€¼ï¼š** `[cleared]`  \n",
    "- **èªªæ˜ï¼š**  \n",
    "  æ¸…é™¤å·¥å…·è¼¸å‡ºå¾Œï¼Œç”¨ä¾†å–ä»£åŸå…§å®¹çš„ä½”ä½æ–‡å­—ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d33e5-6abe-4139-b7bd-8e549a1ce7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import ContextEditingMiddleware, ClearToolUsesEdit\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    middleware=[\n",
    "        ContextEditingMiddleware(\n",
    "            edits=[\n",
    "                ClearToolUsesEdit(\n",
    "                    trigger=2000,\n",
    "                    keep=3,\n",
    "                    clear_tool_inputs=False,\n",
    "                    exclude_tools=[],\n",
    "                    placeholder=\"[cleared]\",\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909f8334-17f4-4281-b9a1-f78614cefe1d",
   "metadata": {},
   "source": [
    "## Advanced: è‡ªè¨‚ç¾© Middleware\n",
    "\n",
    "https://langchain-5e9cc07a.mintlify.app/oss/python/langchain/middleware/custom#node-style-hooks\n",
    "\n",
    "### Node é¢¨æ ¼çš„ Hooks\n",
    "\n",
    "åœ¨ç‰¹å®šçš„åŸ·è¡Œç¯€é»ä¾åºåŸ·è¡Œã€‚é©ç”¨æ–¼è¨˜éŒ„ï¼ˆloggingï¼‰ã€é©—è­‰ï¼ˆvalidationï¼‰èˆ‡ç‹€æ…‹æ›´æ–°ï¼ˆstate updatesï¼‰ã€‚å¯ç”¨çš„ hooksï¼š\n",
    "\n",
    "- **before_agent** - åœ¨ agent é–‹å§‹å‰åŸ·è¡Œï¼ˆæ¯æ¬¡å‘¼å«åƒ…ä¸€æ¬¡ï¼‰\n",
    "- **before_model** - åœ¨æ¯æ¬¡æ¨¡å‹å‘¼å«å‰åŸ·è¡Œ\n",
    "- **after_model** - åœ¨æ¯æ¬¡æ¨¡å‹å›æ‡‰å¾ŒåŸ·è¡Œ\n",
    "- **after_agent** - åœ¨ agent å®Œæˆå¾ŒåŸ·è¡Œï¼ˆæ¯æ¬¡å‘¼å«åƒ…ä¸€æ¬¡ï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "### Wrap é¢¨æ ¼çš„ Hooks\n",
    "\n",
    "æ””æˆªåŸ·è¡Œæµç¨‹ä¸¦æ§åˆ¶ä½•æ™‚å‘¼å«è™•ç†å™¨ã€‚é©ç”¨æ–¼é‡è©¦ï¼ˆretriesï¼‰ã€å¿«å–ï¼ˆcachingï¼‰èˆ‡è½‰æ›ï¼ˆtransformationï¼‰ã€‚  \n",
    "ä½ å¯ä»¥æ±ºå®šè™•ç†å™¨è¢«å‘¼å«çš„æ¬¡æ•¸ï¼š\n",
    "\n",
    "- **0 æ¬¡**ï¼ˆçŸ­è·¯ï¼Œshort-circuitï¼‰\n",
    "- **1 æ¬¡**ï¼ˆæ­£å¸¸æµç¨‹ï¼‰\n",
    "- **å¤šæ¬¡**ï¼ˆé‡è©¦é‚è¼¯ï¼‰\n",
    "\n",
    "å¯ç”¨çš„ hooksï¼š\n",
    "\n",
    "- **wrap_model_call** - åŒ…ä½æ¯ä¸€æ¬¡æ¨¡å‹å‘¼å«\n",
    "- **wrap_tool_call** - åŒ…ä½æ¯ä¸€æ¬¡å·¥å…·å‘¼å«\n",
    "\n",
    "---\n",
    "\n",
    "### å»ºç«‹ Middleware çš„å…©ç¨®æ–¹å¼\n",
    "\n",
    "ä½ å¯ä»¥ç”¨ä»¥ä¸‹å…©ç¨®æ–¹å¼å»ºç«‹ middlewareï¼š\n",
    "\n",
    "#### 1. åŸºæ–¼è£é£¾å™¨ï¼ˆDecorator-basedï¼‰çš„ Middleware\n",
    "\n",
    "å¿«é€Ÿä¸”ç°¡å–®ï¼Œé©åˆå–®ä¸€ hook çš„ middlewareã€‚ä½¿ç”¨è£é£¾å™¨ä¾†åŒ…è£å€‹åˆ¥å‡½å¼ã€‚\n",
    "\n",
    "#### 2. åŸºæ–¼é¡åˆ¥ï¼ˆClass-basedï¼‰çš„ Middleware\n",
    "\n",
    "æ›´å¼·å¤§ï¼Œé©åˆéœ€è¦å¤šå€‹ hooks æˆ–è¨­å®šçš„è¤‡é›œ middlewareã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### åŸºæ–¼è£é£¾å™¨çš„ Middleware\n",
    "\n",
    "å¿«é€Ÿä¸”ç°¡å–®ï¼Œé©åˆå–®ä¸€ hook çš„ middlewareã€‚ä½¿ç”¨è£é£¾å™¨ä¾†åŒ…è£å€‹åˆ¥å‡½å¼ã€‚å¯ç”¨çš„è£é£¾å™¨ï¼š\n",
    "\n",
    "#### Node é¢¨æ ¼ï¼š\n",
    "\n",
    "- **@before_agent** - åœ¨ agent é–‹å§‹å‰åŸ·è¡Œï¼ˆæ¯æ¬¡å‘¼å«åƒ…ä¸€æ¬¡ï¼‰\n",
    "- **@before_model** - åœ¨æ¯æ¬¡æ¨¡å‹å‘¼å«å‰åŸ·è¡Œ\n",
    "- **@after_model** - åœ¨æ¯æ¬¡æ¨¡å‹å›æ‡‰å¾ŒåŸ·è¡Œ\n",
    "- **@after_agent** - åœ¨ agent å®Œæˆå¾ŒåŸ·è¡Œï¼ˆæ¯æ¬¡å‘¼å«åƒ…ä¸€æ¬¡ï¼‰\n",
    "\n",
    "#### Wrap é¢¨æ ¼ï¼š\n",
    "\n",
    "- **@wrap_model_call** - ä»¥è‡ªè¨‚é‚è¼¯åŒ…ä½æ¯ä¸€æ¬¡æ¨¡å‹å‘¼å«\n",
    "- **@wrap_tool_call** - ä»¥è‡ªè¨‚é‚è¼¯åŒ…ä½æ¯ä¸€æ¬¡å·¥å…·å‘¼å«\n",
    "\n",
    "#### ä¾¿åˆ©åŠŸèƒ½ï¼ˆConvenienceï¼‰ï¼š\n",
    "\n",
    "- **@dynamic_prompt** - ç”¢ç”Ÿå‹•æ…‹çš„ system prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b70717e-ea8d-44ac-a9b8-35304a8ae5d7",
   "metadata": {},
   "source": [
    "### @dynamic_prompt ç¯„ä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf4350-0f19-4353-84e0-359d05c91211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e23d3a-f113-47c1-ac03-53e16704a120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.initialization import credential_init\n",
    "\n",
    "credential_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27aebd9-fe65-4bdb-912b-30c387e41ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "\n",
    "@dynamic_prompt\n",
    "def dynamic_prompt_demo(request: ModelRequest) -> str:\n",
    "    \"\"\"Generate system prompt based on user role.\"\"\"\n",
    "    messages = request.messages\n",
    "\n",
    "    system_prompt = next(\n",
    "        (m.content for m in messages if isinstance(m, SystemMessage)),\n",
    "        \"You are a helpful assistant.\"\n",
    "    )\n",
    "\n",
    "    print(f\"***{system_prompt}***\")\n",
    "    \n",
    "    return system_prompt\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    middleware=[dynamic_prompt_demo],\n",
    "    system_prompt=\"This is a simple example for learning middleware. You can let the user see the system prompt provided by user\"\n",
    ")\n",
    "\n",
    "# The system prompt will be set dynamically based on context\n",
    "# result = agent.invoke(\n",
    "#     {\"messages\": [{\"role\": \"system\", \"content\": \"You will behave as the US president Donald Trump\"}, {\"role\": \"user\", \"content\": \"How are you today?\"}]},\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4680afcf-2835-49e9-a264-003c08dcdba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254c2e39-961d-459d-87d9-38e4a5948273",
   "metadata": {},
   "source": [
    "å¾é€™å€‹ä¾‹å­ä½ å¯ä»¥çœ‹å‡ºé€é@dynamic_promptï¼Œå¯ä»¥ä¿®æ”¹invokeæ™‚çµ¦äºˆçš„ç³»çµ±æç¤ºè©ã€‚\n",
    "\n",
    "æ¥ä¸‹ä¾†æˆ‘å€‘å¯åŠ å…¥context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f677d5-e67a-408a-be12-d254dd469ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Context å®šç¾© æ–¹æ³•ä¸€\n",
    "# @dataclass\n",
    "# class Context:\n",
    "#     user_id: str\n",
    "#     prompt: str\n",
    "\n",
    "# Context å®šç¾© æ–¹æ³•äºŒ\n",
    "class Context(BaseModel):\n",
    "    user_id: str\n",
    "    prompt: str\n",
    "    \n",
    "\n",
    "@dynamic_prompt\n",
    "def dynamic_prompt_demo(request: ModelRequest) -> str:\n",
    "    \"\"\"Generate system prompt based on user role.\"\"\"\n",
    "    messages = request.messages\n",
    "\n",
    "    user_id = request.runtime.context.user_id\n",
    "    system_prompt = request.runtime.context.prompt\n",
    "\n",
    "    print(f\"user_id: {user_id}\")\n",
    "    \n",
    "    return system_prompt\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    middleware=[dynamic_prompt_demo],\n",
    "    system_prompt=\"This is a simple example for learning middleware. You can let the user see the system prompt provided by user\",\n",
    "    context_schema=Context\n",
    ")\n",
    "\n",
    "# The system prompt will be set dynamically based on context\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"How are you today?\"}]},\n",
    "    context={\"user_id\": \"123456\", \"prompt\": \"You will behave as the US president Donald Trump\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a83ad9-89c4-4549-bff8-68c9c769b097",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad38628-d37c-4ecb-ba25-10ad78e40067",
   "metadata": {},
   "source": [
    "### @wrap_model_call ç¯„ä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd443f11-d92d-478c-a515-17a0da45d4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "\n",
    "\n",
    "@wrap_model_call\n",
    "def wrap_model_call_demo(\n",
    "    request: ModelRequest,\n",
    "    handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "\n",
    "    # Append at end - models pay more attention to final messages\n",
    "    messages = [\n",
    "        *request.messages,\n",
    "        {\"role\": \"ai\", \"content\": \"ä»Šå¤©é¢³é¢¨æ‰“é›·ä¸‹é›¨\"},\n",
    "        {\"role\": \"user\", \"content\": \"æˆ‘å‰›å‰›å•ä»€éº¼å•é¡Œ?\"}\n",
    "    ]\n",
    "    request = request.override(messages=messages)  \n",
    "    \n",
    "    return handler(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76b8489-7f30-4e44-b0a1-84b08f839271",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    middleware=[wrap_model_call_demo],\n",
    ")\n",
    "\n",
    "# The system prompt will be set dynamically based on context\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"ä»Šå¤©çš„å¤©æ°£å¦‚ä½•?\"}]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc3abbf-1789-40cf-8984-ccbaadb1cf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929c1627-8cd6-4913-a36a-d72e518fd7b8",
   "metadata": {},
   "source": [
    "åŠ å…¥ ImMemoryStoreã€‚åœ¨dynamic_promptä¸­ä¹Ÿå¯ä»¥åŠ å…¥ImMemoryStore\n",
    "\n",
    "https://docs.langchain.com/oss/python/langchain/context-engineering#store-2\n",
    "\n",
    "èªªå¯¦è©±é€™ä¸ç®—æ˜¯ä¸€å€‹å¥½çš„ç¯„ä¾‹ï¼Œæœƒåœ¨æœ‰èª¿ç”¨å·¥å…·çš„æƒ…æ³ä¸‹å‡ºå•é¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c923546-ff97-45b4-a9c4-fef2c939558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, List\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from langchain.tools import tool\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Context schema\n",
    "# ---------------------------\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Middleware\n",
    "# ---------------------------\n",
    "\n",
    "@wrap_model_call\n",
    "def inject_writing_style(\n",
    "    request: ModelRequest,\n",
    "    handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"Inject user's email writing style from Store.\"\"\"\n",
    "    user_id = request.runtime.context.user_id\n",
    "\n",
    "    # Read from Store: get user's writing style examples\n",
    "    store = request.runtime.store\n",
    "    writing_style = store.get((\"writing_style\",), user_id)\n",
    "\n",
    "    print(\"inject_writing_style\\n****\")\n",
    "    # for message in request.messages:\n",
    "    #     print(f\"type: {message.type}: {message.content}\")\n",
    "    # print(\"****\")\n",
    "    \n",
    "    if writing_style:\n",
    "        style = writing_style.value\n",
    "        style_context = dedent(f\"\"\"\\\n",
    "        Your writing style:\n",
    "        - Tone: {style.get('tone', 'professional')}\n",
    "        - Typical greeting: \"{style.get('greeting', 'Hi')}\"\n",
    "        - Typical sign-off: \"{style.get('sign_off', 'Best')}\"\n",
    "        - Example email you've written:\n",
    "        {style.get('example_email', '')}\n",
    "        \"\"\")\n",
    "        # print(\"*****\")\n",
    "        # print(\"ğŸ”¥ inject_writing_style called\")\n",
    "        # print(f\"messages count: {len(request.messages)}\")\n",
    "        # print(f\"style_context: {style_context}\")\n",
    "        # print(\"*****\")\n",
    "        \n",
    "        messages = [\n",
    "            *request.messages,\n",
    "            # {\"role\": \"user\", \"content\": style_context}\n",
    "        ]\n",
    "        request = request.override(messages=messages)\n",
    "\n",
    "    return handler(request)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Example tool\n",
    "# ---------------------------\n",
    "\n",
    "class EmailInput(BaseModel):\n",
    "    to: str = Field(description=\"The recipient of the email\")\n",
    "    subject: str = Field(description=\"The email subject\")\n",
    "    body: str = Field(description=\"The email content\")\n",
    "\n",
    "\n",
    "@tool\n",
    "def draft_email(input_: EmailInput) -> str:\n",
    "    \"\"\"Draft an email given recipient, subject, and body.\"\"\"\n",
    "    return f\"To: {input_.to}\\nSubject: {input_.subject}\\n\\n{input_.body}\"\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Store + agent setup\n",
    "# ---------------------------\n",
    "\n",
    "store = InMemoryStore()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[draft_email],\n",
    "    middleware=[inject_writing_style],\n",
    "    context_schema=Context,\n",
    "    store=store,\n",
    ")\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Seed the store with a user's style\n",
    "# ---------------------------\n",
    "\n",
    "user_id = \"user_123\"\n",
    "\n",
    "store.put(\n",
    "    (\"writing_style\",),\n",
    "    user_id,\n",
    "    {\n",
    "        \"tone\": \"friendly but professional\",\n",
    "        \"greeting\": \"Hey there\",\n",
    "        \"sign_off\": \"Cheers\",\n",
    "        \"example_email\": (\n",
    "            \"Hey there John,\\n\\n\"\n",
    "            \"Just wanted to follow up on our chat yesterday. \"\n",
    "            \"Let me know if you need anything else.\\n\\n\"\n",
    "            \"Cheers,\\nAlex\"\n",
    "        ),\n",
    "    },\n",
    ")\n",
    "# ---------------------------\n",
    "# Invoke the agent\n",
    "# ---------------------------\n",
    "\n",
    "# response = agent.invoke(\n",
    "#     {\n",
    "#         \"messages\": [\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": \"Write a short email to Sarah about the project update.\"\n",
    "#             }\n",
    "#         ]\n",
    "#     },\n",
    "#     context=Context(user_id=user_id),\n",
    "# )\n",
    "\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d360b38c-8f0e-4837-a5fc-7fc8fc0c8b22",
   "metadata": {},
   "source": [
    "è·‘äº†å¹¾æ¬¡å¾Œç™¼ç¾ï¼Œæœ‰æ™‚å€™Agentç¬¨ç¬¨çš„ï¼Œä¸çŸ¥é“å“ªå€‹æ™‚å€™è¦è·³å‡ºè¿´åœˆ\n",
    "\n",
    "æ‰€ä»¥æˆ‘å€‘å¼·åˆ¶Agentåœ¨é”æˆç›®æ¨™å¾Œé›¢é–‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a1f31c-46ee-4036-8479-225f193d7152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain.agents.middleware import after_model, AgentState\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "\n",
    "class IfGoal(BaseModel):\n",
    "    name: Literal[\"Yes\", \"No\"] = Field(description=\"If we already achieve the goal. The answer is either `Yes` or `No`\")\n",
    "    reason: str = Field(description=\"The reason behind the decision\")\n",
    "\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=IfGoal)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "model_check = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                        model_name=\"gpt-4o-mini\", temperature=0,\n",
    "                        name=\"check_goal_model\")\n",
    "\n",
    "\n",
    "pipeline_check = model_check|output_parser\n",
    "\n",
    "\n",
    "@after_model(can_jump_to=[\"end\"])\n",
    "def check_goal(state: AgentState, runtime: Runtime):\n",
    "\n",
    "    # # æ–¹ä¾¿èµ·è¦‹\n",
    "    # prompt = dedent(f\"\"\"\n",
    "    # Last message: {state[\"messages\"][-1].content}\n",
    "\n",
    "    # Goal: Write a short email to Sarah about the project update.\n",
    "    # output instructions: {format_instructions}\n",
    "    # \"\"\")\n",
    "\n",
    "    # result = pipeline_check.invoke(prompt)\n",
    "    \n",
    "    # if result.name == \"Yes\":\n",
    "    #     return {\"messages\": state['messages'],\n",
    "    #             \"jump_to\": \"end\"\n",
    "    #             }\n",
    "    # else:\n",
    "    #     print(\"^^^\")\n",
    "    #     for message in state[\"messages\"]:\n",
    "    #         print(f\"type: {message.type}: {message.content}\")\n",
    "    #     print(\"^^^\")\n",
    "    #     return None\n",
    "    print(\"^^^\")\n",
    "    for message in state[\"messages\"]:\n",
    "        print(f\"type: {message.type}: {message.content}\")\n",
    "    print(\"^^^\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8f9bdd-e410-4831-91b9-623502e1e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[draft_email],\n",
    "    middleware=[inject_writing_style, \n",
    "                check_goal\n",
    "               ],\n",
    "    context_schema=Context,\n",
    "    store=store,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d211e39a-1eef-402a-add6-f730275f2a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Write a short email to Sarah about the project update.\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    context=Context(user_id=user_id),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df86a82e-e875-4c08-8378-ec8fda3a9899",
   "metadata": {},
   "outputs": [],
   "source": [
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a7f2ed-5490-4ffd-bc53-4add4f3a496c",
   "metadata": {},
   "source": [
    "### åœ¨ä»£ç†é˜²è­·æªæ–½ï¼ˆagent guardrailsï¼‰ä¹‹å‰åŸ·è¡Œ\n",
    "\n",
    "ä½ å¯ä»¥åœ¨ä»£ç†æ­£å¼é€²å…¥é˜²è­·é‚è¼¯ï¼ˆguardrailsï¼‰ä¹‹å‰ï¼Œå…ˆåŠ å…¥è‡ªè¨‚çš„ä¸­ä»‹è»Ÿé«”æµç¨‹ã€‚  \n",
    "é€™è®“ä½ èƒ½åœ¨æ—©æœŸéšæ®µæ””æˆªã€ä¿®æ”¹æˆ–åˆ†æè«‹æ±‚ï¼ŒåŒ…å«ï¼š\n",
    "\n",
    "- åœ¨é€²å…¥æ­£å¼æµç¨‹å‰ï¼Œå…ˆæª¢æŸ¥èˆ‡èª¿æ•´ä½¿ç”¨è€…çš„è¼¸å…¥å…§å®¹  \n",
    "- å¥—ç”¨é¡å¤–çš„é©—è­‰æˆ–å®‰å…¨æª¢æŸ¥  \n",
    "- æ ¹æ“šéœ€æ±‚ä¿®æ”¹æç¤ºï¼ˆpromptï¼‰ã€åŠ å…¥æ¨™è¨˜æˆ–é¡å¤–è³‡è¨Š  \n",
    "- åœ¨å…¶ä»–é‚è¼¯åŸ·è¡Œå‰ï¼Œå°è«‹æ±‚é€²è¡Œç´€éŒ„æˆ–è¿½è¹¤  \n",
    "\n",
    "é€™èƒ½è®“æ•´å€‹ä»£ç†æµç¨‹æ›´åŠ å¯æ§ã€å¯æ“´å……ï¼Œä¹Ÿæ›´å®¹æ˜“æ»¿è¶³è‡ªè¨‚éœ€æ±‚ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ec83cb-65ac-4a41-8c31-a88cc0ee7968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from langchain.agents.middleware import AgentMiddleware, AgentState, hook_config\n",
    "from langgraph.runtime import Runtime\n",
    "\n",
    "\n",
    "# å®¢è£½åŒ–AgentMiddleware\n",
    "class ContentFilterMiddleware(AgentMiddleware):\n",
    "    \"\"\"Deterministic guardrail: Block requests containing banned keywords.\"\"\"\n",
    "\n",
    "    def __init__(self, banned_keywords: list[str]):\n",
    "        super().__init__()\n",
    "        self.banned_keywords = [kw.lower() for kw in banned_keywords]\n",
    "\n",
    "    @hook_config(can_jump_to=[\"end\"])\n",
    "    def before_agent(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "        # Get the first user message\n",
    "        if not state[\"messages\"]:\n",
    "            return None\n",
    "        \n",
    "        first_message = state[\"messages\"][0]\n",
    "        \n",
    "        if first_message.type != \"human\":\n",
    "            return None\n",
    "\n",
    "        content = first_message.content.lower()\n",
    "\n",
    "        # Check for banned keywords\n",
    "        for keyword in self.banned_keywords:\n",
    "            if keyword in content:\n",
    "                # Block execution before any processing\n",
    "                return {\n",
    "                    \"messages\": [{\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": dedent(f\"\"\"\\\n",
    "                        I cannot process requests containing inappropriate content. \n",
    "                        banned keyword `{keyword}` is detected\n",
    "                        Please rephrase your request.\n",
    "                        \"\"\"\n",
    "                        )\n",
    "                    }],\n",
    "                    \"jump_to\": \"end\"\n",
    "                }\n",
    "\n",
    "        return None\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    middleware=[\n",
    "        ContentFilterMiddleware(\n",
    "            banned_keywords=[\"hack\", \"exploit\", \"malware\"]\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# This request will be blocked before any processing\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"How do I hack into a database?\"}]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a8b748-0dc0-4c9e-a2cf-7abee6daa0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"How do I access a database?\"}]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80298316-9d13-497c-b885-c27aca0c012d",
   "metadata": {},
   "source": [
    "### åœ¨ä»£ç†é˜²è­·æªæ–½ï¼ˆagent guardrailsï¼‰ä¹‹å¾Œ\n",
    "\n",
    "ä½ ä¹Ÿå¯ä»¥åœ¨ä»£ç†å®Œæˆé˜²è­·æª¢æŸ¥ä¹‹å¾ŒåŠ å…¥è‡ªè¨‚ä¸­ä»‹è»Ÿé«”ã€‚  \n",
    "é€™å€‹éšæ®µçš„ä¸­ä»‹è»Ÿé«”é€šå¸¸ç”¨ä¾†è™•ç†å·²é€šéå®‰å…¨é©—è­‰çš„å…§å®¹ï¼Œä¾‹å¦‚ï¼š\n",
    "\n",
    "- èª¿æ•´æˆ–é‡æ–°æ ¼å¼åŒ–ä»£ç†ç”¢ç”Ÿçš„å›æ‡‰  \n",
    "- æ·»åŠ é¡å¤–çš„è³‡è¨Šï¼ˆå¦‚æ‘˜è¦ã€æ¨™ç±¤ã€ä½¿ç”¨è€…æç¤ºï¼‰  \n",
    "- å°å›æ‡‰é€²è¡Œè¨˜éŒ„ã€åˆ†ææˆ–è¿½è¹¤  \n",
    "- åœ¨å¿…è¦æ™‚é€²è¡ŒäºŒæ¬¡æª¢æŸ¥æˆ–è½‰æ›ï¼ˆä¾‹å¦‚ç¿»è­¯ã€ç°¡åŒ–å…§å®¹ï¼‰  \n",
    "\n",
    "æ”¾ç½®åœ¨é€™å€‹éšæ®µçš„ä¸­ä»‹è»Ÿé«”æœ€é©åˆåšã€Œå¾Œè™•ç†ã€ï¼Œå› ç‚ºè¨Šæ¯å·²ç¶“é€šéå®‰å…¨èˆ‡é©—è­‰æµç¨‹ï¼Œä¸æœƒè·¨è¶Šé˜²è­·è¦å‰‡ã€‚\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70924441-66fe-4d03-8c6a-18a600274b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import AgentMiddleware, AgentState, hook_config\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "from typing import Any\n",
    "\n",
    "class SafetyGuardrailMiddleware(AgentMiddleware):\n",
    "    \"\"\"Model-based guardrail: Use an LLM to evaluate response safety.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.safety_model = init_chat_model(\"gpt-4o-mini\")\n",
    "\n",
    "    @hook_config(can_jump_to=[\"end\"])\n",
    "    def after_agent(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "        # Get the final AI response\n",
    "        if not state[\"messages\"]:\n",
    "            return None\n",
    "\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if not isinstance(last_message, AIMessage):\n",
    "            return None\n",
    "\n",
    "        # Use a model to evaluate safety\n",
    "        safety_prompt = f\"\"\"Evaluate if this response is safe and appropriate.\n",
    "        Respond with only 'SAFE' or 'UNSAFE'.\n",
    "\n",
    "        Response: {last_message.content}\"\"\"\n",
    "\n",
    "        result = self.safety_model.invoke([{\"role\": \"user\", \"content\": safety_prompt}])\n",
    "        \n",
    "        if \"UNSAFE\" in result.content:\n",
    "            return {\n",
    "                \"messages\": [{\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"I cannot provide that response. Please rephrase your request.\"\n",
    "                }],\n",
    "                \"jump_to\": \"end\"\n",
    "            }\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    middleware=[SafetyGuardrailMiddleware()],\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"How do I make explosives?\"}]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757f6a9f-8fe3-4ba8-8597-2503ad4e7f85",
   "metadata": {},
   "source": [
    "## å¯¦ä½œ\n",
    "\n",
    "åˆ©ç”¨ç¬¬äº”å‘¨å­¸åˆ°çš„Danbooru Taggingä¾†åšç‚ºåœ–åƒçš„Guardrail\n",
    "\n",
    "- åœ¨æœ¬åœ°æ¶è¨­Flaskæœå‹™\n",
    "- ä½¿ç”¨requestå°‡åœ–ç‰‡ä¸Šå‚³åˆ°Flaskæœå‹™ä¸­\n",
    "- é€éè¿”å›çš„taggingä¾†åˆ¤æ–·æ˜¯å¦æ‡‰è©²filteræ‰å…§å®¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b25d55f1-b2b2-4174-bdb3-534297dda5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f098e7d0-bbf5-4366-8bc1-9f39e7b8e042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import requests\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def image_to_base64(image_path):\n",
    "    \n",
    "    with Image.open(image_path) as image:\n",
    "        \n",
    "        # Save the Image to a Buffer\n",
    "        buffered = io.BytesIO()\n",
    "        image.save(buffered, format=\"JPEG\")\n",
    "        \n",
    "        # Encode the Image to Base64\n",
    "        image_str = base64.b64encode(buffered.getvalue())\n",
    "    \n",
    "    return image_str.decode('utf-8')\n",
    "\n",
    "\n",
    "# image_base64 = image_to_base64(\"tutorial/week_7/TA-2025-11-09-13-31-amazingqua-231885343593224.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7ddd33-b90f-4a45-9c06-0619777f6e6c",
   "metadata": {},
   "source": [
    "åœ¨ç¬¬äº”å‘¨çš„ wd14-tagger-standalone è£¡åŸ·è¡Œ:\n",
    "\n",
    "python -m app_flask --model camie-tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89090b87-cdf9-475f-9a3f-180514bcac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://localhost:5000/tag\"\n",
    "\n",
    "image_base64 = image_to_base64(\"tutorial/week_5/StellarBladeTachy-Nikke.png\")\n",
    "\n",
    "response = requests.post(\n",
    "                url,\n",
    "                json={\"image\": image_base64},\n",
    "                timeout=60,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afba2a3c-2135-447d-be3c-441d1a3480b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1girl',\n",
       " 'weapon',\n",
       " 'gun',\n",
       " 'holding',\n",
       " 'rifle',\n",
       " 'long hair',\n",
       " 'solo',\n",
       " 'brown eyes',\n",
       " 'holding weapon',\n",
       " 'bodysuit',\n",
       " 'holding gun',\n",
       " 'brown hair',\n",
       " 'covered navel',\n",
       " 'breasts',\n",
       " 'aiming',\n",
       " 'parted lips',\n",
       " 'science fiction',\n",
       " 'lips',\n",
       " 'skin tight',\n",
       " 'black bodysuit',\n",
       " 'sniper rifle',\n",
       " 'medium breasts',\n",
       " 'scope']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()['tag_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87b845e-824a-4107-8fc9-b9c16b30daff",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_base64 = image_to_base64(\"tutorial/week_7/TA-2025-11-09-13-24-amazingqua-231885343593224.png\")\n",
    "\n",
    "response = requests.post(\n",
    "                url,\n",
    "                json={\"image\": image_base64},\n",
    "                timeout=60,\n",
    "            )\n",
    "\n",
    "response.json()['tag_list']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2608ba-0d0f-4d3b-a8de-19d247236968",
   "metadata": {},
   "source": [
    "### å°‡åœ–ç‰‡åŠ å…¥åˆ°messageä¸­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6491c6-ee8c-4915-beee-c66cdbaa3638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "human_message = HumanMessage(content_blocks=[\n",
    "    {\"type\": \"text\", \"text\": \"Hello, how are you?\"},\n",
    "    {\"type\": \"image\", \"url\": \"https://example.com/image.jpg\"},\n",
    "])\n",
    "\n",
    "\"\"\"\\\n",
    "Image base64 format: data:image/jpeg;base64,{image_str}\\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d47615-4936-4fb1-bef4-d4e3ceff1307",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message.type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baa4e66-66cd-4af7-bfd9-f18a5457eeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f938207-b14f-415a-9eef-811fc5cfae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message.content[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c534e3-6eb2-4d56-ba6c-2e03ae997243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from textwrap import dedent\n",
    "from typing import Literal, List\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# å®¢è£½åŒ–AgentMiddleware\n",
    "class ImageContentFilterMiddleware(AgentMiddleware):\n",
    "    \"\"\"Deterministic guardrail: Block requests containing banned keywords.\"\"\"\n",
    "\n",
    "    def __init__(self, url: str):\n",
    "        super().__init__()\n",
    "        self.flagged_tags = ['uncensored', 'censored', 'mosaic censoring']\n",
    "        self.url = url\n",
    "        \n",
    "    @hook_config(can_jump_to=[\"end\"])\n",
    "    def before_agent(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "        # Get the first user message\n",
    "        if not state[\"messages\"]:\n",
    "            return None\n",
    "\n",
    "        first_message = state[\"messages\"][0]\n",
    "            \n",
    "        if first_message.type != \"human\":\n",
    "            return None\n",
    "\n",
    "        content = first_message.content\n",
    "\n",
    "        if isinstance(content, str):\n",
    "            return None\n",
    "        else:\n",
    "            image_list = []\n",
    "            for c in content:\n",
    "                if c[\"type\"] == 'image':\n",
    "                    # append the base64\n",
    "                    image_list.append(c[\"url\"].split(\",\")[-1])\n",
    "        \n",
    "        # Check for NSFW content\n",
    "        for image_base64 in image_list:\n",
    "            \n",
    "            response = requests.post(\n",
    "                self.url,\n",
    "                json={\"image\": image_base64},\n",
    "                timeout=60,\n",
    "            )\n",
    "            \n",
    "            tag_list = response.json()['tag_list']\n",
    "\n",
    "            for flagged_tag in self.flagged_tags:\n",
    "                if flagged_tag in tag_list:\n",
    "                    return {\n",
    "                        \"messages\": [{\n",
    "                            \"role\": \"assistant\",\n",
    "                            \"content\": f\"It contains NSFW content including: tag {flagged_tag} is detected\"\n",
    "                        }],\n",
    "                        \"jump_to\": \"end\"\n",
    "                    }\n",
    "\n",
    "        return None\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    middleware=[\n",
    "        ImageContentFilterMiddleware(url=\"http://localhost:5000/tag\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e22571-6a1e-4b35-b967-4532c38d2330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "image_base64 = image_to_base64(\"tutorial/week_7/TA-2025-11-09-13-24-amazingqua-231885343593224.png\")\n",
    "\n",
    "human_message = HumanMessage(content_blocks=[\n",
    "    {\"type\": \"text\", \"text\": \"What is the content in this image?\"},\n",
    "    {\"type\": \"image\", \"url\": f\"data:image/jpeg;base64,{image_base64}\"},\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be8c8db-ba94-4b43-9c44-004cb507019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.invoke({\"messages\": [human_message]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa207150-37e7-4bad-8177-d17625311cc9",
   "metadata": {},
   "source": [
    "å¦‚ä½•å°‡taggingä¹Ÿè¨˜éŒ„åœ¨mlflowè£¡ï¼Œé€™æ¨£æ–¹ä¾¿ä»¥å¾Œçš„è¿½è¹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfca8b0-ab8c-45b9-9a61-3659d0d2fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain\n",
    "\n",
    "url = \"http://localhost:5000/tag\"\n",
    "\n",
    "@chain\n",
    "def wd14_tagger(image_base64: str):\n",
    "\n",
    "    response = requests.post(\n",
    "                url,\n",
    "                json={\"image\": image_base64},\n",
    "                timeout=60,\n",
    "            )\n",
    "            \n",
    "    tag_list = response.json()['tag_list']\n",
    "    \n",
    "    return tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e075e9-6ddc-46bb-afb4-cb8b21885b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®¢è£½åŒ–AgentMiddleware\n",
    "class ImageContentFilterMiddleware(AgentMiddleware):\n",
    "    \"\"\"Deterministic guardrail: Block requests containing banned keywords.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flagged_tags = ['uncensored', 'censored', 'mosaic censoring']\n",
    "        \n",
    "    @hook_config(can_jump_to=[\"end\"])\n",
    "    def before_agent(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "        # Get the first user message\n",
    "        if not state[\"messages\"]:\n",
    "            return None\n",
    "\n",
    "        first_message = state[\"messages\"][0]\n",
    "            \n",
    "        if first_message.type != \"human\":\n",
    "            return None\n",
    "\n",
    "        content = first_message.content\n",
    "\n",
    "        if isinstance(content, str):\n",
    "            return None\n",
    "        else:\n",
    "            image_list = []\n",
    "            for c in content:\n",
    "                if c[\"type\"] == 'image':\n",
    "                    # append the base64\n",
    "                    image_list.append(c[\"url\"].split(\",\")[-1])\n",
    "        \n",
    "        # Check for NSFW content\n",
    "        for image_base64 in image_list:\n",
    "            \n",
    "            tag_list = wd14_tagger.invoke(image_base64)\n",
    "\n",
    "            for flagged_tag in self.flagged_tags:\n",
    "                if flagged_tag in tag_list:\n",
    "                    return {\n",
    "                        \"messages\": [{\n",
    "                            \"role\": \"assistant\",\n",
    "                            \"content\": f\"It contains NSFW content including: tag {flagged_tag} is detected\"\n",
    "                        }],\n",
    "                        \"jump_to\": \"end\"\n",
    "                    }\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    middleware=[\n",
    "        ImageContentFilterMiddleware(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b83420-1d91-461d-acb3-db0997c1a619",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.invoke({\"messages\": [human_message]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2147c562-2db9-40de-b507-5ff5bd1da2e7",
   "metadata": {},
   "source": [
    "## OpenAI å…§å®¹å¯©æ ¸ï¼ˆOpenAI Moderatorï¼‰\n",
    "\n",
    "OpenAI Moderator å¯ç”¨æ–¼è­˜åˆ¥æ–‡å­—å’Œåœ–ç‰‡ä¸­å¯èƒ½å…·æœ‰å±å®³æ€§çš„å…§å®¹ã€‚  \n",
    "é€é **moderations endpoint**ï¼Œä½ å¯ä»¥æª¢æŸ¥æ–‡å­—æˆ–åœ–ç‰‡æ˜¯å¦å«æœ‰æœ‰å®³å…§å®¹ã€‚  \n",
    "è‹¥ç™¼ç¾å±å®³æ€§å…§å®¹ï¼Œç³»çµ±å¯ä»¥æ¡å–å°æ‡‰æªæ–½ï¼Œä¾‹å¦‚éæ¿¾å…§å®¹ï¼Œæˆ–å°ç”¢ç”Ÿä¸ç•¶å…§å®¹çš„ä½¿ç”¨è€…å¸³è™Ÿé€²è¡Œå¹²é ã€‚  \n",
    "æ­¤ **moderation endpoint** æ˜¯å…è²»ä½¿ç”¨çš„ã€‚\n",
    "\n",
    "### å¯ä½¿ç”¨çš„æ¨¡å‹\n",
    "\n",
    "1. **omni-moderation-latest**  \n",
    "   - æ”¯æ´æ›´å¤šåˆ†é¡é¸é …  \n",
    "   - æ”¯æ´å¤šæ¨¡æ…‹è¼¸å…¥ï¼ˆæ–‡å­— + åœ–ç‰‡ï¼‰  \n",
    "\n",
    "2. **image_base64**  \n",
    "   - é©ç”¨æ–¼å°åœ–ç‰‡é€²è¡ŒåŸºæ–¼ Base64 çš„å¯©æ ¸\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c10f85-ccbd-4427-ad39-8f3e1052bd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_base64?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec68b72-3f46-4741-9679-cbf7125de0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "from src.initialization import credential_init\n",
    "\n",
    "credential_init()\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.moderations.create(\n",
    "    model=\"omni-moderation-latest\",\n",
    "    input=[\n",
    "        {\"type\": \"text\", \"text\": \"...text to classify goes here...\"},\n",
    "        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_base64}\",\n",
    "            }\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dd4c11-a927-411c-9353-97d42e7c39da",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.results[0].categories.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4643de9b-ed6b-4101-9cc5-bed417dfd4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.results[0].category_scores.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0904d3cf-9718-48ca-bfb5-8790363c6c7d",
   "metadata": {},
   "source": [
    "The output has several categories in the JSON response, which tell you which (if any) categories of content are present in the inputs, and to what degree the model believes them to be present.\n",
    "\n",
    "| Output Category                 | Description |\n",
    "|---------------------------------|-------------|\n",
    "| **flagged** | Set to true if the model classifies the content as potentially harmful, false otherwise. |\n",
    "| **categories** | Contains a dictionary of per-category violation flags. For each category, the value is true if the model flags the corresponding category as violated, false otherwise. |\n",
    "| **category_scores** | Contains a dictionary of per-category scores output by the model, denoting the model's confidence that the input violates OpenAI's policy for the category. The value is between 0 and 1, where higher values denote higher confidence. |\n",
    "| **category_applied_input_types** | Contains information on which input types were flagged in the response for each category. For example, if both image and text inputs to the model are flagged for *violence/graphic*, the `violence/graphic` property will be set to `[\"image\", \"text\"]`. This field is only available on Omni models. |\n",
    "\n",
    "### Content Classification\n",
    "\n",
    "\n",
    "The table below describes the types of content that can be detected in the moderation API, along with which models and input types are supported for each category.\n",
    "\n",
    "\n",
    "| Category                 | Description | Models     | Inputs          |\n",
    "|--------------------------|-------------|------------|-----------------|\n",
    "| **harassment** | Content that expresses, incites, or promotes harassing language towards any target. | All | Text only |\n",
    "| **harassment/threatening** | Harassment content that also includes violence or serious harm towards any target. | All | Text only |\n",
    "| **hate** | Content that expresses, incites, or promotes hate based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status, or caste. Hateful content aimed at non-protected groups (e.g., chess players) is harassment. | All | Text only |\n",
    "| **hate/threatening** | Hateful content that also includes violence or serious harm towards the targeted group based on protected characteristics. | All | Text only |\n",
    "| **illicit** | Content that gives advice or instruction on how to commit illicit acts. A phrase like \"how to shoplift\" would fit this category. | Omni only | Text only |\n",
    "| **illicit/violent** | The same types of content flagged by the illicit category, but also includes references to violence or procuring a weapon. | Omni only | Text only |\n",
    "| **self-harm** | Content that promotes, encourages, or depicts acts of self-harm, such as suicide, cutting, and eating disorders. | All | Text and images |\n",
    "| **self-harm/intent** | Content where the speaker expresses that they are engaging or intend to engage in acts of self-harm. | All | Text and images |\n",
    "| **self-harm/instructions** | Content that encourages performing acts of self-harm or gives instructions on how to commit such acts. | All | Text and images |\n",
    "| **sexual** | Content meant to arouse sexual excitement or that promotes sexual services (excluding sex education and wellness). | All | Text and images |\n",
    "| **sexual/minors** | Sexual content that includes an individual under 18 years old. | All | Text only |\n",
    "| **violence** | Content that depicts death, violence, or physical injury. | All | Text and images |\n",
    "| **violence/graphic** | Content that depicts death, violence, or physical injury in graphic detail. | All | Text and images |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b1884d-372b-4a1c-bd64-f1667d2405a1",
   "metadata": {},
   "source": [
    "# åŸ·è¡Œæ™‚ç’°å¢ƒï¼ˆRuntimeï¼‰\n",
    "\n",
    "## æ¦‚è¦½\n",
    "\n",
    "LangChain çš„ `create_agent` åœ¨åº•å±¤æ˜¯é‹è¡Œæ–¼ LangGraph çš„åŸ·è¡Œæ™‚ç’°å¢ƒï¼ˆruntimeï¼‰ä¸Šã€‚  \n",
    "\n",
    "LangGraph æä¾›äº†ä¸€å€‹ **Runtime** ç‰©ä»¶ï¼Œå…¶ä¸­åŒ…å«ä»¥ä¸‹è³‡è¨Šï¼š\n",
    "\n",
    "- **Contextï¼ˆä¸Šä¸‹æ–‡ï¼‰**ï¼šéœæ…‹è³‡è¨Šï¼Œä¾‹å¦‚ä½¿ç”¨è€… IDã€è³‡æ–™åº«é€£ç·šï¼Œæˆ–å…¶ä»–ä»£ç†ç¨‹å¼åŸ·è¡Œæ™‚éœ€è¦çš„ä¾è³´é …ç›®  \n",
    "- **Storeï¼ˆå­˜å„²ï¼‰**ï¼šä¸€å€‹ `BaseStore` å¯¦ä¾‹ï¼Œç”¨æ–¼é•·æœŸè¨˜æ†¶  \n",
    "- **Stream writerï¼ˆä¸²æµå¯«å…¥å™¨ï¼‰**ï¼šç”¨æ–¼é€éã€Œcustomã€ä¸²æµæ¨¡å¼å‚³è¼¸è³‡è¨Šçš„ç‰©ä»¶  \n",
    "\n",
    "### åŸ·è¡Œæ™‚ä¸Šä¸‹æ–‡çš„ç”¨é€”\n",
    "\n",
    "Runtime ä¸Šä¸‹æ–‡å¯ä»¥ç‚ºä½ çš„ `tools` å’Œ `middleware` æä¾›ä¾è³´æ³¨å…¥ï¼ˆdependency injectionï¼‰ã€‚  \n",
    "- ä¸éœ€è¦ç¡¬ç·¨ç¢¼å€¼æˆ–ä¾è³´å…¨åŸŸè®Šæ•¸  \n",
    "- å¯ä»¥åœ¨å‘¼å«ä»£ç†ç¨‹å¼æ™‚æ³¨å…¥å¿…è¦çš„ä¾è³´ï¼Œä¾‹å¦‚è³‡æ–™åº«é€£ç·šã€ä½¿ç”¨è€… ID æˆ–è¨­å®šå€¼  \n",
    "- è®“å·¥å…·æ›´å®¹æ˜“æ¸¬è©¦ã€é‡è¤‡ä½¿ç”¨ä¸”å…·å½ˆæ€§  \n",
    "\n",
    "ä½ å¯ä»¥åœ¨ **tools** å’Œ **middleware** ä¸­å­˜å–é€™äº›åŸ·è¡Œæ™‚è³‡è¨Šï¼Œä»¥å‹•æ…‹èª¿æ•´è¡Œç‚ºæˆ–è™•ç†é‚è¼¯ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8f065b-527a-4255-81e3-d19b26e74164",
   "metadata": {},
   "source": [
    "### Inside tools\n",
    "\n",
    "#### Context\n",
    "\n",
    "Access immutable configuration and contextual data like user IDs, session details, or application-specific configuration through runtime.context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2330f095-0bcf-42a1-aa61-47a4f4df5aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "\n",
    "USER_DATABASE = {\n",
    "    \"lsp1\": {\n",
    "        \"preference\": \"an alluring and seductive tone.\",\n",
    "    },\n",
    "    \"lsp2\": {\n",
    "        \"preference\": \"suggestive content\",\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str\n",
    "\n",
    "\n",
    "@tool\n",
    "def fetch_user_email_preferences(runtime: ToolRuntime[Context]) -> str:  \n",
    "    \"\"\"Fetch the user's email preferences from the store.\"\"\"\n",
    "    user_id = runtime.context.user_id  \n",
    "\n",
    "    preference = USER_DATABASE[user_id]\n",
    "    \n",
    "    return preference\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    context_schema=Context,\n",
    "    tools=[fetch_user_email_preferences]\n",
    ")\n",
    "\n",
    "\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"write an email to the user based on his preference.\"}]},\n",
    "    context=Context(user_id=\"lsp1\")  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821e3cfe-ca58-4647-9ea1-3e519c429b72",
   "metadata": {},
   "source": [
    "#### è¨˜æ†¶é«”ï¼ˆMemory / Storeï¼‰\n",
    "\n",
    "ä½ å¯ä»¥é€é **store** åœ¨å¤šæ¬¡å°è©±é–“å­˜å–æŒä¹…åŒ–è³‡æ–™ã€‚  \n",
    "\n",
    "- ä½¿ç”¨æ–¹å¼ï¼šé€é `runtime.store` å­˜å–  \n",
    "- åŠŸèƒ½ï¼šå¯ä»¥å„²å­˜èˆ‡å–å¾—ä½¿ç”¨è€…å°ˆå±¬æˆ–æ‡‰ç”¨ç¨‹å¼å°ˆå±¬çš„è³‡æ–™  \n",
    "- å„ªé»ï¼šè®“ä»£ç†ç¨‹å¼èƒ½è¨˜ä½éå»çš„äº’å‹•ã€åå¥½è¨­å®šï¼Œæˆ–ä»»ä½•éœ€è¦è·¨å°è©±ä¿ç•™çš„è³‡è¨Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7499815-dc53-435f-8ba1-7a79c48415ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "\n",
    "# Access memory\n",
    "@tool\n",
    "def get_user_info(user_id: str, runtime: ToolRuntime) -> str:\n",
    "    \"\"\"Look up user info.\"\"\"\n",
    "    store = runtime.store\n",
    "    user_info = store.get((\"users\",), user_id)\n",
    "    return str(user_info.value) if user_info else \"Unknown user\"\n",
    "\n",
    "\n",
    "# Update memory\n",
    "@tool\n",
    "def save_user_info(user_id: str, user_info: dict[str, Any], runtime: ToolRuntime) -> str:\n",
    "    \"\"\"Save user info.\"\"\"\n",
    "    store = runtime.store\n",
    "    store.put((\"users\",), user_id, user_info)\n",
    "    return \"Successfully saved user info.\"\n",
    "\n",
    "\n",
    "# é—œéµæ˜¯ InMemoryStore\n",
    "store = InMemoryStore()\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=[get_user_info, save_user_info],\n",
    "    store=store\n",
    ")\n",
    "\n",
    "# First session: save user info\n",
    "agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Save the following user: userid: abc123, name: Foo, age: 25, email: foo@langchain.dev\"}]\n",
    "})\n",
    "\n",
    "# Second session: get user info\n",
    "agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Get user info for user with id 'abc123'\"}]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7e3920-d797-4554-a115-68c4170e6609",
   "metadata": {},
   "source": [
    "#### ä¸²æµå¯«å…¥å™¨ï¼ˆStream Writerï¼‰\n",
    "\n",
    "ä½ å¯ä»¥ä½¿ç”¨ `runtime.stream_writer` åœ¨å·¥å…·åŸ·è¡Œæ™‚å³æ™‚å‚³é€è‡ªè¨‚æ›´æ–°ã€‚  \n",
    "\n",
    "- åŠŸèƒ½ï¼šè®“å·¥å…·çš„åŸ·è¡Œç‹€æ…‹å¯ä»¥å³æ™‚å›é¥‹çµ¦ä½¿ç”¨è€…  \n",
    "- ç”¨é€”ï¼šæä¾›ä½¿ç”¨è€…å³æ™‚é€²åº¦ã€å‹•ä½œæ›´æ–°æˆ–ä¸­é–“çµæœ  \n",
    "- å„ªé»ï¼šæ”¹å–„ä½¿ç”¨è€…é«”é©—ï¼Œè®“ä»–å€‘æ¸…æ¥šäº†è§£å·¥å…·æ­£åœ¨åšä»€éº¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cbb9cd-e538-45ec-9d60-e3cca9d4b88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather(city: str, runtime: ToolRuntime) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    writer = runtime.stream_writer\n",
    "\n",
    "    # Stream custom updates as the tool executes\n",
    "    writer(f\"Looking up data for city: {city}\")\n",
    "    writer(f\"Acquired data for city: {city}\")\n",
    "\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "# First session: save user info\n",
    "agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"How is the weather in Taipei\"}]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0de054-c6aa-4cec-8693-19caf5c46f60",
   "metadata": {},
   "source": [
    "A dummy example of combining Tool BaseTool class and the ToolRuntime.\n",
    "\n",
    "We want to check if we can access the context with BaseTool class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed30df89-b16d-4d2c-96f6-c00c18e927fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58486002-6899-41a4-b3bf-f37440530f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.initialization import credential_init\n",
    "\n",
    "credential_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ec3242-c863-46f2-8e0c-6c307458a016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from textwrap import dedent\n",
    "from typing import Literal\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import BaseTool, ToolRuntime\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "\n",
    "class Inputs(BaseModel):\n",
    "    city: str = Field(description=\"name of the city\")\n",
    "\n",
    "\n",
    "class DummyContext(BaseModel):\n",
    "    weather: str\n",
    "\n",
    "\n",
    "class DummyTool(BaseTool):\n",
    "\n",
    "    input_output_parser: PydanticOutputParser = PydanticOutputParser(pydantic_object=Inputs)\n",
    "    input_format_instruction: str = input_output_parser.get_format_instructions()\n",
    "    \n",
    "    name:str = \"weather-reporter\"\n",
    "    description_template:str = dedent(\"\"\"\n",
    "    This tool can be used to report the weather of a city.\n",
    "    The inputs contains the `city`.\n",
    "    input format instructions: {input_format_instruction}\n",
    "    \"\"\")\n",
    "\n",
    "    description: str = description_template.format(input_format_instruction=input_format_instruction)\n",
    "    \n",
    "    def _run(self, \n",
    "             runtime: ToolRuntime[DummyContext], \n",
    "             **input):\n",
    "        \n",
    "        city = input[\"city\"]\n",
    "\n",
    "        weather = runtime.context.weather\n",
    "\n",
    "        return f\"{city}: {weather}\"\n",
    "    \n",
    "    def _arun(self, runtime: ToolRuntime[DummyContext], **input):\n",
    "        raise NotImplementedError(\"This tool does not support async\")\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    context_schema=DummyContext,\n",
    "    tools=[DummyTool()]\n",
    ")\n",
    "\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"how is the weather of Taipei?\"}]},\n",
    "    context=DummyContext(weather=\"cloudy\")  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68f4fa6-1e5a-48e3-840c-de0abadf6751",
   "metadata": {},
   "outputs": [],
   "source": [
    "response[\"messages\"][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7310497-d663-46f4-9070-29910485cbc3",
   "metadata": {},
   "source": [
    "### ToolRetryMiddleware\n",
    "\n",
    "`ToolRetryMiddleware` æ˜¯ä¸€å€‹ä¸­ä»‹è»Ÿé«”ï¼Œç”¨ä¾†è‡ªå‹•è™•ç†å·¥å…·åŸ·è¡Œå¤±æ•—çš„æƒ…æ³ã€‚  \n",
    "\n",
    "**åŠŸèƒ½èªªæ˜ï¼š**\n",
    "\n",
    "- ç•¶å·¥å…·åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼ˆraise exceptionï¼‰æ™‚  \n",
    "- ä¸­ä»‹è»Ÿé«”æœƒè‡ªå‹•ç­‰å¾…ï¼ˆwaitï¼‰ä¸€æ®µæ™‚é–“å¾Œå†é‡æ–°å˜—è©¦åŸ·è¡Œï¼ˆretryï¼‰  \n",
    "- é€™æ¨£å¯ä»¥æé«˜ä»£ç†ç¨‹å¼çš„ç©©å®šæ€§ï¼Œå°¤å…¶æ˜¯åœ¨å·¥å…·å¶çˆ¾å¤±æ•—æˆ–å¤–éƒ¨æœå‹™æš«æ™‚ä¸å¯ç”¨æ™‚  \n",
    "\n",
    "ä½¿ç”¨ `ToolRetryMiddleware` å¯ä»¥è®“ä½ çš„å·¥å…·æ›´å…·å®¹éŒ¯èƒ½åŠ›ï¼Œé¿å…ä¸€æ¬¡éŒ¯èª¤å°è‡´æ•´å€‹æµç¨‹ä¸­æ–·ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32edc63-8faf-425c-b7f7-7a0afb0dee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "from langchain.agents.middleware import ModelRequest, ModelResponse, wrap_tool_call, ToolRetryMiddleware\n",
    "\n",
    "\n",
    "@wrap_tool_call\n",
    "def DummyMiddleWare(request: ModelRequest,\n",
    "    handler: Callable[[ModelRequest], ModelResponse]) -> ModelResponse:\n",
    "\n",
    "    tool_call = request.tool_call\n",
    "    print(tool_call)\n",
    "\n",
    "    return handler(request)\n",
    "    \n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    context_schema=DummyContext,\n",
    "    tools=[DummyTool()],\n",
    "    middleware=[DummyMiddleWare,\n",
    "                ToolRetryMiddleware(\n",
    "                    max_retries=3,\n",
    "                    backoff_factor=1.0,\n",
    "                    initial_delay=1.0)])\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"how is the weather of Taipei?\"}]},\n",
    "    context=DummyContext(weather=\"cloudy\")  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76064fb4-1d4a-4259-9c07-7ab1d380aed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response['messages'][-1].content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
