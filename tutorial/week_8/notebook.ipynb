{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fabc653-5ca9-484b-a864-0b6a363ac275",
   "metadata": {},
   "source": [
    "# ğŸ“– Agent å¯¦ä½œç¯„ä¾‹ï¼šè‡ªå‹•åŒ–æœ‰è²æ›¸ç”Ÿæˆ\n",
    "\n",
    "æœ¬ Notebook å±•ç¤ºå¦‚ä½•é€é Agent ä¸²æ¥ **æ•…äº‹ â†’ åœ–åƒ â†’ èªéŸ³** çš„è‡ªå‹•åŒ–æµç¨‹ã€‚  \n",
    "æ¯å€‹æ­¥é©Ÿéƒ½æœƒå°‡è¼¸å‡ºä¿å­˜ç‚ºæª”æ¡ˆï¼Œé¿å…é‡è¤‡ Token æ¶ˆè€—ï¼Œä¸¦æ–¹ä¾¿å¾ŒçºŒæµç¨‹ä½¿ç”¨ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ æ•´é«”æµç¨‹\n",
    "1. æ•…äº‹å…§å®¹ç”Ÿæˆ  \n",
    "2. åœ–ç‰‡å…§å®¹ç”Ÿæˆ  \n",
    "3. èªéŸ³å…§å®¹ç”Ÿæˆ  \n",
    "\n",
    "---\n",
    "\n",
    "## 1ï¸âƒ£ æ•…äº‹å…§å®¹ç”Ÿæˆ\n",
    "**è¼¸å…¥**  \n",
    "- è‰ç¨¿æ–‡å­—  \n",
    "- æ—¢æœ‰å…§å®¹ (`.txt` æª”æ¡ˆ)  \n",
    "\n",
    "**è™•ç†æµç¨‹**  \n",
    "1. å°‡æ–‡å­—é€å…¥ Langserve æœå‹™  \n",
    "2. æ¥æ”¶ç”Ÿæˆçš„æ•…äº‹æ®µè½  \n",
    "\n",
    "**è¼¸å‡º**  \n",
    "- å°‡çµæœå­˜ç‚º `.txt` æª”  \n",
    "- é¿å… Agent ä¸€ç›´å‚³éæ•´ä»½æ•…äº‹ï¼Œé™ä½ Token æ¶ˆè€—  \n",
    "\n",
    "---\n",
    "\n",
    "## 2ï¸âƒ£ åœ–ç‰‡å…§å®¹ç”Ÿæˆ\n",
    "**è¼¸å…¥**  \n",
    "- æœ€æ–°ç”Ÿæˆçš„æ•…äº‹æ–‡å­—  \n",
    "<!-- - æ—¢æœ‰åœ–ç‰‡ (`.png`)   -->\n",
    "\n",
    "**è™•ç†æµç¨‹**  \n",
    "1. å°‡åœ–ç‰‡ç·¨ç¢¼ç‚º base64  \n",
    "2. æ–‡å­—èˆ‡åœ–ç‰‡é€å…¥ Langserve æœå‹™  \n",
    "3. æ¥æ”¶å›å‚³çš„åœ–ç‰‡ï¼ˆbase64 æ ¼å¼ï¼‰  \n",
    "\n",
    "**è¼¸å‡º**  \n",
    "- å°‡ base64 è§£ç¢¼ç‚ºäºŒé€²ä½è³‡æ–™ï¼Œå­˜æˆ `.png` æª”  \n",
    "\n",
    "---\n",
    "\n",
    "## 3ï¸âƒ£ èªéŸ³å…§å®¹ç”Ÿæˆ\n",
    "**è¼¸å…¥**  \n",
    "- æœ€æ–°ç”Ÿæˆçš„æ•…äº‹æ–‡å­—  \n",
    "\n",
    "**è™•ç†æµç¨‹**  \n",
    "1. å°‡æ–‡å­—é€å…¥ Langserve æœå‹™  \n",
    "2. æ¥æ”¶å›å‚³çš„èªéŸ³ï¼ˆbase64 æ ¼å¼ï¼‰  \n",
    "\n",
    "**è¼¸å‡º**  \n",
    "- å°‡ base64 è§£ç¢¼ç‚ºäºŒé€²ä½è³‡æ–™ï¼Œå­˜æˆ `.mp3` æˆ– `.wav` æª”  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”„ æµç¨‹åœ–\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    A[æ•…äº‹è‰ç¨¿/èˆŠå…§å®¹ .txt] --> B[é€å…¥ Langserve ç”Ÿæˆæ•…äº‹]\n",
    "    B --> C[æ•…äº‹å…§å®¹ .txt]\n",
    "    C --> D[é€å…¥ Langserve ç”Ÿæˆåœ–ç‰‡ (base64)]\n",
    "    D --> E[è§£ç¢¼ä¸¦å­˜ç‚º .png]\n",
    "    C --> F[é€å…¥ Langserve ç”ŸæˆèªéŸ³ (base64)]\n",
    "    F --> G[è§£ç¢¼ä¸¦å­˜ç‚º .mp3 / .wav]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28811758-cd03-42fc-a88f-1be3988b70fb",
   "metadata": {},
   "source": [
    "## LangServe æœå‹™æ¸¬è©¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c95db07-6153-4ec9-863c-61a0a49a8288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314b6765-7764-46ec-bc16-dfa8b5ed4c86",
   "metadata": {},
   "source": [
    "æ¸¬è©¦æ•…äº‹ç”Ÿæˆæœå‹™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d168449-4550-49b8-acd2-21b4d3009efa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    \"http://localhost:8080/story_telling/invoke\",\n",
    "    json={\"input\":{'scratch': \"Create the first page of the story. This page is about a baby owl capturing a rodent in the night as his dinner\",\n",
    "                   'context': \"\"}\n",
    "         }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2882f0e-1aff-4e8f-b7f1-1c101683aa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "story_json = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6ff1e2-79b3-4b5c-acc7-71fd70025553",
   "metadata": {},
   "outputs": [],
   "source": [
    "story_json['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3654b3-4cf9-4587-a4cd-b023b6e11613",
   "metadata": {},
   "source": [
    "æ¸¬è©¦å½±åƒç”Ÿæˆæœå‹™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174143dd-8f26-486d-9d7e-f22db96d5e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "\n",
    "# image_generation_module = importlib.import_module(\"tutorial.LLM+Langchain.Week-8.logic.image_generation\")\n",
    "# image_create_pipeline = image_generation_module.image_create_pipeline(image_generation_module.system_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f923fa-d406-482b-855b-b0e869afeada",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_image = requests.post(\n",
    "    \"http://localhost:8080/image_generation/invoke\",\n",
    "    json={\"input\": {'story': story_json['output'],\n",
    "                    \"image_io\": []}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5455c3-9853-416b-ac7f-8612e7389375",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_image.json()['output'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b451158-d9cf-46c3-942c-55f70d096b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_image.json()['output']['image_base64'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1011d1-ebd2-47b3-9e7e-a1845ac0fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_image.json()['output']['nl_prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eba4cf-7575-4e8b-a59f-57cde2e59dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "image_base64 = response_image.json()['output']['image_base64']\n",
    "\n",
    "HTML(f'<img src=\"data:image/png;base64,{image_base64}\"/>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30494746-8671-4ece-81d8-83037a8a1075",
   "metadata": {},
   "source": [
    "æ¸¬è©¦ç”Ÿæˆå¾ŒçºŒå¾ŒçºŒçš„æ•…äº‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592e7b42-5213-41be-9ee8-f0bc0d069453",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_next_tory = requests.post(\n",
    "    \"http://localhost:8080/story_telling/invoke\",\n",
    "    json={\"input\":{'scratch': \"Create the next page content following the context\",\n",
    "                   'context': story_json['output']}\n",
    "         }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe8ed59-f76c-4069-913a-8e6d482856ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_chapter = response_next_tory.json()['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee4a7e1-67d7-4492-9f7e-be72eac1e736",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next_chapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57512583-d7ba-4593-9a9a-3eb67d71849b",
   "metadata": {},
   "source": [
    "æ ¹æ“šæ•…äº‹å’Œä¸Šä¸€å¼µåœ–ç‰‡ï¼Œç”¢ç”Ÿå‡ºä¸‹ä¸€å¼µåœ–ç‰‡\n",
    "\n",
    "é€érequestsé€å‡ºbase64 string.\n",
    "\n",
    "æœ¬ä¾†æ˜¯æƒ³è¦é€éimg2imgçš„æ‰‹æ³•æ§åˆ¶åœ–ç‰‡é¢¨æ ¼å’Œå…§å®¹ä¸€è‡´æ€§çš„ï¼Œä½†æ˜¯ç™¼ç¾ä¸ç¢ºå®šæ€§å¾ˆé«˜ï¼Œæ‰€ä»¥æ±ºå®šå¾ä¸Šä¸€å¼µåœ–ç‰‡çš„promptä¸‹æ‰‹ï¼Œçœ‹çœ‹èƒ½ä¸èƒ½èª¿é«˜ä¸€è‡´æ€§ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951b9a93-38e3-46d5-a052-3cc958095de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    \"http://localhost:8080/image_generation/invoke\",\n",
    "    json={\"input\": {'story': next_chapter + f\"\\nPrevious image description:\\n\\n{response_image.json()['output']['nl_prompt']}\",\n",
    "                    # 'image_io': [response_image.json()['output']['image_base64']]\n",
    "                    'image_io': []\n",
    "                   }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0003108d-c97c-4c40-8db9-39594eae610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()['output']['nl_prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769f6c0b-6904-4e79-aa5c-05dffb0fac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_base64 = response.json()['output']['image_base64']\n",
    "\n",
    "HTML(f'<img src=\"data:image/png;base64,{image_base64}\"/>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35819f5-9fa1-4dea-ad1e-1f04a98303bb",
   "metadata": {},
   "source": [
    "æ¸¬è©¦èªéŸ³ç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c3044-274f-4b64-a310-aeb1a37780da",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    \"http://localhost:8080/audio_generation/invoke\",\n",
    "    json={\"input\": {'input': \"How are you doing?\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41234ade-3023-4889-91e1-a9c0230a8452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from IPython.display import Audio\n",
    "\n",
    "audio_bytes = base64.b64decode(response.json()['output'])\n",
    "\n",
    "# åœ¨ notebook ä¸­æ’­æ”¾\n",
    "Audio(audio_bytes, autoplay=True)\n",
    "\n",
    "# with open(\"tutorial/LLM+Langchain/Week-8/test_sample.mp3\", \"wb\") as f:\n",
    "#     f.write(audio_bytes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62454159-038d-4e37-999b-ff81159fb7de",
   "metadata": {},
   "source": [
    "## ç”Ÿæˆå·¥å…·æ¨¡æ¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2768e64a-de75-4196-b7b5-640b189e1669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "from typing import Optional, Any, List, Tuple, Callable\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain.tools import BaseTool\n",
    "from langchain_core.runnables import Runnable\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic import FilePath\n",
    "\n",
    "from initialization import credential_init\n",
    "\n",
    "\n",
    "class ToolTemplate(BaseTool):\n",
    "\n",
    "    \"\"\"\n",
    "    ToolTemplateHTTP: ä¸€å€‹å°ˆé–€ç”¨ä¾†å‘¼å« Langserve REST API çš„ Agent Tool\n",
    "\n",
    "    - ä½¿ç”¨ PydanticOutputParser ä¿è­‰è¼¸å…¥æ ¼å¼æ­£ç¢º\n",
    "    - æ”¯æ´å¤šæ¬„ä½ input/output è™•ç†å™¨\n",
    "    - å° API å‘¼å«åŠ ä¸ŠéŒ¯èª¤è™•ç†\n",
    "    \"\"\"\n",
    "    \n",
    "    runnable: str = Field(..., description='The Langserve endpoint')\n",
    "    name: str\n",
    "    input_parser: PydanticOutputParser\n",
    "    description: str\n",
    "    input_data_processors: Optional[List[Tuple[str, Callable[[Any], Any]]]] = None\n",
    "    output_data_processors: Optional[List[Tuple[Optional[str], Callable[[Any], Any]]]] = None\n",
    "    \n",
    "    @classmethod\n",
    "    def create(cls, runnable: str, name: str, description_template: str,\n",
    "               input_parser: PydanticOutputParser, input_data_processors: Optional=None,\n",
    "               output_data_processors: Optional=None):\n",
    "\n",
    "        \"\"\"å»ºç«‹ Tool å¯¦ä¾‹ï¼Œæœƒè‡ªå‹•æŠŠè¼¸å…¥æ ¼å¼éœ€æ±‚åŠ å…¥ description\"\"\"\n",
    "        \n",
    "        input_format_instruction = input_parser.get_format_instructions()\n",
    "        \n",
    "        description = description_template.format(\n",
    "            input_format_instruction=input_format_instruction\n",
    "        )\n",
    "        \n",
    "        return cls(runnable=runnable, name=name, description=description,\n",
    "                   input_parser=input_parser, input_data_processors=input_data_processors,\n",
    "                   output_data_processors=output_data_processors)\n",
    "    \n",
    "    def _run(self, **input_):\n",
    "\n",
    "        \"\"\"åŸ·è¡Œ Toolï¼ŒåŒæ­¥ç‰ˆæœ¬\"\"\"\n",
    "\n",
    "        print(f\"Call tool: {self.name}\")\n",
    "        \n",
    "        runnable_inputs = input_\n",
    "\n",
    "        # 1. input processorsï¼ˆå‰è™•ç†ï¼‰\n",
    "        if self.input_data_processors:\n",
    "            for field, fn in self.input_data_processors:\n",
    "                if field in runnable_inputs:\n",
    "                    runnable_inputs[field] = fn(runnable_inputs[field])\n",
    "            \n",
    "        # 2. å‘¼å« Langserve REST API\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                str(self.runnable),\n",
    "                json={\"input\": runnable_inputs},\n",
    "                timeout=60,\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Langserve call failed: {e}, inputs={runnable_inputs}\")\n",
    "\n",
    "        if \"output\" not in result:\n",
    "            raise RuntimeError(f\"Invalid response format from Langserve: {result}\")\n",
    "        \n",
    "        output = result['output']\n",
    "\n",
    "        # 4. update the state varaibles:\n",
    "        for key in session_state.keys():\n",
    "            if key in output:\n",
    "                session_state[key] = output[key]\n",
    "        \n",
    "        # 5. output processorsï¼ˆå¾Œè™•ç†ï¼‰\n",
    "        if self.output_data_processors:\n",
    "            for field, fn in self.output_data_processors:\n",
    "                if not field:\n",
    "                    fn(output, runnable_inputs['filename'])\n",
    "                else:\n",
    "                    fn(output[field], runnable_inputs['filename'])\n",
    "                    \n",
    "        # é è¨­å›å‚³ã€Œæª”åã€å¦‚æœæœ‰ filenameï¼Œå¦å‰‡å›å‚³è¼¸å‡ºçš„å­—ä¸²\n",
    "        return runnable_inputs.get(\"filename\", output)\n",
    "\n",
    "    def _arun(self, query: str):\n",
    "\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7a7685-7318-4349-89a4-159e2879d88e",
   "metadata": {},
   "source": [
    "### State Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd71fca-8a1e-4842-acc9-572921972b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_state = {}\n",
    "\n",
    "session_state['nl_prompt'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e253ad6e-6831-4399-be92-59af97e4c3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from textwrap import dedent\n",
    "from typing import List\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class StoryInput(BaseModel):\n",
    "    scratch: str = Field(description=dedent(\"\"\"\\\n",
    "                                            The draft, notes, or rough idea for the current page of the story.\n",
    "                                           ï¼ˆæ•…äº‹ç•¶å‰é é¢çš„è‰ç¨¿ã€ç­†è¨˜æˆ–åˆæ­¥æ§‹æƒ³\n",
    "                                            \"\"\"))\n",
    "    context: List[FilePath] = Field(default_factory=list, description=dedent(\"\"\"\\\n",
    "                                                              A list of previously generated .txt files that contain story content.  \n",
    "                                                              Used to maintain narrative consistency and continuity across images.  \n",
    "                                                              å…ˆå‰ç”Ÿæˆçš„ .txt æª”æ¡ˆæ¸…å–®ï¼Œå…¶ä¸­åŒ…å«æ•…äº‹å…§å®¹ã€‚  \n",
    "                                                              ç”¨æ–¼ä¿æŒå½±åƒç”Ÿæˆéç¨‹ä¸­çš„æ•˜äº‹ä¸€è‡´æ€§èˆ‡é€£è²«æ€§ã€‚\n",
    "                                                              \"\"\"))\n",
    "    filename: str = Field(..., description=dedent(\"\"\"\\\n",
    "                                             The file path where the generated story text will be saved.\n",
    "                                            ï¼ˆç”Ÿæˆçš„æ•…äº‹æ–‡æœ¬å°‡è¢«å„²å­˜çš„æª”æ¡ˆè·¯å¾‘ï¼‰\n",
    "                                             \"\"\"))\n",
    "\n",
    "\n",
    "def export_to_txt(text, filename: Path):\n",
    "\n",
    "    \"\"\"\n",
    "    å°‡æ–‡å­—å„²å­˜ç‚ºæª”æ¡ˆã€‚é€™æ¨£å­agentå°±å¯ä»¥é å‚³éåç¨±ä¾†è¨˜å¾—å‰é¢çš„è¨Šæ¯ï¼Œè€Œä¸æ˜¯ç›´æ¥å°‡æ‰€æœ‰çš„è¨Šæ¯å‚³éçµ¦ä¸‹å»ã€‚\n",
    "    é è‘—çŠ§ç‰²I/Oçš„æ•ˆç‡æ›å–ç¯€çœTokensçš„è²»ç”¨\n",
    "    \"\"\"\n",
    "    print(f\"export file to {filename}\")\n",
    "    \n",
    "    dir_ = Path(filename).parent\n",
    "\n",
    "    if not os.path.isdir(dir_):\n",
    "        os.makedirs(dir_)\n",
    "    \n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text)\n",
    "\n",
    "\n",
    "def read_from_txt(filename) -> str:\n",
    "\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "    return content\n",
    "\n",
    "\n",
    "def read_from_list_of_text(filenames) -> str:\n",
    "\n",
    "    \"\"\"\n",
    "    è®€å–æ‰€æœ‰çš„æª”æ¡ˆï¼Œé‚„ç²å¾—ä¹‹å‰ç”¢ç”Ÿçš„è¨Šæ¯\n",
    "    \"\"\"\n",
    "    \n",
    "    return \"\\n\\n\".join([read_from_txt(f) for f in filenames])\n",
    "\n",
    "\n",
    "story_input_data_processors = [(\"context\", read_from_list_of_text)]\n",
    "\n",
    "# ===================================================================\n",
    "\"\"\"\n",
    "if self.input_data_processors:\n",
    "    for field, fn in self.input_data_processors:\n",
    "        if field in runnable_inputs:\n",
    "            runnable_inputs[field] = fn(runnable_inputs[field])\n",
    "\n",
    "é‚è¼¯:\n",
    "1. æŸ¥è©¢ input_data_processors é€™å€‹ç‰©ä»¶æ˜¯å¦å­˜åœ¨\n",
    "2. è‹¥æ˜¯å­˜åœ¨ï¼Œå°‡Field å’Œ å‡½æ•¸å…¨éƒ¨å±•é–‹ã€‚è‹¥æ˜¯ field å­˜åœ¨æ–¼ input ä¸­ï¼Œä½¿ç”¨å°æ‡‰çš„å‡½æ•¸è™•ç†è©²Field\n",
    "\"\"\"\n",
    "# ===================================================================\n",
    "\n",
    "\n",
    "story_output_data_processors = [(None, export_to_txt)]\n",
    "\n",
    "story_telling_tool = ToolTemplate.create(\n",
    "    runnable=\"http://localhost:8080/story_telling/invoke\",\n",
    "    name=\"Story-generation-tool\",\n",
    "    description_template=dedent(\"\"\"\\\n",
    "                                This tool is designed to generate a story one page at a time.\n",
    "                                Provide a draft or idea for the current page (`scratch`), along with \n",
    "                                the preceding story context stored as .txt files (`context`), \n",
    "                                and specify where the generated text should be saved (`filename`).\n",
    "                                    \n",
    "                                Input format: {input_format_instruction}\n",
    "                                \"\"\"\n",
    "                                ),\n",
    "    input_parser=PydanticOutputParser(pydantic_object=StoryInput),\n",
    "    output_data_processors = story_output_data_processors,\n",
    "    input_data_processors = story_input_data_processors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eacf5e2-200b-4a00-8cbd-202ee93ef350",
   "metadata": {},
   "source": [
    "### å½±åƒç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc7ff16-8827-4c9d-a68c-35681e0e071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageInput(BaseModel):\n",
    "    story: str = Field(description=dedent(\"\"\"\\\n",
    "                                          The file name of the current chapter, whose content will be used to generate the image prompt.  \n",
    "                                          ç•¶å‰ç« ç¯€çš„æª”æ¡ˆåç¨±ï¼Œå…¶å…§å®¹æœƒè¢«ç”¨æ–¼å½±åƒç”Ÿæˆã€‚\n",
    "                                          \"\"\")\n",
    "                      )\n",
    "    # FilePath ensures the input path exists and is a valid file\n",
    "    image_io: List[str] = Field([], description=dedent(\"\"\"\\\n",
    "                                                   Path to the previously generated image.  \n",
    "                                                   Used in img2img generation to maintain visual and texture consistency.  \n",
    "                                                   å…ˆå‰ç”Ÿæˆå½±åƒçš„è·¯å¾‘ã€‚  \n",
    "                                                   åœ¨ img2img ç”Ÿæˆä¸­ç”¨æ–¼ä¿æŒè¦–è¦ºèˆ‡æè³ªçš„ä¸€è‡´æ€§ã€‚\n",
    "                                                   \"\"\")\n",
    "                                    )\n",
    "    # Path allows flexibility: file may not exist yet but must be a valid path object.\n",
    "    filename: str = Field(..., description=dedent(\"\"\"\\\n",
    "                                                  Destination file path where the generated image will be saved.  \n",
    "                                                  ç”Ÿæˆå½±åƒçš„å„²å­˜æª”æ¡ˆè·¯å¾‘ã€‚\n",
    "                                                  \"\"\")\n",
    "                          )\n",
    "\n",
    "\n",
    "def image_to_base64(image_path):\n",
    "    \n",
    "    with Image.open(image_path) as image:\n",
    "        \n",
    "        # Save the Image to a Buffer\n",
    "        buffered = io.BytesIO()\n",
    "        image.save(buffered, format=\"JPEG\")\n",
    "        \n",
    "        # Encode the Image to Base64\n",
    "        image_str = base64.b64encode(buffered.getvalue())\n",
    "    \n",
    "    return image_str.decode('utf-8')\n",
    "\n",
    "\n",
    "def image_to_base64_from_list(filenames: List[str]) -> List[Optional[str]]:\n",
    "\n",
    "    # return [image_to_base64(f) for f in filenames]\n",
    "    return []\n",
    "\n",
    "\n",
    "def export_to_image(content: str, filename: str):\n",
    "\n",
    "    \"\"\"\n",
    "    å°‡base64å­—ä¸²(content)å„²å­˜åœ¨æª”æ¡ˆfilenameä¸­\n",
    "    \"\"\"\n",
    "    \n",
    "    dir_ = Path(filename).parent\n",
    "\n",
    "    if not os.path.isdir(dir_):\n",
    "        os.makedirs(dir_)\n",
    "    \n",
    "    image_bytes = base64.b64decode(content)\n",
    "    \n",
    "    with open(filename, \"wb\") as fh:\n",
    "        fh.write(image_bytes)\n",
    "\n",
    "    \n",
    "def story_adaptation(story: str):\n",
    "\n",
    "    story = read_from_txt(story)\n",
    "    \n",
    "    nl_prompt = session_state['nl_prompt']\n",
    "    \n",
    "    if nl_prompt:\n",
    "        story += f\"\\nPrevious image description:\\n\\n{nl_prompt}\"\n",
    "    \n",
    "    return story\n",
    "    \n",
    "\n",
    "\n",
    "image_output_data_processors = [('image_base64', export_to_image)]\n",
    "\n",
    "image_input_data_processors = [(\"story\", story_adaptation),\n",
    "                                (\"image_io\", image_to_base64_from_list)]\n",
    "\n",
    "image_tool = ToolTemplate.create(\n",
    "    runnable=\"http://localhost:8080/image_generation/invoke\",\n",
    "    name=\"Image-generation-tool\",\n",
    "    description_template=dedent(\"\"\"\\\n",
    "                                This tool is designed to generate an image to the correspoinding narrative.\n",
    "                                Provide a narrative (`story`), along with \n",
    "                                the preceding images stored as .png files (`image_io`), \n",
    "                                and specify where the generated text should be saved (`filename`).\n",
    "                                    \n",
    "                                Input format: {input_format_instruction}\n",
    "                                \"\"\"\n",
    "                                ),\n",
    "    input_parser=PydanticOutputParser(pydantic_object=ImageInput),\n",
    "    output_data_processors = image_output_data_processors,\n",
    "    input_data_processors = image_input_data_processors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eace21c-9917-4f4c-8a3e-7afc8765cc49",
   "metadata": {},
   "source": [
    "### èªéŸ³ç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0fa546-d99b-4ae3-920e-0bf4963a2bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioInput(BaseModel):\n",
    "    input: str = Field(description=dedent(\"\"\"\\\n",
    "                                          The file name of the current chapter, whose content will be used to generate the audio content with text to sound (TTS).  \n",
    "                                          ç•¶å‰ç« ç¯€çš„æª”æ¡ˆåç¨±ï¼Œå…¶å…§å®¹æœƒè¢«ç”¨æ–¼TTSæ–‡å­—è½‰èªéŸ³ã€‚\n",
    "                                          \"\"\")\n",
    "                                    )\n",
    "    # Path allows flexibility: file may not exist yet but must be a valid path object.\n",
    "    filename: str = Field(..., description=dedent(\"\"\"\\\n",
    "                                                  Destination mp3 file path where the generated audio will be saved.  \n",
    "                                                  mp3èªéŸ³æª”çš„å„²å­˜æª”æ¡ˆè·¯å¾‘ã€‚\n",
    "                                                  \"\"\")\n",
    "                         )\n",
    "\n",
    "def export_to_audio(content, filename):\n",
    "\n",
    "    dir_ = Path(filename).parent\n",
    "\n",
    "    if not os.path.isdir(dir_):\n",
    "        os.makedirs(dir_)\n",
    "    \n",
    "    audio_bytes = base64.b64decode(content)\n",
    "    \n",
    "    with open(filename, \"wb\") as fh:\n",
    "        fh.write(audio_bytes)\n",
    "\n",
    "\n",
    "audio_output_data_processors = [(None, export_to_audio)]\n",
    "\n",
    "# ç›´æ¥å€Ÿç”¨ story telling çš„å‡½æ•¸\n",
    "\"\"\"\n",
    "audio_generation ä¸­ ä½¿ç”¨ `input`é€™å€‹è®Šæ•¸\n",
    "\n",
    "def tts_synthesizer(kwargs):\n",
    "    \n",
    "    response = client.audio.speech.create(\n",
    "    model=model,\n",
    "    voice=voice,\n",
    "    input=kwargs['input'],\n",
    "    instructions=instructions)\n",
    "\n",
    "    # Get audio bytes\n",
    "    audio_data = response.read()\n",
    "\n",
    "    # Encode to base64 for JSON serialization\n",
    "    audio_b64 = base64.b64encode(audio_data).decode(\"utf-8\")\n",
    "\n",
    "    return audio_b64\n",
    "\"\"\"\n",
    "audio_input_data_processors = [('input', read_from_txt)]\n",
    "\n",
    "audio_tool = ToolTemplate.create(\n",
    "    runnable=\"http://localhost:8080/audio_generation/invoke\",\n",
    "    name=\"Audio-generation-tool\",\n",
    "    description_template=dedent(\"\"\"\\\n",
    "                                This tool is designed to generate an .mp3 file to a corresponding narrative.\n",
    "                                Provide a narrative (`story`), along with \n",
    "                                and specify where the generated audio should be saved (`filename`).\n",
    "                                    \n",
    "                                Input format: {input_format_instruction}\n",
    "                                \"\"\"\n",
    "                                ),\n",
    "    input_parser = PydanticOutputParser(pydantic_object=AudioInput),\n",
    "    output_data_processors = audio_output_data_processors,\n",
    "    input_data_processors = audio_input_data_processors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8281faeb-b553-47c7-9b03-b7f9b6c671e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "system_prompt = dedent(\"\"\"\\\n",
    "You are a helpful AI assistant responsible for generating high-quality audiobook content page by page.\n",
    "\n",
    "    For each page:\n",
    "\n",
    "    1. Start from the draft text provided by the user.\n",
    "       - Improve, expand, or rewrite it as needed while preserving the storyâ€™s intent and tone.\n",
    "\n",
    "    2. Produce three outputs for that page:\n",
    "       - Text content for the page (TXT).\n",
    "       - A corresponding image (PNG).\n",
    "       - A corresponding audio narration (MP3).\n",
    "\n",
    "    3. You MUST call Story-generation-tool before Audio-generation-tool and Image-generation-tool\n",
    "        \n",
    "    4. Save all three filesâ€”the page text (.txt), the generated image (.png), and the audio narration (.mp3)â€”using the same base filename inside the directory:\n",
    "       tutorial/week_8/story_t est\n",
    "\n",
    "    5. Ensure filename consistency across formats, for example:\n",
    "       - page_01.txt\n",
    "       - page_01.png\n",
    "       - page_01.mp3\n",
    "\n",
    "    Your role is to reliably produce well-written content, matching visuals, and clear audio files for each page in sequence.\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "tools = [story_telling_tool, image_tool, audio_tool]\n",
    "\n",
    "credential_init()\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o\", temperature=0, \n",
    "                  )\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=tools,\n",
    "    system_prompt=system_prompt,\n",
    "    name = \"audio_book_agent\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60f298a-18b7-4b23-96a4-7757b5f1aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "from langchain.messages import HumanMessage\n",
    "\n",
    "session_state = {}\n",
    "\n",
    "session_state['nl_prompt'] = None\n",
    "\n",
    "query = dedent(\"\"\"\n",
    "Create a chapter of a baby owl capturing a rodent in the night as his dinner.\n",
    "\"\"\")\n",
    "\n",
    "agent.invoke({\"messages\": HumanMessage(content=\"Create a chapter of a baby owl capturing a rodent in the night as his dinner.\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7613df9-de89-4546-b738-323a7cc3a9c9",
   "metadata": {},
   "source": [
    "æˆåŠŸçš„ç”Ÿæˆäº†ä¸€é çš„å…§å®¹ï¼ŒAgentå¯ä»¥å¹«æˆ‘å€‘ç”Ÿæˆæ•´å€‹æ•…äº‹å—?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef8eeaa-8886-4e43-962f-73a133bc46bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(\"tutorial/week_8/story_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89f39ff-aeb8-433f-b18b-e20b622e5739",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke({\"messages\": HumanMessage(content=\"Create an 4 pages story for a 4-years-old child. He likes snow owl.\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7929d110-68bd-49e3-bdc7-812dd5bf49f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3683842a-53ee-420d-9423-637ce9cd723a",
   "metadata": {},
   "source": [
    "## ğŸ§ äº’å‹•å¼æœ‰è²æ›¸å…§å®¹ç”Ÿæˆ\n",
    "\n",
    "- ä¸ä¸€å®šéœ€è¦å®Œæ•´çš„ **Agent æ¶æ§‹**ï¼Œå› ç‚ºæµç¨‹çš„æ¯ä¸€æ­¥ï¼ˆæ•…äº‹ â†’ åœ–åƒ â†’ èªéŸ³ï¼‰éƒ½å·²ç¶“æ˜ç¢ºå®šç¾©ï¼Œèƒ½ç”±ä½¿ç”¨è€…ä¸»å‹•è§¸ç™¼ã€‚  \n",
    "- å¯ä»¥ç›´æ¥åŸºæ–¼ **èŠå¤©æ©Ÿå™¨äºº** çš„äº’å‹•å½¢å¼é€²è¡Œï¼Œæ¯æ¬¡è¼¸å…¥ä½¿ç”¨è€…çš„éœ€æ±‚æˆ–æŒ‡ä»¤å¾Œï¼Œç³»çµ±ä¾ç…§æŒ‡å®šæ­¥é©Ÿç”Ÿæˆå°æ‡‰å…§å®¹ã€‚  \n",
    "- ä½¿ç”¨è€…å¯ä»¥åœ¨æ•…äº‹ç”Ÿæˆéç¨‹ä¸­å³æ™‚èª¿æ•´æ–¹å‘ï¼Œä¾‹å¦‚æŒ‡å®šè§’è‰²ã€æƒ…ç¯€èµ°å‘æˆ–èªæ°£ï¼Œæå‡ **å®¢è£½åŒ–é«”é©—**ã€‚  \n",
    "- é€™ç¨®äº’å‹•æ–¹å¼éå¸¸é©åˆ **èªè¨€å­¸ç¿’** å ´æ™¯ï¼š  \n",
    "  - å­¸ç¿’è€…èƒ½ä¸€é‚Šé–±è®€æ•…äº‹ã€ä¸€é‚Šè½æœ‰è²è¼¸å‡º  \n",
    "  - å¯å³æ™‚ä¿®æ”¹æ•…äº‹æƒ…ç¯€ï¼Œç”¢ç”Ÿæ›´è²¼è¿‘å­¸ç¿’éœ€æ±‚çš„å…§å®¹  \n",
    "  - æ­é…åœ–ç‰‡èˆ‡èªéŸ³ï¼Œæå‡æ²‰æµ¸å¼å­¸ç¿’æ•ˆæœ  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adda8172-d8ae-4bf0-80be-14810309324a",
   "metadata": {},
   "source": [
    "# ğŸ§© LangGraph æ¡†æ¶èˆ‡è¨ˆåŠƒ-è¡Œå‹•ä»£ç†äººç°¡ä»‹\n",
    "\n",
    "## ä¸€ã€LangGraph æ˜¯ä»€éº¼ï¼Ÿ\n",
    "\n",
    "**LangGraph** æ˜¯ä¸€å€‹å°ˆé–€ç‚ºæ§‹å»º **å¤šæ™ºèƒ½é«”ç³»çµ±ï¼ˆMulti-Agent Systemsï¼‰** è€Œè¨­è¨ˆçš„æ¡†æ¶ï¼Œæä¾›äº†çµæ§‹åŒ–çš„æ–¹å¼ä¾†è¨­è¨ˆã€å”èª¿èˆ‡ç®¡ç†å¤šå€‹æ™ºèƒ½é«”ä¹‹é–“çš„äº’å‹•ã€‚  \n",
    "å®ƒå»ºç«‹åœ¨ **LangChain** çš„æ¦‚å¿µä¹‹ä¸Šï¼Œä¸¦å¼•å…¥äº†ã€Œåœ–ï¼ˆGraphï¼‰ã€çš„æ€ç¶­æ¨¡å‹ï¼š  \n",
    "æ¯å€‹æ™ºèƒ½é«”ï¼ˆAgentï¼‰è¢«è¦–ç‚ºåœ–ä¸­çš„ä¸€å€‹ç¯€é»ï¼ˆNodeï¼‰ï¼Œç¯€é»ä¹‹é–“çš„é‚Šï¼ˆEdgeï¼‰ä»£è¡¨ä»»å‹™æµæˆ–è³‡è¨Šäº¤æ›çš„é—œä¿‚ã€‚\n",
    "\n",
    "### ğŸŒŸ LangGraph çš„æ ¸å¿ƒç‰¹é»\n",
    "\n",
    "- ğŸ”— **ç¯€é»å°å‘è¨­è¨ˆ**ï¼šæ¯å€‹ç¯€é»å¯ä»£è¡¨ä¸€å€‹æ™ºèƒ½é«”ã€å·¥å…·æˆ–æ±ºç­–æ¨¡çµ„ã€‚  \n",
    "- ğŸ”„ **éˆæ´»çš„ä»»å‹™æµç¨‹**ï¼šæ”¯æ´æœ‰æ¢ä»¶çš„ä»»å‹™è½‰ç§»ï¼ˆä¾‹å¦‚æ ¹æ“šä¸Šä¸‹æ–‡æˆ–ä»»å‹™ç‹€æ…‹å‹•æ…‹é¸æ“‡ä¸åŒæ™ºèƒ½é«”ï¼‰ã€‚  \n",
    "- ğŸ§  **æ¨¡å‹äº’è£œæ€§**ï¼šå¯åŒæ™‚ä½¿ç”¨å¤šç¨®å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMsï¼‰æˆ–ä¸åŒçš„å¤–éƒ¨å·¥å…·ã€‚  \n",
    "- ğŸ“Š **å¯è¦–åŒ–å·¥ä½œæµ**ï¼šé–‹ç™¼è€…å¯ä»¥ç›´è§€åœ°è§€å¯Ÿæ™ºèƒ½é«”ä¹‹é–“çš„äº’å‹•èˆ‡ä»»å‹™æµå‘ã€‚  \n",
    "- ğŸ§© **æœ‰ç‹€æ…‹çš„ä»»å‹™æ§åˆ¶**ï¼šæ”¯æ´ä»»å‹™å›æº¯ã€é‡è©¦èˆ‡æµç¨‹ä¸­æ–·æ¢å¾©ç­‰åŠŸèƒ½ã€‚  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## äºŒã€LangChain vs. LangGraph\n",
    "\n",
    "åœ¨ç¾ä»£ LLM æ‡‰ç”¨é–‹ç™¼ä¸­ï¼Œ**LangChain** å’Œ **LangGraph** æ˜¯å…©å€‹å¸¸è¢«æåŠçš„æ¡†æ¶ã€‚  \n",
    "å®ƒå€‘çš†æ—¨åœ¨ç°¡åŒ–èˆ‡å¤§å‹èªè¨€æ¨¡å‹çš„æ•´åˆæµç¨‹ï¼Œä½†åœ¨è¨­è¨ˆç†å¿µèˆ‡ä½¿ç”¨å ´æ™¯ä¸Šæœ‰æ‰€ä¸åŒã€‚\n",
    "\n",
    "| ç‰¹é» | LangChain | LangGraph |\n",
    "|------|-----------|-----------|\n",
    "| æ¶æ§‹é¢¨æ ¼ | å‡½å¼å°å‘ï¼ˆFunction-basedï¼‰ | åœ–å½¢å°å‘ï¼ˆGraph-basedï¼‰ |\n",
    "| æ ¸å¿ƒç”¨é€” | çµ„åˆä¸åŒçš„å·¥å…·èˆ‡éˆï¼ˆChainsï¼‰ä»¥è™•ç†ä»»å‹™ | å®šç¾©ç‹€æ…‹è½‰æ›èˆ‡æµç¨‹æ§åˆ¶çš„ç‹€æ…‹æ©Ÿ |\n",
    "| é©åˆå ´æ™¯ | ç·šæ€§æµç¨‹ã€å¤šå·¥å…·ä¸²æ¥ã€å–®ä¸€ä»»å‹™ä»£ç†äºº | æœ‰ç‹€æ…‹çš„å·¥ä½œæµç¨‹ã€å¤šæ­¥é©Ÿæ±ºç­–ã€å‹•æ…‹æµç¨‹åˆ‡æ› |\n",
    "| æ§åˆ¶æµç¨‹èƒ½åŠ› | è¼ƒå¼±ï¼Œéœ€é€éç¨‹å¼é‚è¼¯æ§åˆ¶ | è¼ƒå¼·ï¼Œå…§å»ºç‹€æ…‹ç®¡ç†èˆ‡å‹•æ…‹ç¯€é»åˆ‡æ› |\n",
    "| æ˜“å­¸ç¨‹åº¦ | ç›¸å°å®¹æ˜“ä¸Šæ‰‹ | åˆæœŸéœ€ç†è§£ç‹€æ…‹æ©Ÿèˆ‡åœ–çµæ§‹æ¦‚å¿µ |\n",
    "| é€šç”¨æ€§ | æ¨¡çµ„å¤šã€é€šç”¨æ€§å¼· | æ›´é©åˆè¤‡é›œèˆ‡é•·æœŸä»»å‹™ç®¡ç† |\n",
    "\n",
    "> ğŸ’¡ **ç°¡è€Œè¨€ä¹‹**ï¼š  \n",
    "> - **LangChain** åƒæ˜¯ä¸€å€‹ã€Œç©æœ¨ç®±ã€ï¼Œæä¾›å„ç¨®æ¨¡çµ„ä¾›ä½ è‡ªç”±çµ„åˆã€‚  \n",
    "> - **LangGraph** å‰‡åƒæ˜¯ä¸€å€‹ã€Œæµç¨‹ç·¨è¼¯å™¨ã€ï¼Œè®“ä½ æ¸…æ¥šå®šç¾©ä»»å‹™ç¯€é»èˆ‡æµç¨‹é‚è¼¯ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ä¸‰ã€ç‚ºä»€éº¼é¸æ“‡ LangGraphï¼Ÿ\n",
    "\n",
    "LangGraph å»ºç«‹åœ¨ LangChain çš„åŸºç¤ä¸Šï¼Œä½†æä¾›äº†æ›´æ˜ç¢ºçš„ **æµç¨‹æ§åˆ¶èƒ½åŠ›**ã€‚  \n",
    "é€éã€Œæœ‰å‘åœ–ï¼ˆDirected Graphï¼‰ã€å®šç¾©ç¯€é»ï¼ˆNodeï¼‰èˆ‡ç‹€æ…‹è½‰ç§»ï¼ˆEdgeï¼‰ï¼Œé–‹ç™¼è€…å¯ä»¥è¼•é¬†è¨­è¨ˆå‡ºå…·å‚™ä»¥ä¸‹ç‰¹æ€§çš„ LLM æ‡‰ç”¨ï¼š\n",
    "\n",
    "- âœ… **è¨˜æ†¶ç‹€æ…‹ï¼ˆStatefulï¼‰**ï¼šèƒ½ä¿å­˜ä¸Šä¸‹æ–‡èˆ‡ä»»å‹™é€²åº¦ã€‚  \n",
    "- ğŸ” **å¯å›æº¯ï¼ˆReversibleï¼‰**ï¼šæ”¯æ´ä»»å‹™å¤±æ•—æ™‚çš„é‡è©¦èˆ‡å›æº¯ã€‚  \n",
    "- âš¡ **å‹•æ…‹æµç¨‹ï¼ˆDynamic Flowï¼‰**ï¼šæ ¹æ“šçµæœæˆ–ä¸Šä¸‹æ–‡å‹•æ…‹åˆ‡æ›ä¸‹ä¸€æ­¥ç¯€é»ã€‚  \n",
    "- ğŸ§© **å¤šæ™ºèƒ½é«”å”ä½œï¼ˆMulti-Agent Coordinationï¼‰**ï¼šæ”¯æ´å¤šå€‹æ™ºèƒ½é«”å”åŒå·¥ä½œã€‚  \n",
    "\n",
    "é€™ä½¿å¾— LangGraph ç‰¹åˆ¥é©åˆéœ€è¦é•·æœŸè¦åŠƒã€æ±ºç­–ã€ä»¥åŠå¤šéšæ®µä»»å‹™çš„æ‡‰ç”¨å ´æ™¯ï¼Œä¾‹å¦‚ï¼š\n",
    "- AI åŠ©ç†å·¥ä½œæµç¨‹ç®¡ç†  \n",
    "- è‡ªå‹•åŒ–æ±ºç­–ç³»çµ±  \n",
    "- è¤‡é›œä»»å‹™è¦åŠƒèˆ‡åŸ·è¡Œï¼ˆå¦‚ç§‘ç ”åŠ©ç†ã€å°ˆæ¡ˆç®¡ç†ä»£ç†äººï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "## å››ã€è¨ˆåŠƒ-è¡Œå‹•ä»£ç†äººï¼ˆPlan-Action Agentï¼‰\n",
    "\n",
    "### ğŸ” ä»€éº¼æ˜¯è¨ˆåŠƒ-è¡Œå‹•ä»£ç†äººï¼Ÿ\n",
    "\n",
    "è¨ˆåŠƒ-è¡Œå‹•ä»£ç†äººæ˜¯ä¸€ç¨®åŸºæ–¼ã€Œ**è¨ˆåŠƒï¼ˆPlanï¼‰** â†’ **è¡Œå‹•ï¼ˆActionï¼‰** â†’ **åé¥‹ï¼ˆFeedbackï¼‰**ã€è¿­ä»£å¾ªç’°çš„æ™ºèƒ½é«”ã€‚  \n",
    "å®ƒæœƒæ ¹æ“šç’°å¢ƒç‹€æ³ç”Ÿæˆè¨ˆåŠƒï¼Œä¸¦é€æ­¥åŸ·è¡Œèˆ‡èª¿æ•´ï¼Œç›´åˆ°é”æˆç›®æ¨™ã€‚\n",
    "\n",
    "å…¸å‹çš„å·¥ä½œæµç¨‹å¦‚ä¸‹ï¼š\n",
    "\n",
    "1. **è§€å¯Ÿç’°å¢ƒ**ï¼šæ”¶é›†ç•¶å‰ç’°å¢ƒç‹€æ…‹æˆ–ä¸Šä¸‹æ–‡ã€‚  \n",
    "2. **è¨ˆåŠƒç”Ÿæˆ**ï¼šæ ¹æ“šè§€å¯Ÿçµæœç”Ÿæˆä¸€ç³»åˆ—è¡Œå‹•è¨ˆåŠƒã€‚  \n",
    "3. **è¡Œå‹•åŸ·è¡Œ**ï¼šé€æ­¥åŸ·è¡Œæ¯å€‹è¨ˆåŠƒæ­¥é©Ÿã€‚  \n",
    "4. **åé¥‹èˆ‡èª¿æ•´**ï¼šæ ¹æ“šåŸ·è¡Œçµæœèˆ‡ç’°å¢ƒè®ŠåŒ–èª¿æ•´è¨ˆåŠƒï¼Œç¢ºä¿æœ€çµ‚ç›®æ¨™çš„é”æˆã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## äº”ã€åœ¨ LangGraph ä¸­å¯¦ç¾è¨ˆåŠƒ-è¡Œå‹•ä»£ç†äºº\n",
    "\n",
    "LangGraph ç‚ºæ§‹å»ºé€™é¡ä»£ç†äººæä¾›äº†ç†æƒ³çš„çµæ§‹ã€‚  \n",
    "åœ¨ LangGraph ä¸­ï¼Œæˆ‘å€‘å¯ä»¥é€éã€Œç¯€é»ã€å®šç¾©ä¸åŒçš„æ™ºèƒ½é«”è§’è‰²ï¼ˆå¦‚è¨ˆåŠƒç”Ÿæˆå™¨ã€åŸ·è¡Œè€…ã€ç›£ç£è€…ï¼‰ï¼Œä¸¦ä»¥ã€Œé‚Šã€å®šç¾©ä»–å€‘ä¹‹é–“çš„äº’å‹•æµç¨‹ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼š\n",
    "\n",
    "[è§€å¯Ÿç¯€é»] â†’ [è¨ˆåŠƒç”Ÿæˆç¯€é»] â†’ [è¡Œå‹•åŸ·è¡Œç¯€é»] â†’ [åé¥‹ç¯€é»]\n",
    "\n",
    "â†˜â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â†—ï¼ˆæ ¹æ“šåé¥‹å‹•æ…‹å›åˆ°è¨ˆåŠƒç”Ÿæˆï¼‰\n",
    "\n",
    "\n",
    "é€™æ¨£çš„è¨­è¨ˆå…è¨±ä»£ç†äººåœ¨ä»»å‹™åŸ·è¡Œä¸­é€²è¡Œï¼š\n",
    "- ä»»å‹™é‡è©¦ï¼ˆretryï¼‰  \n",
    "- å‹•æ…‹æ±ºç­–ï¼ˆdynamic routingï¼‰  \n",
    "- è‡ªé©æ‡‰ç­–ç•¥èª¿æ•´ï¼ˆadaptive planningï¼‰  \n",
    "\n",
    "---\n",
    "\n",
    "## å…­ã€æ¥ä¸‹ä¾†çš„å…§å®¹\n",
    "\n",
    "æ¥ä¸‹ä¾†ï¼Œæˆ‘å€‘å°‡é€éå¯¦ä½œä¸€å€‹ **è¨ˆåŠƒ-è¡Œå‹•ä»£ç†äººï¼ˆPlan-Action Agentï¼‰** çš„ç¯„ä¾‹ï¼Œ  \n",
    "å±•ç¤ºå¦‚ä½•ä½¿ç”¨ LangGraph ä¾†ï¼š\n",
    "\n",
    "- å®šç¾©å¤šå€‹æ™ºèƒ½é«”ç¯€é»  \n",
    "- è¨­è¨ˆä»»å‹™æµç¨‹èˆ‡æ¢ä»¶è½‰ç§»  \n",
    "- ç®¡ç†ç‹€æ…‹èˆ‡ä»»å‹™å›æº¯  \n",
    "\n",
    "é€éé€™å€‹å¯¦ä½œï¼Œä½ å°‡èƒ½ç†è§£ LangGraph åœ¨ **å¤šæ™ºèƒ½é«”å”ä½œ**ã€**å‹•æ…‹æ±ºç­–** èˆ‡ **æœ‰ç‹€æ…‹ä»»å‹™æ§åˆ¶** æ–¹é¢çš„å¼·å¤§èƒ½åŠ›ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1856cc-79de-4822-b617-42d6c1b16df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../\")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "from initialization import credential_init\n",
    "\n",
    "credential_init()\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "                   model_name=\"gpt-4o-mini\", \n",
    "                   temperature=0\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931bc721-634e-410f-95f2-6efe391d2b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, Tuple, Union, Optional\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# Stateï¼ŒæŠŠé€™å€‹æƒ³åƒæˆæ˜¯Agentçš„çŸ­æœŸè¨˜æ†¶\n",
    "class PlanExecute(TypedDict):\n",
    "    input: str\n",
    "    plan: List[str]\n",
    "    past_steps: List[Tuple]\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3a9d27-84a2-4237-b99b-883458533bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Literal, Union\n",
    "from textwrap import dedent\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate\n",
    "\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    \"\"\"\n",
    "    Plan to follow in the future\n",
    "    \"\"\"\n",
    "    type: Literal['plan'] = 'plan'\n",
    "    steps: List[str] = Field(description=\"different steps to follow, should be in sorted order\")\n",
    "\n",
    "\n",
    "planner_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\n",
    "        dedent(\"\"\"\\\n",
    "        For the given objective, come up with a simple step by step plan.\n",
    "        This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps.\n",
    "        The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
    "        \"\"\")),\n",
    "        (\"placeholder\", \"{messages}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_planner = model.with_structured_output(Plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899b7f45-cc73-419d-9758-3d7c062029e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = planner_prompt|model_planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92635c74-5dfa-48ed-a421-66da1310d7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "planner.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\"user\", \"What is the hometown of the current Australia open winner\")\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db72109-c583-4f59-8db8-44118c619f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Response(BaseModel):\n",
    "    \"\"\"Response to user.\"\"\"\n",
    "    type: Literal['response'] = 'response'\n",
    "    response: str\n",
    "\n",
    "\n",
    "class Act(BaseModel):\n",
    "    \"\"\"Action to perform.\"\"\"\n",
    "\n",
    "    action: Union[Response, Plan] = Field(\n",
    "        description=dedent(\"\"\"\\\n",
    "        Action to perform. If you want to respond to user, use `response`.\n",
    "        If you need to further use tools to get the answer, use `plan`.\n",
    "        \"\"\"\n",
    "    )\n",
    "    )\n",
    "\n",
    "# inpput: æœ€çµ‚çš„ç›®æ¨™ (goal)\n",
    "# plan: ç›®å‰éœ€è¦å®Œæˆçš„ä»»å‹™ (task)\n",
    "# past_steps: éå»å·²ç¶“å®Œæˆçš„ä»»å‹™\n",
    "\n",
    "replanner_prompt = ChatPromptTemplate.from_template(\n",
    "    dedent(\"\"\"For the given objective, come up with a simple step by step plan. \\\n",
    "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
    "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
    "\n",
    "Your objective was this:\n",
    "{input}\n",
    "\n",
    "Your original plan was this:\n",
    "{plan}\n",
    "\n",
    "You have currently done the follow steps:\n",
    "{past_steps}\n",
    "\n",
    "Update your plan accordingly. If no more steps are needed and you can return to the user, then respond with that. Otherwise, fill out the plan. Only add steps to the plan that still NEED to be done. Do not return previously done steps as part of the plan.\"\"\"\n",
    "))\n",
    "\n",
    "model_act = model.with_structured_output(Act)\n",
    "\n",
    "replanner = replanner_prompt | model_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484482cd-3357-4f15-9c23-0225528edcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "replanner.invoke({\"plan\": \"Identify the current Australian Open winner for the most recent tournament.\",\n",
    "                  \"past_steps\": [],\n",
    "                  \"input\": \"What is the hometown of the current Australia open winner\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaecd86e-f890-45ac-9648-c182d650ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f86669-8576-407b-8bb7-4030e8087ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "from langchain.tools import BaseTool\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "client = OpenAI()\n",
    "async_client = AsyncOpenAI()\n",
    "\n",
    "\n",
    "class Inputs(BaseModel):\n",
    "    query: str = Field(description=\"User query\")\n",
    "    country_code: str = Field(description=\"ISO 3166-1 alpha-2 code of the user language\")\n",
    "\n",
    "\n",
    "class SearchTool(BaseTool):\n",
    "\n",
    "    input_output_parser: PydanticOutputParser = PydanticOutputParser(pydantic_object=Inputs)\n",
    "    input_format_instructions: str = input_output_parser.get_format_instructions()\n",
    "    \n",
    "    name:str = \"websearch-tool\"\n",
    "    description_template:str = dedent(\"\"\"\n",
    "    Currently it is 2026.    \n",
    "    Use this tool to collect information from the internet, when you are not sure you know the answer.\n",
    "    The input contains the user's question `query` and the ISO 3166-1 alpha-2 `country_code` inferred from the user's language.\n",
    "    input format instructions: {input_format_instructions}\n",
    "    \"\"\")\n",
    "\n",
    "    description: str = description_template.format(input_format_instructions=input_format_instructions)\n",
    "\n",
    "    def _build_messages_and_opts(self, input_):\n",
    "        \"\"\"Shared logic for sync + async\"\"\"\n",
    "        \n",
    "        query = input_[\"query\"]\n",
    "        country_code = input_[\"country_code\"]\n",
    "\n",
    "        tool = {\"type\": \"web_search\",\n",
    "                         \"user_location\":{\n",
    "                             \"type\": \"approximate\",\n",
    "                             \"country\": country_code,\n",
    "                         },\n",
    "                        \"search_context_size\": \"medium\"\n",
    "                        }\n",
    "        return query, tool\n",
    "        \n",
    "    def _run(self, **input_):\n",
    "        \n",
    "        query, tool = self._build_messages_and_opts(input_)\n",
    "\n",
    "        response = client.responses.create(\n",
    "                    model=\"gpt-4o-mini\",\n",
    "                    tools=[tool],\n",
    "                    tool_choice=\"auto\",\n",
    "                    input=query)\n",
    "\n",
    "        \n",
    "        return response.output_text\n",
    "    \n",
    "    async def _arun(self, **input_):\n",
    "        \n",
    "        query, tool = self._build_messages_and_opts(input_)\n",
    "\n",
    "        response = await async_client.responses.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            tools=[tool],\n",
    "            tool_choice=\"auto\",\n",
    "            input=query\n",
    "        )\n",
    "\n",
    "        return response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc969039-04eb-4b23-8b06-a149ad764a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(name='websearch_agent',\n",
    "                     model='gpt-4o-mini',\n",
    "                     tools=[SearchTool()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e7f912-1194-4f19-9520-def70d4aa36c",
   "metadata": {},
   "source": [
    "### Define the functionalities of the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a8892-d9a6-429f-9f39-4023457db696",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def execute_step(state: PlanExecute):\n",
    "    \"\"\"\n",
    "    æ­¤æ–¹æ³•è² è²¬åŸ·è¡Œç›®å‰è¨ˆåŠƒï¼ˆplanï¼‰ä¸­çš„ç¬¬ä¸€å€‹æ­¥é©Ÿã€‚\n",
    "    åœ¨ LangGraph ç¯€é»ä¸­ï¼Œå®ƒé€šå¸¸ä½œç‚ºã€Œä»»å‹™åŸ·è¡Œç¯€é»ã€ï¼Œè² è²¬æ ¹æ“šè¨ˆåŠƒæŒ‡ä»¤å‘¼å«ä»£ç†æ¨¡å‹ï¼ˆagentï¼‰ä¾†åŸ·è¡Œå…·é«”ä»»å‹™ï¼Œä¸¦å°‡åŸ·è¡Œçµæœè¨˜éŒ„åˆ°ç‹€æ…‹ï¼ˆstateï¼‰ä¸­ã€‚\n",
    "    \n",
    "    ä¸»è¦é‚è¼¯ï¼š\n",
    "    \n",
    "    å¾ state è®€å–ç›®å‰çš„è¨ˆåŠƒ (plan)ã€‚\n",
    "    \n",
    "    ä»¥ç·¨è™Ÿæ–¹å¼å°‡æ•´å€‹è¨ˆåŠƒæ ¼å¼åŒ–æˆå¯è®€å­—ä¸²ã€‚\n",
    "    \n",
    "    å–å‡ºè¨ˆåŠƒä¸­çš„ç¬¬ä¸€å€‹æ­¥é©Ÿä½œç‚ºè¦åŸ·è¡Œçš„ä»»å‹™ã€‚\n",
    "    \n",
    "    å‘¼å« agent.ainvoke()ï¼Œè®“æ™ºèƒ½ä»£ç†åŸ·è¡Œè©²ä»»å‹™ã€‚\n",
    "    \n",
    "    å°‡åŸ·è¡Œçµæœèˆ‡ä»»å‹™åç¨±ä»¥ tuple å½¢å¼å­˜å…¥ past_stepsã€‚\n",
    "    \n",
    "    è‹¥ state ä¸­å°šç„¡éå»ç´€éŒ„ï¼Œå»ºç«‹æ–°çš„ past_stepsï¼›å¦å‰‡å°‡æ–°çµæœé™„åŠ åˆ°ç¾æœ‰ç´€éŒ„ä¸­ã€‚\n",
    "    \n",
    "    åƒæ•¸ï¼š\n",
    "    \n",
    "    state (PlanExecute)ï¼šåŒ…å«è¨ˆåŠƒã€éå¾€æ­¥é©Ÿèˆ‡ç•¶å‰è¼¸å…¥çš„åŸ·è¡Œç‹€æ…‹ã€‚\n",
    "    \n",
    "    å›å‚³ï¼š\n",
    "    \n",
    "    dictï¼šåŒ…å«æ›´æ–°å¾Œçš„ past_stepsï¼Œå³åŸ·è¡Œä»»å‹™çš„æ­·å²ç´€éŒ„ã€‚\n",
    "    \n",
    "    æ‡‰ç”¨æƒ…å¢ƒï¼š\n",
    "    æ­¤ç¯€é»å¯ç”¨æ–¼å¤šæ­¥é©Ÿä»»å‹™åŸ·è¡Œæµç¨‹ï¼Œä¾‹å¦‚ï¼š\n",
    "    \n",
    "    æ ¹æ“šè¨ˆåŠƒé€æ­¥åŸ·è¡Œå‹•ä½œï¼ˆå¦‚è³‡æ–™è’é›†ã€åˆ†æã€å ±å‘Šæ’°å¯«ç­‰ï¼‰ã€‚\n",
    "    \n",
    "    åœ¨å¤šä»£ç†ç³»çµ±ä¸­ç”±ç‰¹å®š agent åŸ·è¡Œåˆ†é…ä»»å‹™ã€‚\n",
    "    \"\"\"\n",
    "    plan = state[\"plan\"]\n",
    "    plan_str = \"\\n\".join(f\"{i + 1}. {step}\" for i, step in enumerate(plan))\n",
    "    task = plan[0]\n",
    "    task_formatted = f\"\"\"For the following plan:{plan_str}\\n\\nYou are tasked with executing step {1}, {task}.\"\"\"\n",
    "    \n",
    "    agent_response = await agent.ainvoke(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": task_formatted}]}\n",
    "    )\n",
    "    \n",
    "    current_step = [(task, agent_response['messages'][-1].content)]\n",
    "\n",
    "    # push the result to state\n",
    "    if \"past_steps\" not in state:\n",
    "        return {\"past_steps\": current_step}\n",
    "    else:\n",
    "        return {\"past_steps\": state[\"past_steps\"] + current_step}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1399c-c278-4e57-92eb-a628e8a31e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def plan_step(state: PlanExecute):\n",
    "    \"\"\"\n",
    "    æ­¤æ–¹æ³•è² è²¬æ ¹æ“šä½¿ç”¨è€…è¼¸å…¥å»ºç«‹å®Œæ•´çš„è¨ˆåŠƒï¼ˆplanï¼‰ã€‚\n",
    "    åœ¨ LangGraph ç¯€é»ä¸­ï¼Œå®ƒé€šå¸¸ä½œç‚ºã€Œè¨ˆåŠƒç”Ÿæˆç¯€é»ã€ï¼Œè®“è¦åŠƒå™¨ï¼ˆplannerï¼‰æ ¹æ“šä½¿ç”¨è€…æŒ‡ä»¤ç”¢ç”Ÿä¸€ç³»åˆ—å¯åŸ·è¡Œæ­¥é©Ÿã€‚\n",
    "    \n",
    "    ä¸»è¦é‚è¼¯ï¼š\n",
    "    \n",
    "    å‘¼å« planner.ainvoke()ï¼Œå°‡ä½¿ç”¨è€…è¼¸å…¥çš„è¨Šæ¯å‚³å…¥è¦åŠƒæ¨¡å‹ã€‚\n",
    "    \n",
    "    æ¥æ”¶è¦åŠƒå™¨è¼¸å‡ºçš„æ­¥é©Ÿï¼ˆplan.stepsï¼‰ã€‚\n",
    "    \n",
    "    å°‡é€™äº›æ­¥é©Ÿå­˜å…¥ stateï¼Œä»¥ä¾¿å¾ŒçºŒç¯€é»åŸ·è¡Œã€‚\n",
    "    \n",
    "    åƒæ•¸ï¼š\n",
    "    \n",
    "    state (PlanExecute)ï¼šåŒ…å«ä½¿ç”¨è€…è¼¸å…¥çš„åŸ·è¡Œç‹€æ…‹ï¼ˆstate[\"input\"] ç‚ºç”¨æˆ¶çš„ä¸»è¦æŒ‡ä»¤ï¼‰ã€‚\n",
    "    \n",
    "    å›å‚³ï¼š\n",
    "    \n",
    "    dictï¼šåŒ…å«ä¸€å€‹éµå€¼å° { \"plan\": plan.steps }ï¼Œå³æ¨¡å‹ç”Ÿæˆçš„ä»»å‹™æ­¥é©Ÿæ¸…å–®ã€‚\n",
    "    \n",
    "    æ‡‰ç”¨æƒ…å¢ƒï¼š\n",
    "    æ­¤ç¯€é»å¯ç”¨æ–¼ä»»å‹™å°å‘ç³»çµ±çš„é–‹é ­éšæ®µï¼Œä¾‹å¦‚ï¼š\n",
    "    \n",
    "    å°‡ã€Œæ’°å¯«å¸‚å ´å ±å‘Šã€åˆ†è§£ç‚ºã€Œè³‡æ–™è’é›† â†’ æ•´ç† â†’ åˆ†æ â†’ æ’°å¯«ã€ã€‚\n",
    "    \n",
    "    åœ¨å¤šéšæ®µæ¨ç†æˆ–è‡ªå‹•åŒ–ä»»å‹™ä¸­ç”Ÿæˆå…·é«”å·¥ä½œè¨ˆåŠƒã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    # push the result to state\n",
    "    plan = await planner.ainvoke({\"messages\": [(\"user\", state[\"input\"])]})\n",
    "    return {\"plan\": plan.steps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597949a2-3dd0-473d-b33b-9e0556bad85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def replan_step(state: PlanExecute):\n",
    "\n",
    "    \"\"\"\n",
    "    æ­¤æ–¹æ³•è² è²¬åœ¨ä»»å‹™åŸ·è¡Œéç¨‹ä¸­é€²è¡Œå‹•æ…‹é‡æ–°è¦åŠƒï¼ˆReplanningï¼‰ã€‚\n",
    "    ç•¶ä»£ç†åŸ·è¡Œä¸­é‡åˆ°å•é¡Œã€æ¢ä»¶æ”¹è®Šæˆ–4ä»»å‹™æœªå®Œæˆæ™‚ï¼Œè©²ç¯€é»å¯å‘¼å«ã€Œå†è¦åŠƒå™¨ã€ï¼ˆreplannerï¼‰ç”Ÿæˆæ–°çš„è¨ˆåŠƒæˆ–ç›´æ¥è¼¸å‡ºæœ€çµ‚å›æ‡‰ã€‚\n",
    "    \n",
    "    ä¸»è¦é‚è¼¯ï¼š\n",
    "    \n",
    "    å‘¼å« replanner.ainvoke()ï¼Œå°‡ç•¶å‰åŸ·è¡Œç‹€æ…‹ä½œç‚ºè¼¸å…¥ã€‚\n",
    "    \n",
    "    è‹¥è¿”å›çµæœåŒ…å« Response é¡å‹çš„å‹•ä½œï¼Œè¡¨ç¤ºå¯ç›´æ¥è¼¸å‡ºæœ€çµ‚å›è¦†ã€‚\n",
    "    \n",
    "    è‹¥çµæœç‚ºæ–°çš„è¨ˆåŠƒæ­¥é©Ÿï¼Œå‰‡æ›´æ–° planã€‚\n",
    "    \n",
    "    è‹¥ç„¡æ–°æ­¥é©Ÿå¯åŸ·è¡Œï¼Œå‰‡ä½¿ç”¨æœ€å¾Œä¸€æ¬¡åŸ·è¡Œçš„çµæœä½œç‚ºå›æ‡‰ã€‚\n",
    "    \n",
    "    åƒæ•¸ï¼š\n",
    "    \n",
    "    state (PlanExecute)ï¼šåŒ…å«ç›®å‰çš„åŸ·è¡Œç‹€æ…‹ã€æ­·å²æ­¥é©Ÿèˆ‡å·²çŸ¥è¨ˆåŠƒã€‚\n",
    "    \n",
    "    å›å‚³ï¼š\n",
    "    \n",
    "    dictï¼šåŒ…å«æ–°çš„ plan æˆ–æœ€çµ‚ responseã€‚\n",
    "    \n",
    "    æ‡‰ç”¨æƒ…å¢ƒï¼š\n",
    "    æ­¤ç¯€é»ç”¨æ–¼ï¼š\n",
    "    \n",
    "    åŸ·è¡Œä»»å‹™æ™‚æ ¹æ“šå¤±æ•—æ­¥é©Ÿæˆ–ç’°å¢ƒè®ŠåŒ–èª¿æ•´è¨ˆåŠƒã€‚\n",
    "    \n",
    "    è®“æ™ºèƒ½é«”å…·å‚™ã€Œè‡ªæˆ‘ä¿®æ­£ã€èƒ½åŠ›ã€‚\n",
    "    \n",
    "    åœ¨é•·ç¨‹ä»»å‹™ä¸­æ ¹æ“šä¸­é–“è¼¸å‡ºé‡æ–°å®‰æ’å¾ŒçºŒæ­¥é©Ÿã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    # è‹¥æ˜¯ replanner çµ¦å‡º Response, çµæŸè¿´åœˆ\n",
    "    # è‹¥æ˜¯ replanner çµ¦å‡º Aaction, ç¹¼çºŒåŸ·è¡Œ\n",
    "    output = await replanner.ainvoke(state)\n",
    "    if isinstance(output.action, Response):\n",
    "        return {\"response\": output.action.response}\n",
    "    else:\n",
    "        if output.action.steps:\n",
    "            return {\"plan\": output.action.steps}\n",
    "        else:\n",
    "            return {\"response\": state['past_steps'][-1][1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891decb3-0846-4687-bc28-73a849dbcce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_end(state: PlanExecute):\n",
    "    \"\"\"\n",
    "    æ­¤æ–¹æ³•è² è²¬æ±ºå®šå·¥ä½œæµç¨‹æ˜¯å¦çµæŸã€‚\n",
    "    åœ¨ LangGraph ç¯€é»ä¸­ï¼Œå®ƒé€šå¸¸æ˜¯æ¢ä»¶åˆ†æ”¯ï¼ˆconditional edgeï¼‰çš„åˆ¤æ–·é‚è¼¯ï¼Œç”¨ä¾†æª¢æŸ¥ä»»å‹™æ˜¯å¦å®Œæˆæˆ–æ˜¯å¦æ‡‰è©²å›åˆ°ä»£ç†ç¹¼çºŒåŸ·è¡Œã€‚\n",
    "    \n",
    "    ä¸»è¦é‚è¼¯ï¼š\n",
    "    \n",
    "    è‹¥ state ä¸­å­˜åœ¨ response ä¸”å…¶å€¼éç©ºï¼Œä»£è¡¨ä»»å‹™å·²å®Œæˆ â†’ å›å‚³ ENDã€‚\n",
    "    \n",
    "    å¦å‰‡ï¼Œå›å‚³ \"agent\"ï¼Œè¡¨ç¤ºä»éœ€ç”±ä»£ç†ç¯€é»ç¹¼çºŒåŸ·è¡Œã€‚\n",
    "    \n",
    "    åƒæ•¸ï¼š\n",
    "    \n",
    "    state (PlanExecute)ï¼šç›®å‰çš„åŸ·è¡Œç‹€æ…‹ã€‚\n",
    "    \n",
    "    å›å‚³ï¼š\n",
    "    \n",
    "    ENDï¼ˆä»»å‹™å®Œæˆï¼ŒçµæŸç¯€é»ï¼‰æˆ– \"agent\"ï¼ˆç¹¼çºŒåŸ·è¡Œä¸‹ä¸€éšæ®µï¼‰ã€‚\n",
    "    \n",
    "    æ‡‰ç”¨æƒ…å¢ƒï¼š\n",
    "    æ­¤ç¯€é»å¸¸ç”¨æ–¼ï¼š\n",
    "    \n",
    "    æµç¨‹æ§åˆ¶ï¼ˆæ±ºå®šä»»å‹™æ˜¯å¦çµæŸï¼‰ã€‚\n",
    "    \n",
    "    å¤šç¯€é» LangGraph æµç¨‹ä¸­è¨­ç½®çµ‚æ­¢æ¢ä»¶ã€‚\n",
    "    \n",
    "    ç¢ºä¿ç³»çµ±åœ¨ä»»å‹™å®Œæˆå¾Œé©æ™‚åœæ­¢ï¼Œä¸é€²è¡Œå¤šé¤˜æ“ä½œã€‚\n",
    "    \"\"\"\n",
    "    \n",
    "    if \"response\" in state and state[\"response\"]:\n",
    "        return END\n",
    "    else:\n",
    "        return \"agent\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1e7ad6-5d36-4928-b96a-0a572f9b8b55",
   "metadata": {},
   "source": [
    "LangGraph æ˜¯å®£å‘Šå¼ï¼ˆdeclarativeï¼‰çš„ï¼Œè€Œéç´”ç²¹å‹•æ…‹ï¼ˆpurely dynamicï¼‰çš„ã€‚\n",
    "é€™è¡¨ç¤ºç•¶ä½ åœ¨å»ºç«‹å·¥ä½œæµç¨‹åœ–ï¼ˆworkflow graphï¼‰æ™‚ï¼ˆä¹Ÿå°±æ˜¯åœ¨åŸ·è¡Œä¹‹å‰ï¼‰ï¼ŒLangGraph éœ€è¦äº‹å…ˆçŸ¥é“æ‰€æœ‰å¯èƒ½çš„åˆ†æ”¯â€”â€”\n",
    "å³ä½¿ä½ çš„æ¢ä»¶å‡½å¼ï¼ˆshould_endï¼‰æœƒåœ¨åŸ·è¡Œéšæ®µæ‰æ±ºå®šå¯¦éš›è¦èµ°å“ªä¸€å€‹åˆ†æ”¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ac6db2-e3ce-499a-94fe-77bf5b9eede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "workflow = StateGraph(PlanExecute)\n",
    "\n",
    "# Add the plan node\n",
    "workflow.add_node(\"planner\", plan_step)\n",
    "\n",
    "# Add the execution step\n",
    "workflow.add_node(\"agent\", execute_step)\n",
    "\n",
    "# Add a replan node\n",
    "workflow.add_node(\"replan\", replan_step)\n",
    "\n",
    "workflow.add_edge(START, \"planner\")\n",
    "\n",
    "# From plan we go to agent\n",
    "workflow.add_edge(\"planner\", \"agent\")\n",
    "\n",
    "# From agent, we replan\n",
    "workflow.add_edge(\"agent\", \"replan\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"replan\",\n",
    "    should_end,\n",
    "    [\"agent\", END]\n",
    ")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20752f84-b2b2-4e21-a791-9daaa2d6af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d77480-b1a1-474c-82a4-e04ca8680b35",
   "metadata": {},
   "source": [
    "#### ç¯„ä¾‹ä¸€: 2023å¹´æ¾³æ´²ç¶²çƒå…¬é–‹è³½å† è»çš„è€å®¶åœ¨å“ªè£¡?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a1255-a90c-43d7-a2f8-7330fe15d71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"recursion_limit\": 50}\n",
    "inputs = {\"input\": \"what is the hometown of the mens 2023 Australia open winner?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22f0040-bcf8-463c-9e92-b32da959e533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow server --host 127.0.0.1 --port 8080\n",
    "import mlflow\n",
    "\n",
    "experiment = \"Week-8-Exp1\"\n",
    "uri = \"http://127.0.0.1:8081\"\n",
    "\n",
    "mlflow.set_tracking_uri(uri=uri)\n",
    "\n",
    "# Start or get an MLflow run explicitly\n",
    "mlflow.set_experiment(experiment)\n",
    "\n",
    "mlflow.langchain.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6ec7f9-3e49-4d30-a1a4-3a1612799b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async for event in app.astream(inputs, config=config):\n",
    "    for k, v in event.items():\n",
    "        if k != \"__end__\":\n",
    "            print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f8587f-75d9-4008-86d1-aaffa148caf8",
   "metadata": {},
   "source": [
    "#### ç¯„ä¾‹äºŒ å°ç£è·æ£’å¯Œé‚¦æ‚å°‡çš„å•¦å•¦éšŠä¸‰æœ¬æŸ±æ˜¯èª°?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a29ef6-8697-47bf-a461-aae3989d56c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"recursion_limit\": 50}\n",
    "inputs = {\"input\": \"å°ç£è·æ£’å¯Œé‚¦æ‚å°‡çš„å•¦å•¦éšŠä¸‰æœ¬æŸ±æ˜¯èª°?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7f25ad-9e27-41d1-bdbb-f5fbcc4d6e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "async for event in app.astream(inputs, config=config):\n",
    "    for k, v in event.items():\n",
    "        if k != \"__end__\":\n",
    "            print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c91039-b819-4532-ac19-413968f9a645",
   "metadata": {},
   "source": [
    "## ğŸ’¬ è©•è«–ï¼šLangGraph ä»»å‹™åŸ·è¡Œè§€å¯Ÿ4èˆ‡å„ªåŒ–å»ºè­°\n",
    "\n",
    "é€™æ¬¡çš„æœ€çµ‚ç­”æ¡ˆæ˜¯æ­£ç¢ºçš„â€”â€”**ã€Œå¯Œé‚¦æ‚å°‡å•¦å•¦éšŠçš„ä¸‰æœ¬æŸ±ç‚ºæç ç¢ã€æé›…è‹±ã€å—ç‰è²ã€**ï¼Œçµæœç¬¦åˆäº‹å¯¦ã€‚  \n",
    "ä¸éæ•´é«”æ¨ç†èˆ‡è¡Œå‹•éç¨‹é¡¯å¾—æœ‰äº›ã€Œç¬¨æ‹™ã€ï¼Œå­˜åœ¨æ˜é¡¯çš„å„ªåŒ–ç©ºé–“ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§  å•é¡Œè§€å¯Ÿ\n",
    "1. **é‡è¤‡èˆ‡ä½æ•ˆçš„æŸ¥è©¢æ­¥é©Ÿ**  \n",
    "   å¤šæ¬¡åŸ·è¡Œé¡ä¼¼çš„ `websearch`ï¼ŒæŸ¥è©¢é—œéµå­—å·®ç•°ä¸å¤§ï¼Œå°è‡´ç³»çµ±é‡è¤‡ç²å–ç›¸è¿‘å…§å®¹ï¼Œæµªè²»è³‡æºèˆ‡æ™‚é–“ã€‚  \n",
    "\n",
    "2. **ä¸Šä¸‹æ–‡ç†è§£ä¸è¶³**  \n",
    "   ç•¶å·²ç¶“åœ¨å‰ä¸€æ­¥ç¢ºå®šã€Œä¸‰æœ¬æŸ±ã€æŒ‡çš„æ˜¯å¯Œé‚¦æ‚å°‡çš„éŸ“ç±å•¦å•¦éšŠæˆå“¡æ™‚ï¼Œå¾ŒçºŒæ­¥é©Ÿä»ç„¶é‡æ–°æŸ¥è©¢ã€Œä¸‰ä½æˆå“¡çš„åå­—ã€ï¼Œ  \n",
    "   é¡¯ç¤ºæ¨¡å‹æ²’æœ‰æœ‰æ•ˆåˆ©ç”¨å…ˆå‰çš„ç‹€æ…‹ï¼ˆ`past_steps`ï¼‰ã€‚  \n",
    "\n",
    "---\n",
    "\n",
    "### âš™ï¸ æ”¹é€²å»ºè­°\n",
    "1. **å¼·åŒ–ä¸Šä¸‹æ–‡è¨˜æ†¶ä½¿ç”¨ï¼ˆState Managementï¼‰**  \n",
    "   - åœ¨ `execute_step` æˆ– `replan_step` éšæ®µä¸­ï¼Œæ˜ç¢ºè®“ agent æª¢æŸ¥ `past_steps`ï¼Œé¿å…é‡è¤‡æŸ¥è©¢ç›¸åŒå•é¡Œã€‚  \n",
    "\n",
    "2. **åŠ å…¥å‹•æ…‹åœæ­¢æ¢ä»¶ï¼ˆDynamic Stop Conditionï¼‰**  \n",
    "   - è‹¥ `agent_response` å·²åŒ…å«é«˜ç½®ä¿¡åº¦çš„å…·é«”åç¨±ï¼ˆä¾‹å¦‚ä¸‰å€‹äººåï¼‰ï¼Œå¯ç›´æ¥å°‡ç‹€æ…‹åˆ‡æ›ç‚º `END`ï¼Œç„¡éœ€ç¹¼çºŒå¾ªç’°ã€‚  \n",
    "\n",
    "3. **å„ªåŒ–æœå°‹ç­–ç•¥**  \n",
    "   - å°‡å¤šæ­¥æŸ¥è©¢æ•´åˆç‚ºå–®ä¸€æ˜ç¢ºæŸ¥è©¢ï¼Œä¾‹å¦‚ï¼š  \n",
    "     ã€Œå¯Œé‚¦æ‚å°‡ å•¦å•¦éšŠ ä¸‰æœ¬æŸ± 2025 æˆå“¡åå–®ã€ï¼Œä»¥æ¸›å°‘å™ªéŸ³ã€‚  \n",
    "\n",
    "4. **ä¿®æ­£è¼¸å‡ºæ ¼å¼ç”Ÿæˆé‚è¼¯**  \n",
    "   - åœ¨ LLM Prompt Template ä¸­ï¼Œä½¿ç”¨çµæ§‹åŒ–æ ¼å¼ï¼ˆå¦‚ JSON æˆ– YAMLï¼‰æ˜ç¢ºå®šç¾© `Thought / Action / Observation` å€å¡Šï¼Œæ¸›å°‘æ ¼å¼éŒ¯èª¤ã€‚  \n",
    "\n",
    "5. **å¯è€ƒæ…®åŠ å…¥ Re-Planning åˆ¤æ–·å¼·åŒ–**  \n",
    "   - ç•¶ç³»çµ±åµæ¸¬åˆ°é‡è¤‡æŸ¥è©¢æˆ–å…§å®¹ç„¡è®ŠåŒ–æ™‚ï¼Œå¯è‡ªå‹•è§¸ç™¼ `replan_step`ï¼Œåˆ‡æ›ç­–ç•¥æˆ–ç›´æ¥è¼¸å‡ºçµæœã€‚  \n",
    "\n",
    "---\n",
    "\n",
    "### âœ… ç¸½çµ\n",
    "æ•´é«”è€Œè¨€ï¼Œç³»çµ±æœ€çµ‚å¾—å‡ºäº†æ­£ç¢ºç­”æ¡ˆï¼Œèªªæ˜ä»»å‹™è¨­è¨ˆé‚è¼¯æœ‰æ•ˆï¼›  \n",
    "ä½†åœ¨éç¨‹ä¸­è¡¨ç¾å‡ºç¼ºä¹ä¸Šä¸‹æ–‡è¨˜æ†¶ã€é‡è¤‡æŸ¥è©¢èˆ‡æ ¼å¼éŒ¯èª¤ç­‰å•é¡Œã€‚  \n",
    "\n",
    "è‹¥èƒ½åŠ å¼·ç‹€æ…‹åˆ¤æ–·ã€çµæœç½®ä¿¡åº¦è©•ä¼°èˆ‡æŸ¥è©¢æ•´åˆï¼Œå°‡èƒ½é¡¯è‘—æå‡æ•ˆç‡èˆ‡æ™ºèƒ½ç¨‹åº¦ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eaa988-b1ca-4a6e-9f98-d84660b4a4ee",
   "metadata": {},
   "source": [
    "### Reserved / Special Parts of `config`\n",
    "\n",
    "Below are the reserved or commonly used keys in the `config` dictionary when working with **LangGraph**:\n",
    "\n",
    "| Key | Purpose | Example |\n",
    "|------|----------|----------|\n",
    "| `\"configurable\"` | âœ… **Main section for user-defined and framework config.** Used by checkpointers, node settings, etc. | `{\"configurable\": {\"thread_id\": \"abc123\"}}` |\n",
    "| `\"recursion_limit\"` | **Limits graph recursion depth.** Prevents infinite loops or too-deep graph calls. | `{\"recursion_limit\": 10}` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8107d5-f8f3-4d87-8ba2-ddc6f7c6700a",
   "metadata": {},
   "source": [
    "# LangGraph Memory\n",
    "\n",
    "## configurable\n",
    "\n",
    "- å–å¾—å·¥ä½œæµçš„æœ€å¾Œä¸€å€‹state\n",
    "- æ ¹æ“šç•¶å‰çš„stateç¹¼çºŒåŸ·è¡Œ\n",
    "\n",
    "Dummy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db5eeb4-0d36-4a74-a116-8b6c103c8093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from operator import add\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "class State(TypedDict):\n",
    "    foo: str\n",
    "    bar: Annotated[list[str], add]\n",
    "\n",
    "def node_a(state: State):\n",
    "    return {\"foo\": \"a\", \"bar\": [\"a\"]}\n",
    "\n",
    "def node_b(state: State):\n",
    "    return {\"foo\": \"b\", \"bar\": [\"b\"]}\n",
    "\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"node_a\", node_a)\n",
    "workflow.add_node(\"node_b\", node_b)\n",
    "workflow.add_edge(START, \"node_a\")\n",
    "workflow.add_edge(\"node_a\", \"node_b\")\n",
    "workflow.add_edge(\"node_b\", END)\n",
    "\n",
    "\"\"\"\n",
    "Checkpoints:\n",
    "\n",
    "The state of a thread at a particular point in time is called a checkpoint. \n",
    "Checkpoint is a snapshot of the graph state saved at each superstep and is represented by StateSnapshot object.\n",
    "\"\"\"\n",
    "\n",
    "# è¦å–å¾—stateçš„å…§å®¹ï¼Œä½ å¿…é ˆè¦åŒæ™‚æœ‰ InMemeorySaver å’Œ configurable\n",
    "checkpointer = InMemorySaver()\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "graph = workflow.compile(checkpointer=checkpointer)\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d3de89-b134-4577-a0e9-b062514a5e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\"foo\": \"\"}, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e44fd29-d2bd-44da-8238-c23ec1d3ca8a",
   "metadata": {},
   "source": [
    "## Get state\n",
    "\n",
    "ç•¶èˆ‡å·²å„²å­˜çš„åœ–å½¢ç‹€æ…‹äº’å‹•æ™‚ï¼Œæ‚¨å¿…é ˆæŒ‡å®šä¸€å€‹åŸ·è¡Œç·’è­˜åˆ¥ç¢¼ï¼ˆthread identifierï¼‰ã€‚æ‚¨å¯ä»¥é€éå‘¼å« graph.get_state(config) ä¾†æŸ¥çœ‹åœ–å½¢çš„æœ€æ–°ç‹€æ…‹ã€‚æ­¤æ–¹æ³•æœƒå›å‚³ä¸€å€‹ StateSnapshot ç‰©ä»¶ï¼Œè©²ç‰©ä»¶å°æ‡‰æ–¼åœ¨ config ä¸­æä¾›çš„åŸ·è¡Œç·’ ID æ‰€é—œè¯çš„æœ€æ–°æª¢æŸ¥é»ï¼ˆcheckpointï¼‰ï¼Œæˆ–è€…ï¼Œå¦‚æœæä¾›äº†æª¢æŸ¥é» IDï¼Œå‰‡æœƒå›å‚³èˆ‡è©²åŸ·è¡Œç·’ç›¸é—œçš„æª¢æŸ¥é»ç‹€æ…‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801dda91-4fbc-4da1-b311-dfa94e4492ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(config)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246a7d63-3861-46e2-80a8-762132f6e48b",
   "metadata": {},
   "source": [
    "## Get state history\n",
    "\n",
    "æ‚¨å¯ä»¥é€éå‘¼å« graph.get_state_history(config) ä¾†å–å¾—æŒ‡å®šåŸ·è¡Œç·’çš„å®Œæ•´åœ–å½¢åŸ·è¡Œæ­·å²ã€‚æ­¤æ–¹æ³•æœƒå›å‚³ä¸€å€‹èˆ‡ config ä¸­æä¾›çš„åŸ·è¡Œç·’ ID ç›¸é—œè¯çš„ StateSnapshot ç‰©ä»¶æ¸…å–®ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œé€™äº›æª¢æŸ¥é»ï¼ˆcheckpointsï¼‰æœƒä¾æ™‚é–“é †åºæ’åˆ—ï¼Œæœ€æ–°çš„æª¢æŸ¥é»ï¼StateSnapshot æœƒä½æ–¼æ¸…å–®çš„æœ€å‰ç«¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ec5c35-e499-480e-8acc-a63ac0b3e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "list(graph.get_state_history(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b419ad-c79b-453c-b69f-8f985eb2ca72",
   "metadata": {},
   "source": [
    "## Get State: specific to checkpoint_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a72db02-8e54-4f19-b987-651a01ec7981",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state({\"configurable\": {\"thread_id\": \"1\",\n",
    "                                          \"checkpoint_id\": '1f0c7703-9870-6223-8001-9f6b6613e6e7'}})\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8fb2b1-df7d-46d2-9a89-397ea0d6f7a2",
   "metadata": {},
   "source": [
    "## Replay\n",
    "\n",
    "ä¹Ÿå¯ä»¥é‡æ’­å…ˆå‰çš„åœ–å½¢åŸ·è¡Œéç¨‹ã€‚è‹¥æˆ‘å€‘åœ¨å‘¼å«åœ–å½¢æ™‚åŒæ™‚æŒ‡å®š thread_id å’Œ checkpoint_idï¼Œç³»çµ±å°‡æœƒé‡æ–°åŸ·è¡Œå°æ‡‰æ–¼è©² checkpoint_id æª¢æŸ¥é»ä¹‹å‰çš„æ‰€æœ‰æ­¥é©Ÿï¼Œä¸¦åƒ…åŸ·è¡Œè©²æª¢æŸ¥é»ä¹‹å¾Œçš„æ­¥é©Ÿã€‚\n",
    "\n",
    "- thread_id æ˜¯åŸ·è¡Œç·’çš„è­˜åˆ¥ç¢¼ã€‚\n",
    "- checkpoint_id æ˜¯æŒ‡å‘è©²åŸ·è¡Œç·’ä¸­æŸå€‹ç‰¹å®šæª¢æŸ¥é»çš„è­˜åˆ¥ç¢¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21ee627-250b-43a5-a3df-be5fb7bf26d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke(None, config={\"configurable\": {\"thread_id\": \"1\",\n",
    "                                            \"checkpoint_id\": '1f0c7703-9870-6223-8001-9f6b6613e6e7'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58ebaa7-a916-47e9-a994-df0dec39a239",
   "metadata": {},
   "source": [
    "é‡è¦çš„æ˜¯ï¼ŒLangGraph å…·å‚™è¾¨è­˜ç‰¹å®šæ­¥é©Ÿæ˜¯å¦å·²è¢«åŸ·è¡Œéçš„èƒ½åŠ›ã€‚è‹¥æŸå€‹æ­¥é©Ÿå·²ç¶“åŸ·è¡Œéï¼ŒLangGraph æœƒåœ¨åœ–å½¢ä¸­é‡æ’­è©²æ­¥é©Ÿï¼Œè€Œä¸æœƒé‡æ–°åŸ·è¡Œå®ƒâ€”â€”ä½†é€™åƒ…é©ç”¨æ–¼åœ¨æ‰€æä¾›çš„ checkpoint_id ä¹‹å‰çš„æ­¥é©Ÿã€‚è‡³æ–¼ checkpoint_id ä¹‹å¾Œçš„æ‰€æœ‰æ­¥é©Ÿï¼Œå‰‡éƒ½æœƒè¢«é‡æ–°åŸ·è¡Œï¼ˆå³ç”¢ç”Ÿä¸€å€‹æ–°çš„åˆ†æ”¯ï¼‰ï¼Œå³ä½¿é€™äº›æ­¥é©Ÿå…ˆå‰å·²ç¶“åŸ·è¡Œéã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4635ac1a-2245-4182-aa83-4500876a5937",
   "metadata": {},
   "source": [
    "## Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944518be-cb53-4375-b705-ce214f1e6a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\"foo\": \"c\"}, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fff561c-83b9-4c62-8a5b-d3ab867cf2c5",
   "metadata": {},
   "source": [
    "## InMemoryStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c610fe-c69a-4df8-a376-6dd5e5f78df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "in_memory_store = InMemoryStore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2ae107-d000-4c6a-b8b6-69ce01d9fd4e",
   "metadata": {},
   "source": [
    "è¨˜æ†¶ï¼ˆMemoriesï¼‰æ˜¯ä»¥ä¸€å€‹å…ƒçµ„ï¼ˆtupleï¼‰ä½œç‚ºå‘½åç©ºé–“ï¼ˆnamespaceï¼‰ä¾†å€åˆ†çš„ï¼Œåœ¨æ­¤ç‰¹å®šç¯„ä¾‹ä¸­ç‚º (<user_id>, \"memories\")ã€‚å‘½åç©ºé–“çš„é•·åº¦å¯ä»¥æ˜¯ä»»æ„çš„ï¼Œä¸¦ä¸”å¯ä»¥ä»£è¡¨ä»»ä½•å…§å®¹ï¼Œä¸ä¸€å®šå¿…é ˆèˆ‡ä½¿ç”¨è€…ç›¸é—œã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e652249-f717-4fe5-936c-98377a8e9e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = \"1\"\n",
    "namespace_for_memory = (user_id, \"memories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f481f61-527c-4711-a331-7702f9574d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "memory_id = str(uuid.uuid4())\n",
    "\n",
    "memory = {\"food_preference\" : \"I like pizza\"}\n",
    "\n",
    "# åœ¨ç‰¹å®šç”¨æˆ¶ï¼Œç‰¹å®šä¸»é¡Œä¹‹ä¸‹ï¼Œå°‡ç‰¹å®šå…§å®¹ç”¨ memory_id æ¨™è¨˜ä¸¦ä¸”å„²å­˜\n",
    "in_memory_store.put(namespace_for_memory, memory_id, memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd2a052-2594-4529-b79d-ff95a9c3652f",
   "metadata": {},
   "source": [
    "### æª¢ç´¢\n",
    "\n",
    "æ ¹æ“šç”¨æˆ¶IDå’Œä¸»é¡Œä¾†æœå°‹ç›¸é—œç´€éŒ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749ac1e2-bbf5-4d53-a4b0-ce3e71251d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_memory_store.search(namespace_for_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1771e17a-0af0-4446-b5fa-9033b5a2a425",
   "metadata": {},
   "source": [
    ">- valueï¼šæ­¤è¨˜æ†¶çš„å…§å®¹ï¼ˆæœ¬èº«ç‚ºä¸€å€‹å­—å…¸ï¼‰\n",
    ">- keyï¼šæ­¤å‘½åç©ºé–“ä¸­è©²è¨˜æ†¶çš„å”¯ä¸€éµå€¼\n",
    ">- namespaceï¼šç”±å­—ä¸²çµ„æˆçš„æ¸…å–®ï¼Œè¡¨ç¤ºæ­¤è¨˜æ†¶é¡å‹æ‰€å±¬çš„å‘½åç©ºé–“\n",
    ">- created_atï¼šæ­¤è¨˜æ†¶çš„å»ºç«‹æ™‚é–“æˆ³è¨˜\n",
    ">- updated_atï¼šæ­¤è¨˜æ†¶çš„æ›´æ–°æ™‚é–“æˆ³è¨˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd95bf1-40f8-4b1e-ab4b-5a0b46d7838e",
   "metadata": {},
   "source": [
    "åŠ å…¥èªæ„æœç´¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087dc1c9-0fc1-4d56-9a5b-2a7afdacd760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import init_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c74a52b-1ca9-4722-9d7e-292c81426205",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeded = init_embeddings(\"huggingface:BAAI/bge-m3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dd50a8-31f1-4588-8431-a8c2009bf069",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeded.embed_query(\"Hello World\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971b8b40-e907-44a7-b040-7ea8853f0592",
   "metadata": {},
   "source": [
    "The main configuration options:\n",
    "\n",
    ">- embedï¼šåµŒå…¥ï¼ˆembeddingï¼‰æä¾›è€…ï¼ˆä¾‹å¦‚ \"openai:text-embedding-3-small\"ï¼‰ï¼Œæˆ–æ˜¯è‡ªè¨‚å‡½å¼çš„è·¯å¾‘ï¼ˆdocï¼‰ã€‚å¯ç”¨çš„ provider:model çµ„åˆå–æ±ºæ–¼ LangChain çš„æ”¯æ´ã€‚\n",
    ">- dimsï¼šæ‰€é¸åµŒå…¥æ¨¡å‹çš„ç¶­åº¦å¤§å°ï¼ˆä¾‹å¦‚ OpenAI çš„ text-embedding-3-small ç‚º 1536 ç¶­ï¼‰ã€‚\n",
    ">- fieldsï¼šè¦å»ºç«‹ç´¢å¼•çš„æ¬„ä½æ¸…å–®ã€‚å¯ä½¿ç”¨ [\"$\"] ä¾†ç´¢å¼•æ•´ä»½æ–‡ä»¶ï¼Œæˆ–æŒ‡å®š JSON è·¯å¾‘ï¼Œä¾‹å¦‚ [\"text\", \"summary\", \"messages[-1]\"]ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423e2856-e034-4524-8664-1d3730c03da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = InMemoryStore(\n",
    "    index={\n",
    "        \"embed\": embeded,  # Embedding provider\n",
    "        \"dims\": 1024,                              # Embedding dimensions\n",
    "        \"fields\": [\"food_preference\"]         # Fields to embed\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a8b28b-cfd9-4c20-a32e-9f4d7c11fd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "store.put(namespace_for_memory, memory_id, memory)\n",
    "\n",
    "store.put(\n",
    "    namespace_for_memory,\n",
    "    str(uuid.uuid4()),\n",
    "    {\n",
    "        \"food_preference\": \"I love Italian cuisine\",\n",
    "        \"context\": \"Discussing dinner plans\"\n",
    "    },\n",
    "    index=[\"food_preference\"]  # Only embed \"food_preferences\" field\n",
    ")\n",
    "\n",
    "store.put(\n",
    "    namespace_for_memory,\n",
    "    str(uuid.uuid4()),\n",
    "    {\"system_info\": \"Last updated: 2024-01-01\"},\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c4ac2c-fa2f-437e-a41d-a0683392f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "store.search(\n",
    "    namespace_for_memory,\n",
    "    query=\"What does the user like to eat?\",\n",
    "    limit=5  # Return top 3 matches\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ee3748-e91a-4ef7-911a-05c172f61b6a",
   "metadata": {},
   "source": [
    "### Search with Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e12ad88-bad8-47e4-bcdd-ee4cb9956641",
   "metadata": {},
   "outputs": [],
   "source": [
    "store.search(namespace_for_memory, filter={\"context\": \"Discussing dinner plans\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c22f284-f5b8-4478-a437-300124864cf4",
   "metadata": {},
   "source": [
    "åœ¨Workflowä¸­èª¿ç”¨store\n",
    "\n",
    "We can access the in_memory_store and the user_id in any node by passing store: BaseStore and config: RunnableConfig as node arguments. Here's how we might use semantic search in a node to find relevant memories\n",
    "\n",
    "ç…§è‘—å®˜æ–¹æ–‡ä»¶åšï¼Œæœƒå ±éŒ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64caa2e5-cb43-44b1-8692-ec7042a44658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.config import RunnableConfig\n",
    "from langchain_core.stores import BaseStore\n",
    "\n",
    "class State(TypedDict):\n",
    "    foo: str\n",
    "    bar: Annotated[list[str], add]\n",
    "\n",
    "def node_a(state: State, config: RunnableConfig):\n",
    "\n",
    "    print(config[\"configurable\"][\"user_id\"])\n",
    "\n",
    "    print(\"*****\")\n",
    "    print(config['configurable']['__pregel_runtime'])\n",
    "    print(\"*****\")\n",
    "\n",
    "    store_ = config['configurable']['__pregel_runtime'].store\n",
    "    \n",
    "    print(store_.search(namespace_for_memory, filter={\"context\": \"Discussing dinner plans\"}))\n",
    "    \n",
    "    return {\"foo\": \"a\", \"bar\": [\"a\"]}\n",
    "\n",
    "def node_b(state: State, config: RunnableConfig):\n",
    "    return {\"foo\": \"b\", \"bar\": [\"b\"]}\n",
    "\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"node_a\", node_a)\n",
    "workflow.add_node(\"node_b\", node_b)\n",
    "workflow.add_edge(START, \"node_a\")\n",
    "workflow.add_edge(\"node_a\", \"node_b\")\n",
    "workflow.add_edge(\"node_b\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc2df89-cb73-4780-b1d0-bf8e8d885300",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = InMemorySaver()\n",
    "config = {\"configurable\": {\"thread_id\": \"100\",\n",
    "                           \"user_id\": 1}}\n",
    "\n",
    "graph = workflow.compile(checkpointer=checkpointer, store=store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad925b18-5977-4c3d-917a-63fa6c827296",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\"foo\": \"\"},  config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8205aa57-d0f3-4a75-88c6-40d9f7887ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = graph.nodes['node_a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb4c937-9299-46d9-96b3-411d39d4feae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
